{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON5Rrk6nK9ORBNSfO6wNbq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Adaline is also a single layer neural network.Adaline Algorithm is quite intersting and important, as this lays the groundwork for the fundamental ML algorithms such as Logistic Regression, SVM and multi layer NN as well as linear regression.\n",
        "\n",
        "#### Key differenvce in the Adaline algorithm and the perceptron algorithm weights in this are updated using a **linear activation function** rather than a unit step function.\n",
        "\n",
        "### The Activation Function in the Adaline is simply just an ***Identity Function***."
      ],
      "metadata": {
        "id": "1Bpcwna9R04T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adaline algorithm compares the true target variable with the continuous output of the linear activation fucntion to compute the model error and update the weights."
      ],
      "metadata": {
        "id": "s3-i6f6OTWTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since these algorithms are quite similar, I would just need to make slight adjustment to the fit() function in such a manner that `bias` and `weights` parameters are updated via ***`minimizing the loss function using gradient descent`***."
      ],
      "metadata": {
        "id": "wlfm_sF1T0Lv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hSGSuzPNO3O-"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters or Tuning Parameters for the model.\n",
        "eta = 0.0001\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Import the data similarly to the Perceptron"
      ],
      "metadata": {
        "id": "M5xVdu2LUhmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "Iris_dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "print('From URL:', Iris_dataset_url)\n",
        "data = pd.read_csv(Iris_dataset_url,\n",
        "                header=None,\n",
        "                encoding='utf-8')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "print(data[4].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBv9dWBIUd_t",
        "outputId": "7864ece2-4625-4fa1-9239-339a4182ce85"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From URL: https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
            "     0    1    2    3            4\n",
            "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
            "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
            "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
            "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
            "4  5.0  3.6  1.4  0.2  Iris-setosa\n",
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique species before dropping 'Iris-versicolor':\", data[4].unique())\n",
        "data = data[data[4] != 'Iris-versicolor']\n",
        "print(\"Unique species after dropping 'Iris-versicolor':\", data[4].unique())\n",
        "print(\"NaN values present in 'Species':\", data[4].isnull().any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b9JFP7GUpIw",
        "outputId": "349ee151-e4d6-46c9-fc77-0790f6a6410d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique species before dropping 'Iris-versicolor': ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
            "Unique species after dropping 'Iris-versicolor': ['Iris-setosa' 'Iris-virginica']\n",
            "NaN values present in 'Species': False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Extract the features and the class label from the data and assign the encoded label to the target variable\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "V_8UeHYpU6gj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def net_input(X, weight):\n",
        "    return np.dot(X, weight)\n",
        "\n",
        "def activation(X):\n",
        "    return X ## Adaline uses identity function as the activation function\n",
        "\n",
        "def predict(X, weight):\n",
        "    net_inp = activation(X)\n",
        "    return np.where(net_inp >= 0.5, 1, 0)\n"
      ],
      "metadata": {
        "id": "guiUrc5bVZ33"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Rather tha using the Prediction and the Actual Target Variables, Adaline Algorithm uses `sum of squared errors - SSE` as the `loss` function. We first calculate the loss function for the entire epoch and then compute it's gradient to make the adjustment into the `weights`.  \n",
        "\n",
        "### Loss Function\n",
        "\n",
        "The Loss function quantifies the error between the predicted outputs and the actual target values across all samples in the dataset. As mentioned earlier, the Adaline uses the Sum of Squared Errors (SSE) as its loss function, defined as:\n",
        "\n",
        "\n",
        "### Gradient of the Loss Function\n",
        "\n",
        "The gradient of the loss function with respect to the weights is a vector that points in the direction of the steepest increase of the cost function. To minimize the cost, we want to move in the opposite direction of this gradient. The gradient tells us how to change the weights to decrease the cost.\n",
        "\n",
        "### Weight Update\n",
        "\n",
        "The weight update step then uses this gradient to adjust the weights in the direction that minimally decreases the loss function.\n",
        "\n",
        "In the Adaline algorithm, by iteratively updating the weights in the opposite direction of the cost function's gradient, we gradually ***`\"descend\"`*** towards the set of weights that minimizes the cost, ideally leading to a model that accurately predicts the target values with minimal error.\n",
        "\n",
        "Here's how I am going to implement the SSE in the Adaline `fit` method:\n",
        "\n",
        "```python\n",
        "loss = []\n",
        "...\n",
        "errors = y - output\n",
        "loss.append((errors**2).sum() / 2.0)\n",
        "```\n",
        "\n",
        "To break it down:\n",
        "\n",
        "- `errors = y - output`: Here, `errors` is a vector containing the differences between the actual target values (`y`) and the predicted values (`output`). The predicted values are obtained by applying the net input through the activation function, which in the case of Adaline is the identity function (meaning `output` equals the net input).\n",
        "\n",
        "- `loss.append((errors**2).sum() / 2.0)`: This line calculates the Sum of Squared Errors (SSE) for the current epoch. First, each error in `errors` is squared (`errors**2`), effectively applying the part of the SSE formula for each sample. Then, the sum of all these squared errors is computed (`(errors**2).sum()`). Finally, this sum is divided by 2 (`/ 2.0`), following the loss function, and appended to the `loss` list. This division by 2 doesn't change the location of the minimum but simplifies the derivative calculation.\n",
        "\n",
        "By appending the SSE to the `loss` list at each epoch, the algorithm keeps track of how well the model is performing over time. A decreasing trend in the `loss` values indicates that the model is learning and improving its predictions.\n",
        "\n",
        "This also provides a useful metric for evaluating the convergence of the algorithm. ideally, we would want to see the cost decreasing and eventually stabilizing as the model parameters (weights) are optimized during the training process."
      ],
      "metadata": {
        "id": "vBW0ar6kK99T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(X, y):\n",
        "    rgen = np.random.RandomState(1)\n",
        "    weight = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
        "    loss = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "        print(f\"Epoch - {i} starting.....\")\n",
        "        net_input = np.dot(X, weight[1:]) + weight[0]\n",
        "        output = net_input\n",
        "        print(f\"Predicted Output from the Adaline Model in the {i} th step is as follows:\", output)\n",
        "        print('\\n')\n",
        "        errors = (y - output)\n",
        "        print(f\"Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\\n\", errors)\n",
        "\n",
        "        \"\"\"\n",
        "        Here, When we use += with eta * X.T.dot(errors), we are technically\n",
        "        adding the negative gradient (scaled by Î·), which means we are\n",
        "        moving in the opposite direction of the gradient of the cost function\n",
        "        \"\"\"\n",
        "        weight[1:] += eta * X.T.dot(errors)\n",
        "        weight[0] += eta * errors.sum()\n",
        "        # Here, let's append the loss the loss history list so we can evaluate and track the model performance\n",
        "        loss.append((errors**2).sum() / 2.0)\n",
        "        print(f\"Current value for the Loss value is ::\", loss)\n",
        "    return weight, loss"
      ],
      "metadata": {
        "id": "jHu_TXlzWfcy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "weight, loss = fit(X, y)\n",
        "plt.plot(range(1, len(loss) + 1), np.log10(loss), marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('log(Mean squared error)')\n",
        "plt.title('Adaline - Learning rate 0.01')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4iSTHlljaD5Q",
        "outputId": "b78e10a2-05fd-4129-8d80-6ef4c99dc3f8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0 starting.....\n",
            "Predicted Output from the Adaline Model in the 0 th step is as follows: [-0.04673288 -0.04286851 -0.04162837 -0.04263438 -0.0466493  -0.05216893\n",
            " -0.04228052 -0.04666592 -0.03928155 -0.04533506 -0.05069746 -0.04651538\n",
            " -0.04312216 -0.03684447 -0.0515101  -0.05449912 -0.04787705 -0.04586747\n",
            " -0.05434143 -0.04852496 -0.05125888 -0.04713138 -0.0399104  -0.04629922\n",
            " -0.04973428 -0.0456262  -0.04600807 -0.04841761 -0.04681646 -0.04484728\n",
            " -0.04493086 -0.04738213 -0.05245204 -0.05287711 -0.04533506 -0.04239067\n",
            " -0.04810694 -0.04533506 -0.03873676 -0.04727768 -0.04418275 -0.0347859\n",
            " -0.0397931  -0.04480543 -0.05195142 -0.04139134 -0.05046333 -0.04208958\n",
            " -0.05008571 -0.04506478 -0.08246979 -0.07177771 -0.08816799 -0.08212309\n",
            " -0.08255908 -0.09873756 -0.06050856 -0.09575143 -0.08460336 -0.09063309\n",
            " -0.07783546 -0.07759419 -0.08204085 -0.06817123 -0.06797884 -0.07677341\n",
            " -0.0828018  -0.10378225 -0.09872472 -0.07274903 -0.08412407 -0.06807102\n",
            " -0.10023134 -0.07355596 -0.08515955 -0.09350528 -0.07239941 -0.07391697\n",
            " -0.07961045 -0.09203382 -0.09282367 -0.10351767 -0.07874504 -0.07882629\n",
            " -0.08277669 -0.09225365 -0.0795715  -0.08271822 -0.07223224 -0.08210781\n",
            " -0.08043401 -0.07715809 -0.07177771 -0.08565825 -0.08169791 -0.07647937\n",
            " -0.07270718 -0.07785208 -0.07767921 -0.07483939]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [0.04673288 0.04286851 0.04162837 0.04263438 0.0466493  0.05216893\n",
            " 0.04228052 0.04666592 0.03928155 0.04533506 0.05069746 0.04651538\n",
            " 0.04312216 0.03684447 0.0515101  0.05449912 0.04787705 0.04586747\n",
            " 0.05434143 0.04852496 0.05125888 0.04713138 0.0399104  0.04629922\n",
            " 0.04973428 0.0456262  0.04600807 0.04841761 0.04681646 0.04484728\n",
            " 0.04493086 0.04738213 0.05245204 0.05287711 0.04533506 0.04239067\n",
            " 0.04810694 0.04533506 0.03873676 0.04727768 0.04418275 0.0347859\n",
            " 0.0397931  0.04480543 0.05195142 0.04139134 0.05046333 0.04208958\n",
            " 0.05008571 0.04506478 1.08246979 1.07177771 1.08816799 1.08212309\n",
            " 1.08255908 1.09873756 1.06050856 1.09575143 1.08460336 1.09063309\n",
            " 1.07783546 1.07759419 1.08204085 1.06817123 1.06797884 1.07677341\n",
            " 1.0828018  1.10378225 1.09872472 1.07274903 1.08412407 1.06807102\n",
            " 1.10023134 1.07355596 1.08515955 1.09350528 1.07239941 1.07391697\n",
            " 1.07961045 1.09203382 1.09282367 1.10351767 1.07874504 1.07882629\n",
            " 1.08277669 1.09225365 1.0795715  1.08271822 1.07223224 1.08210781\n",
            " 1.08043401 1.07715809 1.07177771 1.08565825 1.08169791 1.07647937\n",
            " 1.07270718 1.07785208 1.07767921 1.07483939]\n",
            "Current value for the Loss value is :: [29.313307773211772]\n",
            "Epoch - 1 starting.....\n",
            "Predicted Output from the Adaline Model in the 1 th step is as follows: [0.25055975 0.23861611 0.23282983 0.23253187 0.24864986 0.2742471\n",
            " 0.23601415 0.24829527 0.22210338 0.23977604 0.26405868 0.24412092\n",
            " 0.23357854 0.2123268  0.27392253 0.28532813 0.26638103 0.25252689\n",
            " 0.28033072 0.25797506 0.26451006 0.25878165 0.22850204 0.26003962\n",
            " 0.25002047 0.24561959 0.25419608 0.2555967  0.25246963 0.23872938\n",
            " 0.24063926 0.26451131 0.26059287 0.27096535 0.23977604 0.24007462\n",
            " 0.26087498 0.23977604 0.22129741 0.25136571 0.24748993 0.21821113\n",
            " 0.22361852 0.25929091 0.26780827 0.23751282 0.25797443 0.23172591\n",
            " 0.26098824 0.24516821 0.42078794 0.36897094 0.4320347  0.39450967\n",
            " 0.4136127  0.4611525  0.32328252 0.43897966 0.40608225 0.45387004\n",
            " 0.3982339  0.3913266  0.41495732 0.36358002 0.3799672  0.40499792\n",
            " 0.39984458 0.47744101 0.46941457 0.35947397 0.42821617 0.36202472\n",
            " 0.46190121 0.37842295 0.41930157 0.43349133 0.37454655 0.37576373\n",
            " 0.40232098 0.42330291 0.43892366 0.47374805 0.40428812 0.37761511\n",
            " 0.37701858 0.45832464 0.41211528 0.39793469 0.37072677 0.41722179\n",
            " 0.42091537 0.41525652 0.36897094 0.42907877 0.42717013 0.40992161\n",
            " 0.3800355  0.39787931 0.40314466 0.37355589]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.25055975 -0.23861611 -0.23282983 -0.23253187 -0.24864986 -0.2742471\n",
            " -0.23601415 -0.24829527 -0.22210338 -0.23977604 -0.26405868 -0.24412092\n",
            " -0.23357854 -0.2123268  -0.27392253 -0.28532813 -0.26638103 -0.25252689\n",
            " -0.28033072 -0.25797506 -0.26451006 -0.25878165 -0.22850204 -0.26003962\n",
            " -0.25002047 -0.24561959 -0.25419608 -0.2555967  -0.25246963 -0.23872938\n",
            " -0.24063926 -0.26451131 -0.26059287 -0.27096535 -0.23977604 -0.24007462\n",
            " -0.26087498 -0.23977604 -0.22129741 -0.25136571 -0.24748993 -0.21821113\n",
            " -0.22361852 -0.25929091 -0.26780827 -0.23751282 -0.25797443 -0.23172591\n",
            " -0.26098824 -0.24516821  0.57921206  0.63102906  0.5679653   0.60549033\n",
            "  0.5863873   0.5388475   0.67671748  0.56102034  0.59391775  0.54612996\n",
            "  0.6017661   0.6086734   0.58504268  0.63641998  0.6200328   0.59500208\n",
            "  0.60015542  0.52255899  0.53058543  0.64052603  0.57178383  0.63797528\n",
            "  0.53809879  0.62157705  0.58069843  0.56650867  0.62545345  0.62423627\n",
            "  0.59767902  0.57669709  0.56107634  0.52625195  0.59571188  0.62238489\n",
            "  0.62298142  0.54167536  0.58788472  0.60206531  0.62927323  0.58277821\n",
            "  0.57908463  0.58474348  0.63102906  0.57092123  0.57282987  0.59007839\n",
            "  0.6199645   0.60212069  0.59685534  0.62644411]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572]\n",
            "Epoch - 2 starting.....\n",
            "Predicted Output from the Adaline Model in the 2 th step is as follows: [0.35658072 0.33975752 0.33078687 0.33162976 0.35380516 0.3915064\n",
            " 0.3355753  0.35400409 0.31621792 0.34225316 0.37637842 0.34865189\n",
            " 0.33283748 0.30064962 0.38849418 0.40587642 0.37782832 0.3591149\n",
            " 0.40051951 0.36736531 0.37838657 0.36828919 0.32258364 0.37122121\n",
            " 0.35891046 0.35098242 0.36249195 0.3643861  0.35935628 0.34104544\n",
            " 0.343821   0.37661587 0.37151372 0.38539624 0.34225316 0.34052493\n",
            " 0.37070464 0.34225316 0.3144087  0.35838995 0.35130952 0.31005665\n",
            " 0.31762929 0.3691706  0.38357757 0.33790583 0.36825066 0.32982053\n",
            " 0.37199256 0.34897427 0.62157439 0.54400258 0.63827416 0.58371591\n",
            " 0.61107366 0.68414011 0.47572378 0.65151115 0.6016572  0.66929754\n",
            " 0.58528926 0.57715678 0.6114385  0.53551078 0.55828374 0.59534496\n",
            " 0.5906784  0.70736204 0.69741169 0.5311666  0.63095234 0.53253629\n",
            " 0.68619072 0.55655866 0.61872258 0.64169762 0.55036358 0.55261784\n",
            " 0.59409399 0.62656964 0.64998184 0.70080685 0.59662816 0.55740549\n",
            " 0.55997661 0.6764967  0.60697243 0.58790284 0.54481246 0.61401513\n",
            " 0.61968498 0.60882491 0.54400258 0.63340552 0.62885926 0.60186242\n",
            " 0.55929176 0.58548818 0.59321336 0.55068516]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.35658072 -0.33975752 -0.33078687 -0.33162976 -0.35380516 -0.3915064\n",
            " -0.3355753  -0.35400409 -0.31621792 -0.34225316 -0.37637842 -0.34865189\n",
            " -0.33283748 -0.30064962 -0.38849418 -0.40587642 -0.37782832 -0.3591149\n",
            " -0.40051951 -0.36736531 -0.37838657 -0.36828919 -0.32258364 -0.37122121\n",
            " -0.35891046 -0.35098242 -0.36249195 -0.3643861  -0.35935628 -0.34104544\n",
            " -0.343821   -0.37661587 -0.37151372 -0.38539624 -0.34225316 -0.34052493\n",
            " -0.37070464 -0.34225316 -0.3144087  -0.35838995 -0.35130952 -0.31005665\n",
            " -0.31762929 -0.3691706  -0.38357757 -0.33790583 -0.36825066 -0.32982053\n",
            " -0.37199256 -0.34897427  0.37842561  0.45599742  0.36172584  0.41628409\n",
            "  0.38892634  0.31585989  0.52427622  0.34848885  0.3983428   0.33070246\n",
            "  0.41471074  0.42284322  0.3885615   0.46448922  0.44171626  0.40465504\n",
            "  0.4093216   0.29263796  0.30258831  0.4688334   0.36904766  0.46746371\n",
            "  0.31380928  0.44344134  0.38127742  0.35830238  0.44963642  0.44738216\n",
            "  0.40590601  0.37343036  0.35001816  0.29919315  0.40337184  0.44259451\n",
            "  0.44002339  0.3235033   0.39302757  0.41209716  0.45518754  0.38598487\n",
            "  0.38031502  0.39117509  0.45599742  0.36659448  0.37114074  0.39813758\n",
            "  0.44070824  0.41451182  0.40678664  0.44931484]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435]\n",
            "Epoch - 3 starting.....\n",
            "Predicted Output from the Adaline Model in the 3 th step is as follows: [0.38912482 0.3715975  0.36093879 0.36306246 0.38592154 0.42839336\n",
            " 0.36646709 0.38699633 0.34604903 0.37454759 0.4109302  0.38166457\n",
            " 0.3639148  0.32719854 0.42210761 0.44220833 0.41138474 0.39201556\n",
            " 0.43828981 0.40103376 0.41466847 0.40233582 0.34974509 0.40737615\n",
            " 0.39442104 0.38489377 0.39702998 0.39816893 0.39232809 0.37369526\n",
            " 0.37689853 0.41194565 0.40481027 0.41941341 0.37454759 0.37106251\n",
            " 0.40404049 0.37454759 0.34338556 0.39178829 0.38297145 0.3399475\n",
            " 0.34656292 0.40440014 0.42093312 0.36969629 0.40239517 0.36039899\n",
            " 0.40613825 0.3811555  0.70553721 0.61643148 0.7232917  0.66193866\n",
            " 0.69317854 0.77701657 0.53883208 0.73962332 0.68325608 0.75768302\n",
            " 0.66080932 0.65368753 0.6919072  0.60710075 0.63247388 0.67319391\n",
            " 0.6688591  0.80166087 0.79399176 0.60225686 0.71416232 0.60282267\n",
            " 0.77999258 0.62899621 0.7003856  0.72684094 0.62154078 0.62417833\n",
            " 0.67381417 0.70937778 0.73721303 0.79270683 0.67670491 0.63041697\n",
            " 0.63602572 0.76632924 0.68722652 0.66565582 0.61513422 0.69403568\n",
            " 0.70162831 0.68706071 0.61643148 0.71787467 0.71194857 0.68014027\n",
            " 0.63296175 0.66188412 0.67103951 0.62309873]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38912482 -0.3715975  -0.36093879 -0.36306246 -0.38592154 -0.42839336\n",
            " -0.36646709 -0.38699633 -0.34604903 -0.37454759 -0.4109302  -0.38166457\n",
            " -0.3639148  -0.32719854 -0.42210761 -0.44220833 -0.41138474 -0.39201556\n",
            " -0.43828981 -0.40103376 -0.41466847 -0.40233582 -0.34974509 -0.40737615\n",
            " -0.39442104 -0.38489377 -0.39702998 -0.39816893 -0.39232809 -0.37369526\n",
            " -0.37689853 -0.41194565 -0.40481027 -0.41941341 -0.37454759 -0.37106251\n",
            " -0.40404049 -0.37454759 -0.34338556 -0.39178829 -0.38297145 -0.3399475\n",
            " -0.34656292 -0.40440014 -0.42093312 -0.36969629 -0.40239517 -0.36039899\n",
            " -0.40613825 -0.3811555   0.29446279  0.38356852  0.2767083   0.33806134\n",
            "  0.30682146  0.22298343  0.46116792  0.26037668  0.31674392  0.24231698\n",
            "  0.33919068  0.34631247  0.3080928   0.39289925  0.36752612  0.32680609\n",
            "  0.3311409   0.19833913  0.20600824  0.39774314  0.28583768  0.39717733\n",
            "  0.22000742  0.37100379  0.2996144   0.27315906  0.37845922  0.37582167\n",
            "  0.32618583  0.29062222  0.26278697  0.20729317  0.32329509  0.36958303\n",
            "  0.36397428  0.23367076  0.31277348  0.33434418  0.38486578  0.30596432\n",
            "  0.29837169  0.31293929  0.38356852  0.28212533  0.28805143  0.31985973\n",
            "  0.36703825  0.33811588  0.32896049  0.37690127]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211]\n",
            "Epoch - 4 starting.....\n",
            "Predicted Output from the Adaline Model in the 4 th step is as follows: [0.39359852 0.37694019 0.36518484 0.36861718 0.39013943 0.43455143\n",
            " 0.37111637 0.39219369 0.35129604 0.38000681 0.41577021 0.38732978\n",
            " 0.36892765 0.33016346 0.42483522 0.44638597 0.41520277 0.39676052\n",
            " 0.4445496  0.40577203 0.42127019 0.40754258 0.35138861 0.41481311\n",
            " 0.40184127 0.39146506 0.40335486 0.40328623 0.39705761 0.37969634\n",
            " 0.38315543 0.41791986 0.40847292 0.42274083 0.38000681 0.3748993\n",
            " 0.40816352 0.38000681 0.34785032 0.39704424 0.38707281 0.34612272\n",
            " 0.35063322 0.41107031 0.42828269 0.37525165 0.4074472  0.36517147\n",
            " 0.41091966 0.38596508 0.74425766 0.64914979 0.76140248 0.69720921\n",
            " 0.73062407 0.81951533 0.56736504 0.77957477 0.7207199  0.79692404\n",
            " 0.69322282 0.68792736 0.7275022  0.63984118 0.66635123 0.7075326\n",
            " 0.70346458 0.84349663 0.83963557 0.63440846 0.75113396 0.63432782\n",
            " 0.82325814 0.66056616 0.73650033 0.76438708 0.6522699  0.65503943\n",
            " 0.7101543  0.74560586 0.77652153 0.83236222 0.7133163  0.66214594\n",
            " 0.67068578 0.80650405 0.72313845 0.70000549 0.64535172 0.72890702\n",
            " 0.73836627 0.72071953 0.64914979 0.75595775 0.74914833 0.71446416\n",
            " 0.66578242 0.69527708 0.70545158 0.65501268]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.39359852 -0.37694019 -0.36518484 -0.36861718 -0.39013943 -0.43455143\n",
            " -0.37111637 -0.39219369 -0.35129604 -0.38000681 -0.41577021 -0.38732978\n",
            " -0.36892765 -0.33016346 -0.42483522 -0.44638597 -0.41520277 -0.39676052\n",
            " -0.4445496  -0.40577203 -0.42127019 -0.40754258 -0.35138861 -0.41481311\n",
            " -0.40184127 -0.39146506 -0.40335486 -0.40328623 -0.39705761 -0.37969634\n",
            " -0.38315543 -0.41791986 -0.40847292 -0.42274083 -0.38000681 -0.3748993\n",
            " -0.40816352 -0.38000681 -0.34785032 -0.39704424 -0.38707281 -0.34612272\n",
            " -0.35063322 -0.41107031 -0.42828269 -0.37525165 -0.4074472  -0.36517147\n",
            " -0.41091966 -0.38596508  0.25574234  0.35085021  0.23859752  0.30279079\n",
            "  0.26937593  0.18048467  0.43263496  0.22042523  0.2792801   0.20307596\n",
            "  0.30677718  0.31207264  0.2724978   0.36015882  0.33364877  0.2924674\n",
            "  0.29653542  0.15650337  0.16036443  0.36559154  0.24886604  0.36567218\n",
            "  0.17674186  0.33943384  0.26349967  0.23561292  0.3477301   0.34496057\n",
            "  0.2898457   0.25439414  0.22347847  0.16763778  0.2866837   0.33785406\n",
            "  0.32931422  0.19349595  0.27686155  0.29999451  0.35464828  0.27109298\n",
            "  0.26163373  0.27928047  0.35085021  0.24404225  0.25085167  0.28553584\n",
            "  0.33421758  0.30472292  0.29454842  0.34498732]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Adaline - Learning rate 0.01')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABixklEQVR4nO3dd3gU1f4G8Hc2ZTe9kUpCgCSU0GtIFEKvFwURUECKIoIBgaAIv0sRG3IvVUGaCldAEaVYUDohNOmB0EICSQgxhYT0SrLz+yOysqSQDbuZ3c37eZ59Hnb2zO47O+h+OXPmHEEURRFERERERkImdQAiIiIibWJxQ0REREaFxQ0REREZFRY3REREZFRY3BAREZFRYXFDRERERoXFDRERERkVFjdERERkVFjcEBERkVFhcUOkRZs3b4YgCIiLi9N43/Hjx6Nhw4Zq2wRBwAcffKCVbFRe9+7d0b17d6ljEJGWsbghqsCXX34JQRAQEBAgdRS9FxYWBkEQ8NNPP0kdpc759NNPsWfPHp2896lTp/D888/D0tISbm5ueOedd5Cbm1vt/b/++ms0b94cCoUCfn5++OKLL8q1iYqKwsyZMxEUFASFQlHjfxgQPYnFDVEFtm3bhoYNG+Ls2bOIiYmRLEdBQQHmzZsn2ecbuwMHDuDAgQNSx6gxXRU3ERER6NWrF/Lz87F8+XJMnDgRGzZswPDhw6u1//r16zFx4kS0aNECX3zxBQIDA/HOO+9gyZIlau1Onz6Nzz//HDk5OWjevLnWj4PqLlOpAxDpm9jYWJw6dQq7du3CW2+9hW3btmHhwoWSZFEoFJJ8riFSKpUoLi7W6DszNzfXYSLN1CS/rvzf//0fHBwcEBYWBltbWwBAw4YN8eabb+LAgQPo27dvpfsWFBTg3//+NwYNGqTqzXvzzTehVCrx0UcfYdKkSXBwcAAAvPDCC8jMzISNjQ2WLl2KiIgInR8b1Q3suSF6wrZt2+Dg4IBBgwbh5ZdfxrZt2ypsd+3aNfTs2RMWFhbw9PTExx9/DKVSWa7dzz//jEGDBsHDwwNyuRw+Pj746KOPUFpa+tQsT465+eCDDyAIAmJiYjB+/HjY29vDzs4OEyZMQH5+frn9t27dig4dOsDCwgKOjo545ZVXkJCQUP0vQ4syMzMxY8YMeHl5QS6Xw9fXF0uWLCn3nS1duhRBQUFwcnKChYUFOnToUOElL0EQMHXqVGzbtg0tWrSAXC7Hvn37VOOeTp48idDQUDg7O8PKygpDhw7F/fv31d7jyTE3jy6x7dixA5988gk8PT2hUCjQq1evCnvw1qxZg8aNG8PCwgKdO3fG8ePHqz2Op7L81f0OBEFAXl4e/ve//0EQBAiCgPHjx6teT0xMxOuvvw5XV1fI5XK0aNEC33zzzVNzZWdn4+DBgxgzZoyqsAGAsWPHwtraGjt27Khy/6NHjyI9PR1vv/222vaQkBDk5eVh7969qm2Ojo6wsbF5aiYiTbHnhugJ27Ztw0svvQRzc3O8+uqrWLt2Lc6dO4dOnTqp2iQnJ6NHjx4oKSnBnDlzYGVlhQ0bNsDCwqLc+23evBnW1tYIDQ2FtbU1jhw5ggULFiA7Oxv//e9/a5RxxIgRaNSoERYvXoyLFy/iq6++gouLi1q3/yeffIL58+djxIgRmDhxIu7fv48vvvgC3bp1w6VLl2Bvb1+jz66J/Px8BAcHIzExEW+99RYaNGiAU6dOYe7cuUhKSsLKlStVbVetWoUXXngBo0ePRnFxMbZv347hw4fjt99+w6BBg9Te98iRI9ixYwemTp2KevXqoWHDhqp//U+bNg0ODg5YuHAh4uLisHLlSkydOhU//PDDU/N+9tlnkMlkePfdd5GVlYX//Oc/GD16NM6cOaNqs3btWkydOhVdu3bFzJkzERcXhyFDhsDBwQGenp7V+l4qyl/d72DLli2YOHEiOnfujEmTJgEAfHx8AAApKSno0qWLqoBydnbGH3/8gTfeeAPZ2dmYMWNGpZkiIyNRUlKCjh07qm03NzdH27ZtcenSpSqP6dHrT+7foUMHyGQyXLp0CWPGjKnW90NUYyIRqZw/f14EIB48eFAURVFUKpWip6enOH36dLV2M2bMEAGIZ86cUW1LTU0V7ezsRABibGysant+fn65z3nrrbdES0tLsbCwULVt3Lhxore3t1o7AOLChQtVzxcuXCgCEF9//XW1dkOHDhWdnJxUz+Pi4kQTExPxk08+UWsXGRkpmpqaltv+LI4ePSoCEH/88cdK23z00UeilZWVeOvWLbXtc+bMEU1MTMS7d++qtj35fRUXF4stW7YUe/bsqbYdgCiTycRr166pbd+0aZMIQOzdu7eoVCpV22fOnCmamJiImZmZqm3BwcFicHBwuWNp3ry5WFRUpNq+atUqEYAYGRkpiqIoFhUViU5OTmKnTp3Ehw8fqtpt3rxZBKD2npWpLL8m34GVlZU4bty4cvu/8cYboru7u5iWlqa2/ZVXXhHt7Owq/Dv5yI8//igCEMPDw8u9Nnz4cNHNza2qwxJDQkJEExOTCl9zdnYWX3nllQpf++9//1vuvx2imuJlKaLHbNu2Da6urujRoweAsq7/kSNHYvv27WqXkX7//Xd06dIFnTt3Vm1zdnbG6NGjy73n4705OTk5SEtLQ9euXZGfn4+bN2/WKOfkyZPVnnft2hXp6enIzs4GAOzatQtKpRIjRoxAWlqa6uHm5gY/Pz8cPXq0Rp9bUz/++CO6du0KBwcHtTy9e/dGaWkpwsPDVW0f/74yMjKQlZWFrl274uLFi+XeNzg4GP7+/hV+5qRJkyAIgup5165dUVpaivj4+KfmnTBhgtp4nK5duwIA7ty5AwA4f/480tPT8eabb8LU9J8O8NGjR6vGk1RHZfk1+Q6eJIoidu7cicGDB0MURbXvu1+/fsjKyqryfQoKCgAAcrm83GsKhUL1elX7VzaWqTr7E2kDL0sR/a20tBTbt29Hjx49EBsbq9oeEBCAZcuW4fDhw6qBlPHx8RXeJt60adNy265du4Z58+bhyJEjquLjkaysrBplbdCggdrzRz+oGRkZsLW1RXR0NERRhJ+fX4X7m5mZVfrexcXFePDggdo2Z2dnmJiY1CgrAERHR+PKlStwdnau8PXU1FTVn3/77Td8/PHHiIiIQFFRkWr744XKI40aNar0M6v6jp7mafs+KpB8fX3V2pmampabq6gqleXX5Dt40v3795GZmYkNGzZgw4YNFbZ5/Pt+0qPC6vHPfaSwsLDCS69P7l9cXFzha9XZn0gbWNwQ/e3IkSNISkrC9u3bsX379nKvb9u2rcq7RCqSmZmJ4OBg2Nra4sMPP4SPjw8UCgUuXryI999/v8IByNVRWaEhiiKAsjtvBEHAH3/8UWFba2vrSt/71KlTqp6rR2JjYzX60X6SUqlEnz59MHv27Apfb9KkCQDg+PHjeOGFF9CtWzd8+eWXcHd3h5mZGTZt2oTvvvuu3H5V/VA+7TuqyrPsq4mK8mv6HTzp0d+pMWPGYNy4cRW2ad26daX7u7u7AwCSkpLKvZaUlAQPD48qP9/d3R2lpaVITU2Fi4uLantxcTHS09Ofuj+RNrC4Ifrbtm3b4OLigjVr1pR7bdeuXdi9ezfWrVsHCwsLeHt7Izo6uly7qKgotedhYWFIT0/Hrl270K1bN9X2x3uGdMHHxweiKKJRo0aqwqG62rRpg4MHD6ptc3Nze+Y8ubm56N27d5Xtdu7cCYVCgf3796tdFtm0adMzfb62eXt7AwBiYmLUCsGSkhLExcVVWTw8jSbfQUU9Oc7OzrCxsUFpaelTv++KtGzZEqampjh//jxGjBih2l5cXIyIiAi1bRVp27YtgLJLdwMHDlRtP3/+PJRKpep1Il3imBsilI0T2LVrF/71r3/h5ZdfLveYOnUqcnJy8MsvvwAABg4ciD///BNnz55Vvcf9+/fL3Tb+qAfg8X/xFxcX48svv9Tp8bz00kswMTHBokWLyvU2iKKI9PT0Svd1cHBA79691R7POvfKiBEjcPr0aezfv7/ca5mZmSgpKQFQ9n0JgqA2vikuLk5ns/DWVMeOHeHk5ISNGzeqsgNlBXJ1LntVRZPvwMrKCpmZmeX2HzZsGHbu3ImrV6+W2+fJ2+GfZGdnh969e2Pr1q3IyclRbd+yZQtyc3PVJvJ7NG4sLS1Nta1nz55wdHTE2rVr1d537dq1sLS0LHfHG5EusOeGCMAvv/yCnJwcvPDCCxW+3qVLFzg7O2Pbtm0YOXIkZs+ejS1btqB///6YPn266lZwb29vXLlyRbVfUFAQHBwcMG7cOLzzzjsQBAFbtmzR+uWNJ/n4+ODjjz/G3LlzVbco29jYIDY2Frt378akSZPw7rvvavUzd+7cWeEA6XHjxuG9997DL7/8gn/9618YP348OnTogLy8PERGRuKnn35CXFwc6tWrh0GDBmH58uXo378/Ro0ahdTUVKxZswa+vr5q36vUzM3N8cEHH2DatGno2bMnRowYgbi4OGzevBk+Pj7VGhtTGU2+gw4dOuDQoUNYvnw5PDw80KhRIwQEBOCzzz7D0aNHERAQgDfffBP+/v548OABLl68iEOHDpUbU/WkTz75BEFBQQgODsakSZNw7949LFu2DH379kX//v1V7c6ePYsePXpg4cKFqvmYLCws8NFHHyEkJATDhw9Hv379cPz4cWzduhWffPIJHB0dVftnZWWplmU4efIkAGD16tWwt7eHvb09pk6dWuPvkeo4ie7SItIrgwcPFhUKhZiXl1dpm/Hjx4tmZmaq22uvXLkiBgcHiwqFQqxfv7740UcfiV9//XW521lPnjwpdunSRbSwsBA9PDzE2bNni/v37xcBiEePHlW10+RW8Pv376u1e3T785O30e7cuVN8/vnnRSsrK9HKykps1qyZGBISIkZFRWn0/VTl0e3TlT2OHz8uiqIo5uTkiHPnzhV9fX1Fc3NzsV69emJQUJC4dOlSsbi4WPV+X3/9tejn5yfK5XKxWbNm4qZNm1TH/eR3ExISUi7Po+/i3LlzFeZ8/Duv7FbwJ29rj42NFQGImzZtUtv++eefi97e3qJcLhc7d+4snjx5UuzQoYPYv3//p35vleXX5Du4efOm2K1bN9HCwkIEoHZbeEpKihgSEiJ6eXmJZmZmopubm9irVy9xw4YNT80miqJ4/PhxMSgoSFQoFKKzs7MYEhIiZmdnq7V59H09/nf0kQ0bNohNmzYVzc3NRR8fH3HFihVqt+aL4j/fa0WPJ/9bINKEIIo6/ickEVEdoVQq4ezsjJdeegkbN26UOg5RncUxN0RENVBYWFju8uK3336LBw8eVGv5BSLSHfbcEBHVQFhYGGbOnInhw4fDyckJFy9exNdff43mzZvjwoULerUoJ1FdwwHFREQ10LBhQ3h5eeHzzz/HgwcP4OjoiLFjx+Kzzz5jYUMkMfbcEBERkVGRdMxNeHg4Bg8eDA8PDwiC8NS5LMLCwiAIQrlHcnJy7QQmIiIivSdpcZOXl4c2bdpUOCNsVaKiopCUlKR6PD7FNxEREdVtko65GTBgAAYMGKDxfi4uLrC3t6/RZyqVSvz111+wsbF5pom2iIiIqPaIooicnBx4eHhAJqu6b8YgBxS3bdsWRUVFaNmyJT744AM899xzlbYtKipSW902MTER/v7+tRGTiIiItCwhIQGenp5VtjGo4sbd3R3r1q1Dx44dUVRUhK+++grdu3fHmTNn0L59+wr3Wbx4MRYtWlRue0JCAmxtbXUdmYiIiLQgOzsbXl5esLGxeWpbvblbShAE7N69G0OGDNFov+DgYDRo0ABbtmyp8PUne24efTlZWVksboiIiAxEdnY27OzsqvX7bVA9NxXp3LkzTpw4Uenrcrkccrm8FhMRERGRlAx++YWIiAi4u7tLHYOIiIj0hKQ9N7m5uYiJiVE9j42NRUREBBwdHdGgQQPMnTsXiYmJ+PbbbwEAK1euRKNGjdCiRQsUFhbiq6++wpEjR3DgwAGpDoGIiIj0jKTFzfnz59GjRw/V89DQUADAuHHjsHnzZiQlJeHu3buq14uLizFr1iwkJibC0tISrVu3xqFDh9Teg4iIiOo2vRlQXFs0GZBERERE+kGT32+DH3NDRERE9DgWN0RERGRUWNwQERGRUWFxQ0REREbF4Cfx0xelShFnYx8gNacQLjYKdG7kCBMZF+YkIiKqbSxutGDf1SQs+vU6krIKVdvc7RRYONgf/VtygkEiIqLaxMtSz2jf1SRM2XpRrbABgOSsQkzZehH7riZJlIyIiKhuYnHzDEqVIhb9eh0VTRT0aNuiX6+jVFmnphIiIiKSFIubZ3A29kG5HpvHiQCSsgpxNvZB7YUiIiKq41jcPIPUnMoLm5q0IyIiomfH4uYZuNgotNqOiIiInh2Lm2fQuZEj3O0UqOyGbwFld011buRYm7GIiIjqNBY3z8BEJmDhYH8AqLTAWTjYn/PdEBER1SIWN8+of0t3rB3THm525S89vdjWg/PcEBER1TJO4qcF/Vu6o4+/m2qG4lspOVhz9DaORt1HduFD2CrMpI5IRERUZ7C40RITmYBAHycAZfPf7L+WgpjUXHxzIhYzejeROB0REVHdwctSOmAiEzCjtx8A4OvjscjML5Y4ERERUd3B4kZHBrZ0RzM3G+QUlWBD+B2p4xAREdUZLG50RCYTENqn7HLU5lNxSMstkjgRERFR3cDiRof6+Luitacd8otLsS7sttRxiIiI6gQWNzokCP/03mz5Mx4p2VyGgYiISNdY3OhYcBNndPR2QFGJEmuOxkgdh4iIyOixuNExQRAQ2res92b72QQkZhZInIiIiMi4sbipBUE+9RDk44TiUiVWH4mWOg4REZFRY3FTS2b93Xuz4/w9xKfnSZyGiIjIeLG4qSUdvB3RvakzSpUiVh1m7w0REZGusLipRY/unNpzKRExqbkSpyEiIjJOLG5qUWtPe/Txd4VSBFYeuiV1HCIiIqPE4qaWPeq9+e1KEm4kZUuchoiIyPiwuKllzd1tMai1OwBgxUH23hAREWkbixsJzOztB5kAHLiegiv3MqWOQ0REZFRY3EjA18UGQ9rWBwAsZ+8NERGRVrG4kcj03n4wkQkIi7qPC/EPpI5DRERkNFjcSMTbyQrDO3gCAJYdYO8NERGRtrC4kdC0Xn4wN5Hh1O10nLqdJnUcIiIio8DiRkL17S3wSmcvAMDyA7cgiqLEiYiIiAwfixuJhfTwhdxUhvPxGQiPZu8NERHRs5K0uAkPD8fgwYPh4eEBQRCwZ8+eau978uRJmJqaom3btjrLVxtcbRV4rYs3AGDZgSj23hARET0jSYubvLw8tGnTBmvWrNFov8zMTIwdOxa9evXSUbLaNbm7DyzNTXDlXhYO3UiVOg4REZFBk7S4GTBgAD7++GMMHTpUo/0mT56MUaNGITAwUEfJalc9aznGBzUEUNZ7o1Sy94aIiKimDG7MzaZNm3Dnzh0sXLiwWu2LioqQnZ2t9tBHk7o1ho3cFDeTc/DH1WSp4xARERksgypuoqOjMWfOHGzduhWmpqbV2mfx4sWws7NTPby8vHScsmbsLc3xRtdGAIAVh26hlL03RERENWIwxU1paSlGjRqFRYsWoUmTJtXeb+7cucjKylI9EhISdJjy2bz+fCPYWZghJjUXv1xOlDoOERGRQTKY4iYnJwfnz5/H1KlTYWpqClNTU3z44Ye4fPkyTE1NceTIkQr3k8vlsLW1VXvoK1uFGd4KbgwAWHkoGg9LlRInIiIiMjwGU9zY2toiMjISERERqsfkyZPRtGlTREREICAgQOqIWjEusCGcrMwRn56PXRfvSR2HiIjI4FRv4IqO5ObmIiYmRvU8NjYWERERcHR0RIMGDTB37lwkJibi22+/hUwmQ8uWLdX2d3FxgUKhKLfdkFnJTTGluw8+3nsDnx+OwZB29SE3NZE6FhERkcGQtOfm/PnzaNeuHdq1awcACA0NRbt27bBgwQIAQFJSEu7evStlREmM6eINV1s5EjMLsOOc/o4RIiIi0keCWMemxM3OzoadnR2ysrL0evzNltNxmP/zNbjaynHsvR5QmLH3hoiI6i5Nfr8NZsxNXTOikxfq21sgJbsIW/+MlzoOERGRwWBxo6fkpiZ4p5cvAGDdsdvIKyqROBEREZFhYHGjx15q7wlvJ0uk5Rbjf6fjpI5DRERkEFjc6DEzExmm9/IDAKw/dgfZhQ8lTkRERKT/WNzouRfb1oePsxWyCh7imxOxUschIiLSeyxu9JyJTMDMPmXLTXx9PBaZ+cUSJyIiItJvLG4MwMCW7mjmZoOcohJsCL8jdRwiIiK9xuLGAMhkAkL/7r3ZfCoOablFEiciIiLSXyxuDEQff1e09rRDfnEp1oXdljoOERGR3mJxYyAE4Z/emy1/xiMlu1DiRERERPqJxY0BCW7ijI7eDigqUeLLozFP34GIiKgOYnFjQARBQGjfst6b788mIDGzQOJERERE+ofFjYEJ8qmHIB8nFJcqsfpItNRxiIiI9A6LGwM06+/emx3n7yE+PU/iNERERPqFxY0B6uDtiOAmzihVilh1mL03REREj2NxY6Ae9d7suZSImNRcidMQERHpDxY3Bqq1pz36+LtCKQIrD92SOg4REZHeYHFjwB7Ne/PblSTcSMqWOA0REZF+YHFjwJq722JQa3cAwIqD7L0hIiICWNwYvJm9/SATgAPXU3DlXqbUcYiIiCTH4sbA+brYYEjb+gCA5ey9ISIiYnFjDKb39oOJTEBY1H1ciH8gdRwiIiJJsbgxAt5OVhjewRMAsOwAe2+IiKhuY3FjJKb18oO5iQynbqfj1O00qeMQERFJhsWNkahvb4FXOnsBAJYfuAVRFCVOREREJA0WN0YkpIcv5KYynI/PQHg0e2+IiKhuYnFjRFxtFXitizcAYNmBKPbeEBFRncTixshM7u4DS3MTXLmXhUM3UqWOQ0REVOtY3BiZetZyjA9qCKCs90apZO8NERHVLSxujNCkbo1hIzfFzeQc/HE1Weo4REREtYrFjRGytzTHG10bAQBWHLqFUvbeEBFRHcLixki9/nwj2FmYISY1F79cTpQ6DhERUa1hcWOkbBVmeCu4MQBg1aFoPCxVSpyIiIiodrC4MWLjAhvCycoccen52HXxntRxiIiIagWLGyNmJTfFlO4+AIDPD8egqKRU4kRERES6x+LGyI3p4g1XWzkSMwuw41yC1HGIiIh0jsWNkVOYmWBqD18AwOqjMSh8yN4bIiIybixu6oARnbxQ394CKdlF2PpnvNRxiIiIdErS4iY8PByDBw+Gh4cHBEHAnj17qmx/4sQJPPfcc3BycoKFhQWaNWuGFStW1E5YAyY3NcG0nmW9N+uO3UZeUYnEiYiIiHRH0uImLy8Pbdq0wZo1a6rV3srKClOnTkV4eDhu3LiBefPmYd68ediwYYOOkxq+YR084e1kibTcYvzvdJzUcYiIiHRGEPVk6WhBELB7924MGTJEo/1eeuklWFlZYcuWLdVqn52dDTs7O2RlZcHW1rYGSQ3Xrov3ELrjMuwszHD8/R6wVZhJHYmIiKhaNPn9NugxN5cuXcKpU6cQHBxcaZuioiJkZ2erPeqqF9vWh4+zFbIKHuKbE7FSxyEiItIJgyxuPD09IZfL0bFjR4SEhGDixImVtl28eDHs7OxUDy8vr1pMql9MZAJm9mkCAPj6eCwy84slTkRERKR9BlncHD9+HOfPn8e6deuwcuVKfP/995W2nTt3LrKyslSPhIS6PdfLwJbuaOZmg5yiEmw8fkfqOERERFpnKnWAmmjUqGzF61atWiElJQUffPABXn311QrbyuVyyOXy2oyn12QyAaF9mmDSlgvYdDIOrz/XCE7W/H6IiMh4GGTPzeOUSiWKioqkjmFQ+vi7orWnHfKLS7Hu2G2p4xAREWmVpMVNbm4uIiIiEBERAQCIjY1FREQE7t69C6DsktLYsWNV7desWYNff/0V0dHRiI6Oxtdff42lS5dizJgxUsQ3WIJQ1nsDAN+ejkdKdqHEiYiIiLRH48tSsbGxOH78OOLj45Gfnw9nZ2e0a9cOgYGBUCgUGr3X+fPn0aNHD9Xz0NBQAMC4ceOwefNmJCUlqQodoKyXZu7cuYiNjYWpqSl8fHywZMkSvPXWW5oeRp0X3MQZHb0dcD4+A18ejcGiF1tKHYmIiEgrqj3PzbZt27Bq1SqcP38erq6u8PDwgIWFBR48eIDbt29DoVBg9OjReP/99+Ht7a3r3DVWl+e5edKp22kYtfEMzE1kOPped9S3t5A6EhERUYW0Ps9Nu3bt8Pnnn2P8+PGIj49HUlISLly4gBMnTuD69evIzs7Gzz//DKVSiY4dO+LHH3/UyoGQbgX51ENgYycUlyqx+ki01HGIiIi0olo9N/v370e/fv2q9Ybp6emIi4tDhw4dnjmcLrDnRt35uAd4ed1pmMgEHJkVDG8nK6kjERERlaP1nptHhU1JSQm+/fZbpKSkVNrWyclJbwsbKq9jQ0cEN3FGqVLEqsPsvSEiIsOn0d1SpqammDx5MgoLeXeNMZnVt+zOqT2XEhGTmitxGiIiomej8a3gnTt3Vt26Tcahtac9+vi7QikCKw/dkjoOERHRM9H4VvC3334boaGhSEhIQIcOHWBlpT5Go3Xr1loLR7UntE8THLyegt+uJCGkRzaau3M8EhERGaZq3wr+iExWvrNHEASIoghBEFBaWqq1cLrAAcWVC/nuIvZeSUJff1dsGNtR6jhEREQqmvx+12gSPzJOM3v74Y/IJBy4noLIe1lo5WkndSQiIiKNaVzc6PMEffRsfF1sMKRtfey6lIhlB6OweUJnqSMRERFprEZrS92+fRvTpk1D79690bt3b7zzzju4fZsLMBqD6b39YCITEBZ1HxfiH0gdh4iISGMaFzf79++Hv78/zp49i9atW6N169Y4c+YMWrRogYMHD+oiI9UibycrDO/gCQBYdoB3ThERkeHReEBxu3bt0K9fP3z22Wdq2+fMmYMDBw7g4sWLWg2obRxQ/HT3MvLRY2kYHpaK+O7NAAT51JM6EhER1XFan6H4cTdu3MAbb7xRbvvrr7+O69eva/p2pIc8HSzxaucGAIDlB25Bw/qXiIhIUhoXN87OzhVO4hcREQEXFxdtZCI9ENLDF3JTGc7HZyA8Ok3qOERERNWm8d1Sb775JiZNmoQ7d+4gKCgIAHDy5EksWbIEoaGhWg9I0nC1VeC1Lt746kQslh2IQje/ehAEQepYRERET6XxmBtRFLFy5UosW7YMf/31FwDAw8MD7733Ht555x29/wHkmJvqS8stQrf/HEV+cSk2ju2IPv6uUkciIqI6SmdjbkpKSrBlyxaMGjUK9+7dQ1ZWFrKysnDv3j1Mnz5d7wsb0kw9aznGBzUEACw7EAWlkmNviIhI/z3TquA2NjawsbHRSTDSD5O6NYaN3BQ3k3Pwx9VkqeMQERE9VY1WBb906ZIuspAesrc0xxtdGwEAVhy6hVL23hARkZ6r0args2bNwr1797gqeB3x+vONsOlkHGJSc/HL5UQMbecpdSQiIqJKcVVwqpYvw2Lwn31RaOhkiYOhwTAzqdHKHURERDXCVcFJ68YFNsTXx2MRl56PXRfvYWSnBlJHIiIiqpBG//x++PAhevbsifz8fHh7e1f4IONkJTfFlO4+AIDPD8egqES/e+iIiKju0qi4MTMzU90pRXXPmC7ecLGRIzGzADvOJUgdh4iIqEIaD5wICQnBkiVLUFJSoos8pMcUZiaY2tMXALD6aAwKH7L3hoiI9I/GY27OnTuHw4cP48CBA2jVqlW5u6V27dqltXCkf0Z28sL6Y3eQmFmArX/GY2LXxlJHIiIiUqNxcWNvb49hw4bpIgsZALmpCab19MWcXZFYd+w2Xu3cAFZyjf8aERER6YzGt4IbOt4K/uwelirRe/kxxKfnY3b/pni7u6/UkYiIyMjpbG2pR0pKSnDo0CGsX78eOTk5AIC//voLubm5NXk7MjBmJjJM7+UHANgQfgc5hQ8lTkRERPQPjYub+Ph4tGrVCi+++CJCQkJw//59AMCSJUvw7rvvaj0g6acX29aHj7MVMvMf4psTcVLHISIiUtG4uJk+fTo6duyIjIwMWFhYqLYPHToUhw8f1mo40l8mMgEz+zQBAHx1/A4y84slTkRERFRG4+Lm+PHjmDdvHszNzdW2N2zYEImJiVoLRvpvYEt3NHOzQU5RCTYevyN1HCIiIgA1KG6USmWF60fdu3cPNjY2WglFhkEmExD6d+/NppNxSM8tkjgRERFRDYqbvn37YuXKlarngiAgNzcXCxcuxMCBA7WZjQxAH39XtPa0Q35xKdYduy11HCIiIs2Lm2XLluHkyZPw9/dHYWEhRo0apboktWTJEl1kJD0mCP/03nx7Oh4p2Vyeg4iIpFWjeW5KSkrwww8/4PLly8jNzUX79u0xevRotQHG+orz3GifKIp4ed1pXIjPwLhAbyx6saXUkYiIyMho8vvNSfxIK07dTsOojWdgbiLD0fe6o769/he6RERkOHQ+iZ+2hIeHY/DgwfDw8IAgCNizZ0+V7Xft2oU+ffrA2dkZtra2CAwMxP79+2snLFUpyKceAhs7obhUidVHoqWOQ0REdZikxU1eXh7atGmDNWvWVKt9eHg4+vTpg99//x0XLlxAjx49MHjwYFy6dEnHSak6ZvUtG3uz4/w9xKfnSZyGiIjqKr25LCUIAnbv3o0hQ4ZotF+LFi0wcuRILFiwoFrteVlKt8Z9cxbHbt3HS+3rY/mItlLHISIiI2Ewl6WelVKpRE5ODhwdHaWOQn971Huz51IiYlK51hgREdU+gy5uli5ditzcXIwYMaLSNkVFRcjOzlZ7kO609rRHH39XKEVg5aFbUschIqI6yLQ6jRwcHCAIQrXe8MGDB88UqLq+++47LFq0CD///DNcXFwqbbd48WIsWrSoVjJRmdA+TXDwegp+u5KEkB7ZaO7Oy39ERFR7qlXcPD4jcXp6Oj7++GP069cPgYGBAIDTp09j//79mD9/vk5CPmn79u2YOHEifvzxR/Tu3bvKtnPnzkVoaKjqeXZ2Nry8vHQdsU5r7m6LQa3dsfdKElYcvIUNYztKHYmIiOoQjQcUDxs2DD169MDUqVPVtq9evRqHDh166u3clQap5oDi77//Hq+//jq2b9+OF198UePP4YDi2hGTmoO+K8KhFIFfpz6PVp52UkciIiIDptMBxfv370f//v3Lbe/fvz8OHTqk0Xvl5uYiIiICERERAIDY2FhERETg7t27AMp6XcaOHatq/91332Hs2LFYtmwZAgICkJycjOTkZGRlZWl6GKRjvi42GNK2PgBg2cEoidMQEVFdonFx4+TkhJ9//rnc9p9//hlOTk4avdf58+fRrl07tGvXDgAQGhqKdu3aqW7rTkpKUhU6ALBhwwaUlJQgJCQE7u7uqsf06dM1PQyqBe/08oOJTEBY1H1ciK+dsVhEREQaX5bavHkzJk6ciAEDBiAgIAAAcObMGezbtw8bN27E+PHjdZFTa3hZqnbN2XkF288lIMjHCd+92UXqOEREZKB0ellq/PjxOHnyJGxtbbFr1y7s2rULtra2OHHihN4XNlT7pvb0hZmJgFO303HqdprUcYiIqA7QmxmKawt7bmrfgp+v4tvT8ejo7YAfJwdWe1oBIiKiR3Q+Q/Ht27cxb948jBo1CqmpqQCAP/74A9euXavJ25GRC+nhC7mpDOfjMxAezd4bIiLSLY2Lm2PHjqFVq1Y4c+YMdu7cidzcsin2L1++jIULF2o9IBk+V1sFXuviDQBYfiAKdayzkIiIapnGxc2cOXPw8ccf4+DBgzA3N1dt79mzJ/7880+thiPjMbm7DyzNTXD5XhYO3UiVOg4RERkxjYubyMhIDB06tNx2FxcXpKXxkgNVrJ61HOODGgIAlh+8BaWSvTdERKQbGhc39vb2SEpKKrf90qVLqF+/vlZCkXGa1K0xbOSmuJGUjT+uJksdh4iIjJTGxc0rr7yC999/H8nJyRAEAUqlEidPnsS7776rNpsw0ZPsLc3xRtdGAIAVh26hlL03RESkAxoXN59++imaNWsGLy8v5Obmwt/fH926dUNQUBDmzZuni4xkRF5/vhHsLMwQk5qLXy4nSh2HiIiMkEbz3IiiiISEBDg7OyMtLQ2RkZHIzc1Fu3bt4Ofnp8ucWsN5bqS35mgM/rs/Cg2dLHEwNBhmJjWakYCIiOoQTX6/TTV5Y1EU4evri2vXrsHPzw9eXl7PFJTqpvFBDfHNiVjEpedj18V7GNmpgdSRiIjIiGj0T2aZTAY/Pz+kp6frKg/VAVZyU0zp7gMA+PxwDIpKSiVORERExkTj6wGfffYZ3nvvPVy9elUXeaiOGNPFGy42ciRmFmDHuQSp4xARkRHRuLgZO3Yszp49izZt2sDCwgKOjo5qD6LqUJiZYGpPXwDA6qMxKHzI3hsiItIOjcbcAMDKlSt1EIPqopGdvLD+2B0kZhZg25m7eOP5RlJHIiIiI8BVwUlS28/exZxdkahnbY7w2T1gaa5xvU1ERHWAzlcFf6SwsBDZ2dlqDyJNDOvgCW8nS6TlFuN/p+KljkNEREZA4+ImLy8PU6dOhYuLC6ysrODg4KD2INKEmYkM03uVzZG0Pvw2cgofSpyIiIgMncbFzezZs3HkyBGsXbsWcrkcX331FRYtWgQPDw98++23ushIRu7FtvXh42yFzPyH+OZEnNRxiIjIwGlc3Pz666/48ssvMWzYMJiamqJr166YN28ePv30U2zbtk0XGcnImcgEzOzTBADw1fE7yMwvljgREREZMo2LmwcPHqBx48YAAFtbWzx48AAA8PzzzyM8PFy76ajOGNjSHc3cbJBTVIKNx+9IHYeIiAyYxsVN48aNERsbCwBo1qwZduzYAaCsR8fe3l6r4ajukMkEhP7de7PpZBzSc4skTkRERIZK4+JmwoQJuHz5MgBgzpw5WLNmDRQKBWbOnIn33ntP6wGp7ujj74rWnnbILy7FumO3pY5DREQG6pnnuYmPj8eFCxfg6+uL1q1bayuXznCeG/0WFpWK8ZvOQW4qQ/jsHnC1VUgdiYiI9ECtzXMDAN7e3njppZcMorAh/RfcxBkdvB1QVKLEl0djpI5DREQGSOPpYD/88MMqX1+wYEGNwxAJgoBZfZtg1MYz+P5sAiYF+6C+vYXUsYiIyIBoXNzs3r1b7fnDhw8RGxsLU1NT+Pj4sLihZxbkUw+BjZ1w+k46Vh+JxuKX2CtIRETVp3Fxc+nSpXLbsrOzMX78eAwdOlQroYhm9W2Cl9edxo/n72FysA+8naykjkRERAbimcfcAGXz3SxatAjz58/XxtsRoWNDRwQ3cUaJUsSqw9FSxyEiIgOileIGALKyspCVlaWttyPCrL5l897suZSImNRcidMQEZGh0Piy1Oeff672XBRFJCUlYcuWLRgwYIDWghG19rRHH39XHLyegpWHbmH1qPZSRyIiIgOg8Tw3jRo1Unsuk8ng7OyMnj17Yu7cubCxsdFqQG3jPDeG5UZSNgasOg4A+GN6VzR35zkjIqqLNPn91rjn5tHSC0S1obm7LQa1dsfeK0lYcfAWNoztKHUkIiLSc1obc0OkKzN7+0EmAAeupyDyHsd1ERFR1TTuuRk6dCgEQahW2127dmkciOhJvi42GNK2PnZdSsSyg1HYPKGz1JGIiEiPadxzY2dnh8OHD+P8+fOqbRcuXMCRI0dga2sLOzs71YNIW97p5QcTmYCwqPu4EJ8hdRwiItJjGvfcuLq6YsSIEVi3bh1MTEwAAKWlpXj77bdha2uL//73v1oPSdSwnhWGd/DE9nMJWH4wCtsmdpE6EhER6SmN75ZydnbGiRMn0LRpU7XtUVFRCAoKQnp6ulYDahvvljJc9zLy0WNpGB6Wivj+zS4I9HGSOhIREdUSna4KXlJSgps3b5bbfvPmTSiVSo3eKzw8HIMHD4aHhwcEQcCePXuqbJ+UlIRRo0ahSZMmkMlkmDFjhkafR4bN08ESr3ZuAABYfjAKGtblRERUR2hc3EyYMAFvvPEGli9fjhMnTuDEiRNYtmwZJk6ciAkTJmj0Xnl5eWjTpg3WrFlTrfZFRUVwdnbGvHnz0KZNG02jkxEI6eELuakM5+IyEB6dJnUcIiLSQxqPuVm6dCnc3NywbNkyJCUlAQDc3d3x3nvvYdasWRq914ABAzSa1bhhw4ZYtWoVAOCbb77R6LPIOLjaKvBaF298dSIWyw9EoZtfvWrfvUdERHWDxj03MpkMs2fPRmJiIjIzM5GZmYnExETMnj1bNcBYnxQVFSE7O1vtQYZtcncfWJqb4PK9LBy6kSp1HCIi0jMaFzcFBQXIz88HULYaeEZGBlauXIkDBw5oPZw2LF68WO32dC8vL6kj0TOqZy3H+KCGAIDlB29BqeTYGyIi+ofGxc2LL76Ib7/9FgCQmZmJzp07Y9myZXjxxRexdu1arQd8VnPnzlWtWJ6VlYWEhASpI5EWTOrWGDZyU9xIysYfV5OljkNERHpE4+Lm4sWL6Nq1KwDgp59+gpubG+Lj4/Htt9+WWzFcH8jlctja2qo9yPDZW5rj9efLFnFdcegWStl7Q0REf9O4uMnPz1et/H3gwAG89NJLkMlk6NKlC+Lj47UekKgyb3RtBDsLM8Sk5uKXy4lSxyEiIj2hcXHj6+uLPXv2ICEhAfv370ffvn0BAKmpqRr3iuTm5iIiIgIREREAylYcj4iIwN27dwGUXVIaO3as2j6P2ufm5uL+/fuIiIjA9evXNT0MMgK2CjNM6tYYALDqUDQelmo2zxIRERknjWco/umnnzBq1CiUlpaiV69eqoHEixcvRnh4OP74449qv1dYWBh69OhRbvu4ceOwefNmjB8/HnFxcQgLC/sncAW3/Xp7eyMuLq5an8kZio1LXlEJuv3nKNLzirFkWCuM7NRA6khERKQDmvx+a1zcAEBycjKSkpLQpk0byGRlnT9nz56Fra0tmjVrVrPUtYTFjfH56vgdfLz3BurbW+Dou91hbqpxhyQREek5nS6/AABubm5o166dqrABgM6dO+t9YUPGaUwXb7jYyJGYWYAfzvNuOCKiuo7/xCWDpzAzwdSevgCA1UeiUfiwVOJEREQkJRY3ZBRGdvJCfXsLpGQXYduZu1LHISIiCbG4IaMgNzXBtL97b9aGxSC/uETiREREJBUWN2Q0hnXwhLeTJdJyi/G/U5xziYiortJ4VXAAiI6OxtGjR5GamgqlUn1ukQULFmglGJGmzExkmN7LD6E7LmN9+G2M6dIANgozqWMREVEt07i42bhxI6ZMmYJ69erBzc1Nbd4ZQRBY3JCkXmxbH2uOxuD2/Tx8cyIO03v7SR2JiIhqmcbz3Hh7e+Ptt9/G+++/r6tMOsV5bozfb1f+wtTvLsFGborj7/eAvaW51JGIiOgZ6XSem4yMDAwfPrzG4Yh0bWBLdzRzs0FOUQk2Hr8jdRwiIqplGhc3w4cPVy25QKSPZDIBoX2aAAA2nYxDem6RxImIiKg2aTzmxtfXF/Pnz8eff/6JVq1awcxMfcDmO++8o7VwRDXVx98VrT3tcOVeFtYdu41/D/KXOhIREdUSjcfcNGrUqPI3EwTcuaPflwE45qbuCItKxfhN5yA3leH47B5wsVVIHYmIiGpIk99vjXtuYmNjaxyMqDYFN3FGB28HXIjPwJqjMVj0YkupIxERUS3gJH5ktARBwKy+ZWNvvj+bgMTMAokTERFRbajRJH737t3DL7/8grt376K4uFjtteXLl2slGJE2BPnUQ2BjJ5y+k47VR6Kx+KXWUkciIiId07i4OXz4MF544QU0btwYN2/eRMuWLREXFwdRFNG+fXtdZCR6JrP6NsHL607jx/P3MDnYB95OVlJHIiIiHdL4stTcuXPx7rvvIjIyEgqFAjt37kRCQgKCg4M5/w3ppY4NHRHcxBklShGrDkdLHYeIiHRM4+Lmxo0bGDt2LADA1NQUBQUFsLa2xocffoglS5ZoPSCRNjya92bPpUTEpOZKnIaIiHRJ4+LGyspKNc7G3d0dt2/fVr2WlpamvWREWtTGyx59/F2hFIGVh25JHYeIiHRI4+KmS5cuOHHiBABg4MCBmDVrFj755BO8/vrr6NKli9YDEmnLo96b364k4UZStsRpiIhIVzQubpYvX46AgAAAwKJFi9CrVy/88MMPaNiwIb7++mutByTSlubuthjU2h0AsOIge2+IiIyVxjMUGzrOUFy3xaTmoO+KcChF4Nepz6OVp53UkYiIqBp0uio4AGRmZuKrr77C3Llz8eDBAwDAxYsXkZiYWJO3I6o1vi42GNK2PgBg+cEoidMQEZEuaFzcXLlyBU2aNMGSJUuwdOlSZGZmAgB27dqFuXPnajsfkda908sPJjIBR6Pu40J8htRxiIhIyzQubkJDQzF+/HhER0dDofhnIcKBAwciPDxcq+GIdKFhPSsM7+AJgL03RETGSOPi5ty5c3jrrbfKba9fvz6Sk5O1EopI16b29IWZiYCTMek4fTtd6jhERKRFGhc3crkc2dnlb6O9desWnJ2dtRKKSNc8HSzxaucGAMp6b+rYuHoiIqOmcXHzwgsv4MMPP8TDhw8BlK28fPfuXbz//vsYNmyY1gMS6UpID1/ITWU4F5eB8GhOQElEZCw0Lm6WLVuG3NxcuLi4oKCgAMHBwfD19YWNjQ0++eQTXWQk0glXWwVe6+INAFh+gL03RETGQuNVwe3s7HDw4EGcOHECV65cQW5uLtq3b4/evXvrIh+RTk3u7oPvzt7F5XtZOHAtBbYWZkjNKYSLjQKdGznCRCZIHZGIiDTESfyozluy7ybWht2GqUxAifKf/xzc7RRYONgf/Vu6S5iOiIgAzX6/q91z8+2331ar3aMVw4kMha+zFQCoFTYAkJxViClbL2LtmPYscIiIDEi1e25kMhmsra1hampa6dgEQRBUMxbrK/bc0ONKlSKeX3IESVmFFb4uAHCzU+DE+z15iYqISEI6WX6hefPmMDc3x9ixY3Hs2DFkZGSUe+h7YUP0pLOxDyotbABABJCUVYizsfy7TURkKKpd3Fy7dg179+5FQUEBunXrho4dO2Lt2rUVznlDZChScyovbGrSjoiIpKfRreABAQFYv349kpKS8M4772DHjh1wd3fH6NGjUVRUpKuMRDrjYqN4eiMN2hERkfRqtCq4hYUFxo4di0WLFqFz587Yvn078vPztZ2NSOc6N3KEu50CVY2msZaboq2XfW1FIiKiZ6RxcZOYmIhPP/0Ufn5+eOWVV9CpUydcu3YNDg4OGn94eHg4Bg8eDA8PDwiCgD179jx1n7CwMLRv3x5yuRy+vr7YvHmzxp9L9IiJTMDCwf4AUGmBk1tUgmFrT+FmMi/BEhEZgmoXNzt27MCAAQPg5+eHc+fOYdmyZUhISMB//vMfNGvWrEYfnpeXhzZt2mDNmjXVah8bG4tBgwahR48eiIiIwIwZMzBx4kTs37+/Rp9PBAD9W7pj7Zj2cLNTv/TkbqfAm10bwcHSDNeTsjH4ixP4MiwGpco6NTUUEZHB0ehW8AYNGmD06NFwdXWttN0777xTsyCCgN27d2PIkCGVtnn//fexd+9eXL16VbXtlVdeQWZmJvbt21etz+Gt4FSZUqWIs7EPys1QnJpTiP/bFYlDN1IBAO0b2GPZiLZoVM9K4sRERHWHTibxa9CgAQRBwHfffVdpG0EQalzcVMfp06fLLfPQr18/zJgxQ2efSXWHiUxAoI9Tue0uNgpsHNsRP124hw9/vY6LdzMxcNVxzB3YDGMCvCHj/DdERHql2sVNXFycDmNUT3JycrleI1dXV2RnZ6OgoAAWFhbl9ikqKlK7k4u3rlNNCIKA4R29EORbD+/9eBmnbqdjwc/XcOBaCv7zcmt42Jf/u0dERNKo0d1ShmTx4sWws7NTPby8vKSORAasvr0Ftr4RgA8G+0NhJsOJmDT0WxmOnRfucVVxIiI9Ua3iZvv27dV+w4SEBJw8ebLGgari5uaGlJQUtW0pKSmwtbWtsNcGAObOnYusrCzVIyEhQSfZqO6QyQSMf64Rfn+nK9p62SOnsASzfryMt7ZcQFou53siIpJatYqbtWvXonnz5vjPf/6DGzdulHs9KysLv//+O0aNGoX27dsjPT1d60EBIDAwEIcPH1bbdvDgQQQGBla6j1wuh62trdqDSBsaO1vjp8mBeK9fU5iZCDhwPQX9VoRj39VkqaMREdVp1Spujh07hiVLluDgwYNo2bIlbG1t4efnh1atWsHT0xNOTk54/fXX0aBBA1y9ehUvvPBCtT48NzcXERERiIiIAFB2q3dERATu3r0LoKzX5fFVxidPnow7d+5g9uzZuHnzJr788kvs2LEDM2fO1PCwibTD1ESGkB6++DnkeTRzs0F6XjEmb72A0B8ikFXwUOp4RER1UrVvBX8kLS0NJ06cQHx8PAoKClCvXj20a9cO7dq1g0ym2RCesLAw9OjRo9z2cePGYfPmzRg/fjzi4uIQFhamts/MmTNx/fp1eHp6Yv78+Rg/fny1P5O3gpOuFJWUYuWhaKw/dhtKsWyenP+83Bpd/ZyljkZEZPA0+f3WuLgxdCxuSNcuxD/ArB2XEZdetiTJa128MXdgM1iaV/vmRCIieoImv99Gf7cUUW3r4O2I36d3xbhAbwDAlj/jMXDVcVyIfyBxMiKiukHjnhsHBwcIQvlJywRBgEKhgK+vL8aPH48JEyZoLaQ2seeGatOJ6DS899NlJGUVQiYAk7r5YGYfP8hNTaSORkRkUHTac7NgwQLIZDIMGjQIixYtwqJFizBo0CDIZDKEhISgSZMmmDJlCjZu3FjjAyAyFs/71cO+Gd0wrL0nlCKw7thtvPDFSVz7K0vqaERERkvjnpthw4ahT58+mDx5str29evX48CBA9i5cye++OILbNiwAZGRkVoNqw3suSGp7L+WjP/bFYn0vGKYygTM6O2HycE+MDXh1WEioqfR6YBia2trREREwNfXV217TEwM2rZti9zcXNy+fRutW7dGXl6e5ul1jMUNSSkttwj/3h2J/dfKJqNs42WP5SPawMfZWuJkRET6TaeXpRwdHfHrr7+W2/7rr7/C0dERAJCXlwcbGxtN35rI6NWzlmPdmA5YMbINbBSmuJxQtgjnNydioVTWqRsXiYh0RuN7U+fPn48pU6bg6NGj6Ny5MwDg3Llz+P3337Fu3ToAZbMGBwcHazcpkZEQBAFD23miS2MnzP7pCo5Hp+HD367j4PUU/Hd4a3g6WEodkYjIoNVonpuTJ09i9erViIqKAgA0bdoU06ZNQ1BQkNYDahsvS5E+EUURW8/cxad7b6DgYSms5aZY8C9/DO/oWeFdiUREdRUn8asCixvSR3FpeXj3x8s4H58BAOjVzAWLh7WCi41C4mRERPpB58VNaWkp9uzZo1pEs0WLFnjhhRdgYqL/c3ewuCF9VaoUsfH4HSw/cAvFpUo4WJrh4yGtMKi1u9TRiIgkp9PiJiYmBgMHDkRiYiKaNm0KAIiKioKXlxf27t0LHx+fmievBSxuSN/dTM5G6A+XcT0pGwDwQhsPfPhiC9hbmkucjIhIOjotbgYOHAhRFLFt2zbV3VHp6ekYM2YMZDIZ9u7dW/PktYDFDRmC4hIlvjgSjS/DbqNUKcLFRo4lL7dGj6YuUkcjIpKETosbKysr/Pnnn2jVqpXa9suXL+O5555Dbm6u5olrEYsbMiQRCZkI3RGBO/fL5ox6tXMD/HtQc1jLuQgnEdUtOp3nRi6XIycnp9z23NxcmJuz25xIm9p62eP3d7ri9ecaAQC+P3sXA1aF48yddImTERHpL42Lm3/961+YNGkSzpw5A1EUIYoi/vzzT0yePBkvvPCCLjIS1WkKMxMsGOyP79/sgvr2Fkh4UIBXNv6Jj3+7jsKHpVLHIyLSOxoXN59//jl8fHwQGBgIhUIBhUKB5557Dr6+vli1apUuMhIRgEAfJ+yb0RUjO3pBFIGvTsTiX1+cwJV7mVJHIyLSKzWe5yY6Oho3b94EADRv3rzcWlP6imNuyBgcvpGCObsicT+nCCYyAVN7+GJqT1+YcRFOIjJSnMSvCixuyFhk5BVj3s9XsfdKEgCgVX07LB/RBn6uXNeNiIyP1oub0NDQan/48uXLq91WCixuyNj8cvkvzN9zFVkFD2FuKsN7fZvi9ecbwUTG5RuIyHho8vtdrftJL126VK0P5lo4RLXvhTYeCGjkiPd3XkFY1H188vsNHLyegqXD26CBExfhJKK6h5eliIyEKIrYfi4BH/92HXnFpbA0N8G8Qf54tbMX/+FBRAZPp/PcEJF+EgQBr3ZugH0zuqFzI0fkF5fi/3ZHYsLmc0jJLpQ6HhFRrWFxQ2RkvBwtsf3NLpg3qDnMTWUIi7qPvivC8XNEIupYRy0R1VEsboiMkEwmYGLXxtg77Xm0qm+HrIKHmL49AlO/u4QHecVSxyMi0ikWN0RGzM/VBrveDsKM3n4wlQnYG5mEvivCcfhGitTRiIh0hsUNkZEzM5FhRu8m2P32c/BzsUZabhHe+N95zP7pMnIKH0odj4hI61jcENURrTzt8Ou05zGpW2MIArDj/D30X3kcp26nSR2NiEirWNwQ1SEKMxP838Dm+GFSILwcLZCYWYBRG8/gg1+uoaCYi3ASkXFgcUNUB3Vu5Ih907thVEADAMDmU3EY9MVxXLqbIXEyIqJnx+KGqI6ykpvi06GtsHlCJ7jaynHnfh6GrT2FpfujUFyilDoeEVGNsbghquO6N3XBgRnBeLGtB5QisPpoDIasOYmbydlSRyMiqhEWN0QEO0szrHqlHb4c3R4Olma4npSNF744ibVht1Gq5MR/RGRYWNwQkcrAVu7YP7Mbejd3QXGpEkv23cSI9acRl5YndTQiompjcUNEalxsFNg4tiP+83JrWMtNcSE+AwNWHceW03FcvoGIDAKLGyIqRxAEjOjohX0zuiKwsRMKHpZi/s/XMPabs0jKKpA6HhFRlVjcEFGlPB0ssW1iAD4Y7A+5qQzHo9PQd0U4dl28x14cItJbLG6IqEoymYDxzzXC79O7oq2XPXIKSxC64zImb72AtNwiqeMREZXD4oaIqsXH2Ro/TQ7Ee/2awsxEwP5rKei3Ihz7riZLHY2ISI1eFDdr1qxBw4YNoVAoEBAQgLNnz1ba9uHDh/jwww/h4+MDhUKBNm3aYN++fbWYlqjuMjWRIaSHL34OeR7N3GyQnleMyVsvIHRHBLIKuAgnEekHyYubH374AaGhoVi4cCEuXryINm3aoF+/fkhNTa2w/bx587B+/Xp88cUXuH79OiZPnoyhQ4fi0qVLtZycqO7y97DFz1Ofw5TuPpAJwK6Liei/MhzHo+9LHY2ICIIo8ajAgIAAdOrUCatXrwYAKJVKeHl5Ydq0aZgzZ0659h4eHvj3v/+NkJAQ1bZhw4bBwsICW7dufernZWdnw87ODllZWbC1tdXegRDVURfiH2DWjsuIS88HAIwN9MacAc1gaW4qcTIiMiaa/H5L2nNTXFyMCxcuoHfv3qptMpkMvXv3xunTpyvcp6ioCAqFQm2bhYUFTpw4UWn77OxstQcRaU8Hb0f8Pr0rxgZ6AwC+PR2PgauO40L8A4mTEVFdJWlxk5aWhtLSUri6uqptd3V1RXJyxYMU+/Xrh+XLlyM6OhpKpRIHDx7Erl27kJSUVGH7xYsXw87OTvXw8vLS+nEQ1XWW5qb48MWW2PpGANztFIhLz8fwdafx2R83UVRSKnU8IqpjJB9zo6lVq1bBz88PzZo1g7m5OaZOnYoJEyZAJqv4UObOnYusrCzVIyEhoZYTE9Udz/vVw74Z3fBS+/pQisC6Y7fx4uqTuPZXltTRiKgOkbS4qVevHkxMTJCSkqK2PSUlBW5ubhXu4+zsjD179iAvLw/x8fG4efMmrK2t0bhx4wrby+Vy2Nraqj2ISHfsLMywfERbrH+tA5yszHEzOQdD1pzE6iPRKClVSh2PiOoASYsbc3NzdOjQAYcPH1ZtUyqVOHz4MAIDA6vcV6FQoH79+igpKcHOnTvx4osv6jouEWmgXws37J/ZDf1auOJhqYilB27h5XWncft+rtTRiMjISX5ZKjQ0FBs3bsT//vc/3LhxA1OmTEFeXh4mTJgAABg7dizmzp2ran/mzBns2rULd+7cwfHjx9G/f38olUrMnj1bqkMgokrUs5Zj3ZgOWDGyDWwUpohIyMSgz49j08lYKJVcvoGIdEPyezVHjhyJ+/fvY8GCBUhOTkbbtm2xb98+1SDju3fvqo2nKSwsxLx583Dnzh1YW1tj4MCB2LJlC+zt7SU6AiKqiiAIGNrOE10aO2H2T1dwPDoNi369jgPXUvDf4a3h6WApdUQiMjKSz3NT2zjPDZF0RFHE1jN38eneGyh4WApruSkWDPbH8A6eEARB6nhEpMcMZp4bIqpbBEHAa1288cf0rujg7YDcohLM/ukK3vz2PFJzCqWOR0RGgsUNEdW6hvWssOOtQMwZ0AzmJjIcupGKfivC8XtkxfNVERFpgsUNEUnCRCZgcrAPfpn2HPzdbZGR/xBvb7uI6dsvITO/WOp4RGTAWNwQkaSaudliT8hzmNbTFyYyAT9H/IV+K8MRFlXx4rlERE/D4oaIJGduKsOsvk2xc0oQGjtbISW7COM3ncP/7Y5EXlGJ1PGIyMCwuCEivdHWyx6/v9MVE55rCAD47sxd9F8VjrOxXISTiKqPxQ0R6RWFmQkWDm6B794MQH17CyQ8KMDIDafxyd7rKHzIRTiJ6OlY3BCRXgryqYd9M7piREdPiCKw8XgsBn9xApH3uAgnEVWNxQ0R6S0bhRn+83IbfDW2I+pZyxGdmouhX57EykO38JCLcBJRJVjcEJHe6+3vioMzu2FQa3eUKEWsPBSNYWtPITolR9WmVCni9O10/ByRiNO301HKtauI6iwuv0BEBuWXy39h/p6ryCp4CHNTGWb3awoPOwt8tPc6krL+meXY3U6BhYP90b+lu4RpiUhbNPn9ZnFDRAYnJbsQ7++8grCo+5W2ebRS1dox7VngEBkBri1FREbN1VaBTeM74ZOhLVHZcpuP/tW26NfrvERFVMewuCEigyQIAhrXs0ZVZYsIICmrkPPkENUxplIHICKqqequJP792bswkQloVd8OFuYmOk5FRFJjcUNEBsvFRlGtdr9c/gu/XP4LpjIBzd1t0a6BPdo1sEf7Bg5o4GgJQajs4hYRGSIWN0RksDo3coS7nQLJWYWVXp6yUZgiqLETLiVkIjWnCJGJWYhMzMK3p+MBAE5W5n8XOw5o18AebTztYSXn/xqJDBnvliIig7bvahKmbL0IAGoFzpN3S4miiL+yCnHpbgYuxmfiUkIGriVmo/iJyQBlAtDU7e/eHS97tPd2QON6VuzdIZIYbwWvAosbIuOz72oSFv2q+Tw3RSWluPZXNi7GZ+BSQiYuxWfgr6zy43jsLMz+LnYc0N7bHm287GGrMNPJsRBRxVjcVIHFDZFxKlWKOBv7AKk5hXCxUaBzI0eYyDTvbUnOKkREQgYu3s3EpbsZuHIvC0Ul6r07ggD4uVijnVfZpaz23g7wdbaGrAafR0TVw+KmCixuiEgTxSVK3Ez+p3fn4t0MJDwoKNfORm6Ktn9fymrn7YB2XvawtzSXIDGRcWJxUwUWN0T0rO7nFCHi70Ln0t0MXE7IQsHD0nLtGjtbqS5ltfNyQBNXa5iacHoxoppgcVMFFjdEpG0lpUpEpeSoLmVdupuJ2LS8cu0szU3QxvOf29DbNbCHk7VcgsREhofFTRVY3BBRbcjIK36sdycTEQmZyC0qKdfO28lSdVdWOy8HNHO3gRl7d4jKYXFTBRY3RCSFUqWImNRc1aWsS3czEZ2aW66dwkyG1vXtVXPvtG9gDxfb6k1WSGTMWNxUgcUNEemLrIKHuPxY786luxnILizfu1Pf3kKt2PH3sIXclMtIUN3C4qYKLG6ISF8plSLupOWpFTu3UnLw5KLm5qYytPSw/bvYKRu742FvIU1oolrC4qYKLG6IyJDkFpXgymO9OxfvZiAj/2G5dm62CrU1s1rWt4PCjL07ZDxY3FSBxQ0RGTJRFBGfnv9P705CBm4k5aD0ie4dMxMB/u62qjWz2jdwgKeDBZeRIIPF4qYKLG6IyNjkF5cg8l6W6lb0i3czkZZbVK5dPWu5Wu9Oa087WJpzkVAyDCxuqsDihoiMnSiKuJdR8FjvTiau/5WFh6Xq/7s3kQlo5mbz2Lw7DmjoZMneHdJLLG6qwOKGiOqiwoeluPZXlmpF9IvxmUjOLr9IqIOlWdmlrL/n3mntaQcbLhJKeoDFTRVY3BARlUnKKigrdu5m4OLdDFxNzEZxaflFQpu62qjdit64HhcJpdrH4qYKLG6IiCpWVFKKG0k5/ywSGp+BxMzyi4TaKkzR9rHenbae9rCzZO8O6RaLmyqwuCEiqr7U7MKygcoJZeN3rtzLROFDZbl2vi7W/ywj0cAefi42MNGwd6dUKeJs7AOk5hTCxUaBzo0cNX4PMl4sbqrA4oaIqOYelioRlZyjNu9OfHp+uXbWclO08bJTTTLY1ssBjlbmlb7vvqtJWPTrdSRl/TMOyN1OgYWD/dG/pbtOjoUMC4ubKrC4ISLSrvTcIrVFQi8nZCKvuLRcu0b1rNDOyx7tvMsuaTVzs4GpiQz7riZhytaLePLH6FGfzdox7VngEIubqrC4ISLSrVKliFsp6r07d+7nlWtnYWaCVvVtce2v7AqLIaCswHGzU+DE+z15iaqO0+T3W1ZLmaq0Zs0aNGzYEAqFAgEBATh79myV7VeuXImmTZvCwsICXl5emDlzJgoLy9/SSEREtc9EJqC5uy1GB3hj6fA2ODKrOyIW9MHmCZ3wTi8/dPWrBxuFKQoeluJsXEalhQ0AiACSsgpxMuZ+7R0AGTzJp6b84YcfEBoainXr1iEgIAArV65Ev379EBUVBRcXl3Ltv/vuO8yZMwfffPMNgoKCcOvWLYwfPx6CIGD58uUSHAERET2NvaU5ujd1QfemZf9fVypF3L6fi29OxuL7swlP3X/sN+fgZquAl6MFvBws4eX498PBAl6OlnC1VbBnh1QkvywVEBCATp06YfXq1QAApVIJLy8vTJs2DXPmzCnXfurUqbhx4wYOHz6s2jZr1iycOXMGJ06ceOrn8bIUEZH+OH07Ha9u/POZ38fMREB9+7JCx9PBEl6OFmjgaKkqhBwszTjzsoHT5Pdb0p6b4uJiXLhwAXPnzlVtk8lk6N27N06fPl3hPkFBQdi6dSvOnj2Lzp07486dO/j999/x2muvVdi+qKgIRUX/rLGSnZ2t3YMgIqIa69zIEe52CiRnFZYbUAz8M+ZmT8hz+CuzAAkZBUh4kI97GflIeFCAhIx8JGYU4GGpiLj0fMRVcOcWAFiZm6gVPo+KngaOZc+5xpZxkfRspqWlobS0FK6urmrbXV1dcfPmzQr3GTVqFNLS0vD8889DFEWUlJRg8uTJ+L//+78K2y9evBiLFi3SenYiInp2JjIBCwf7Y8rWixAAtQLnUT/LwsH+cLVVwNVWgXYNHMq9R0mpEsnZhapi596DfFURlJCRj5TsIuQVl+Jmcg5uJudUmMPJyhyej13m8nL4p/DxsLeAmYleDFGlajK4UjUsLAyffvopvvzySwQEBCAmJgbTp0/HRx99hPnz55drP3fuXISGhqqeZ2dnw8vLqzYjExFRFfq3dMfaMe3LzXPjVs15bkxNZPB0KOuVCYRTudcLH5biXkbFhU/CgwJkFTxEel4x0vOKcTkhs9z+MgFwt7OA52OFj5ejharnx9lazuUo9IykxU29evVgYmKClJQUte0pKSlwc3OrcJ/58+fjtddew8SJEwEArVq1Ql5eHiZNmoR///vfkMnUq2u5XA65XK6bAyAiIq3o39IdffzddDJDscLMBL4u1vB1sa7w9ayCh+UudSU8VgQVlSiRmFmAxMwCnIl9UG5/c1NZWeHzxCWvR70/XJqi9kla3Jibm6NDhw44fPgwhgwZAqBsQPHhw4cxderUCvfJz88vV8CYmJgAAOrYlD1EREbFRCYg0Kd8z4uu2VmYwa6+HVrWtyv3miiKuJ9TpOrlebzHJyEjH0lZhSguUeLO/bwK5/IBABuFafnC5+8/ezpYwsLcRNeHWOdIflkqNDQU48aNQ8eOHdG5c2esXLkSeXl5mDBhAgBg7NixqF+/PhYvXgwAGDx4MJYvX4527dqpLkvNnz8fgwcPVhU5RERE2iAIAlxsFXCxVaCDd/nXH5YqkZxViLsP8ssVPgkPCpCWW4ScwhJcT8rG9aSKb2hxtpGrjfV5vAhyt1PAlON9NCZ5cTNy5Ejcv38fCxYsQHJyMtq2bYt9+/apBhnfvXtXradm3rx5EAQB8+bNQ2JiIpydnTF48GB88sknUh0CERHVUWYmMtWcOxUpKC4tu9yVkY+76Y+P9ynAvQf5yCkqwf2cItzPKcLFu5nl9jeRCXC3Uzx2W7v67e7O1nLe4l4Byee5qW2c54aIiPSBKIp/j/cp6+n5p/enrPC5l1GA4tLyK7A/TmFWNpi6wWN3enk+VgTZKoxnvI/BzHNDRERUVwmCAHtLc9hbmqOVZ/nxPkqliFTVeJ+yy1x3/770de9BPpKyC1H4UImY1FzEpOZW+Bl2Fmaqy1wNHC3Vbnevb28BhZl2h3OUKkWdDArXFHtuiIiIDFBxifLviQ2fuMvr796fB3nFT30PV1t5hctZeDlawk3DJS32XU0qdzu/ezVv568OrgpeBRY3RERUF+QWlfxze/vjg53//nN+FQuWAmVLWnjYW6iN9fnnNncLOFqZq8b77LuahClbL5abZfpRabR2TPtnLnBY3FSBxQ0REdV1oijiQV5xuQkN7/3d+5OYWbakRVUszU3+vp1dgdN3HlRaLD1aQuPE+z2f6RIVx9wQERFRpQRBgJO1HE7WcrT1si/3eqlS/HtJC/VBzo+KoOTsQuQXlyIqJQdRKRUvafGICCApqxBnYx/U2jxGLG6IiIhIjYmsbJX1+vYW6NK44iUtEjPLen32Ribhx/P3nvqeqTmFT22jLSxuiIiISCMKMxP4OFvDx9kaclOTahU3LjaKWkhWhtMeEhERUY11buQIdzsFKhtNI6DsrqnOjRxrLROLGyIiIqoxE5mAhYP9AaBcgfPo+cLB/rU63w2LGyIiInom/Vu6Y+2Y9nCzU7/05Gan0Mpt4JrimBsiIiJ6Zv1buqOPv5tezFDM4oaIiIi0wkQm1Nrt3lXhZSkiIiIyKixuiIiIyKiwuCEiIiKjwuKGiIiIjAqLGyIiIjIqLG6IiIjIqLC4ISIiIqPC4oaIiIiMCosbIiIiMip1boZiURQBANnZ2RInISIioup69Lv96He8KnWuuMnJyQEAeHl5SZyEiIiINJWTkwM7O7sq2whidUogI6JUKvHXX3/BxsYGgqDdxbyys7Ph5eWFhIQE2NraavW99YGxHx9g/MfI4zN8xn6MPD7Dp6tjFEUROTk58PDwgExW9aiaOtdzI5PJ4OnpqdPPsLW1Ndq/tIDxHx9g/MfI4zN8xn6MPD7Dp4tjfFqPzSMcUExERERGhcUNERERGRUWN1okl8uxcOFCyOVyqaPohLEfH2D8x8jjM3zGfow8PsOnD8dY5wYUExERkXFjzw0REREZFRY3REREZFRY3BAREZFRYXFDRERERoXFjQbCw8MxePBgeHh4QBAE7Nmz56n7hIWFoX379pDL5fD19cXmzZt1nrOmND2+sLAwCIJQ7pGcnFw7gTW0ePFidOrUCTY2NnBxccGQIUMQFRX11P1+/PFHNGvWDAqFAq1atcLvv/9eC2k1V5Pj27x5c7nzp1Aoaimx5tauXYvWrVurJgcLDAzEH3/8UeU+hnL+AM2Pz9DO35M+++wzCIKAGTNmVNnOkM7h46pzfIZ2Dj/44INyeZs1a1blPlKcPxY3GsjLy0ObNm2wZs2aarWPjY3FoEGD0KNHD0RERGDGjBmYOHEi9u/fr+OkNaPp8T0SFRWFpKQk1cPFxUVHCZ/NsWPHEBISgj///BMHDx7Ew4cP0bdvX+Tl5VW6z6lTp/Dqq6/ijTfewKVLlzBkyBAMGTIEV69ercXk1VOT4wPKZhF9/PzFx8fXUmLNeXp64rPPPsOFCxdw/vx59OzZEy+++CKuXbtWYXtDOn+A5scHGNb5e9y5c+ewfv16tG7dusp2hnYOH6nu8QGGdw5btGihlvfEiROVtpXs/IlUIwDE3bt3V9lm9uzZYosWLdS2jRw5UuzXr58Ok2lHdY7v6NGjIgAxIyOjVjJpW2pqqghAPHbsWKVtRowYIQ4aNEhtW0BAgPjWW2/pOt4zq87xbdq0SbSzs6u9UDrg4OAgfvXVVxW+Zsjn75Gqjs9Qz19OTo7o5+cnHjx4UAwODhanT59eaVtDPIeaHJ+hncOFCxeKbdq0qXZ7qc4fe2506PTp0+jdu7fatn79+uH06dMSJdKNtm3bwt3dHX369MHJkyeljlNtWVlZAABHR8dK2xjyOazO8QFAbm4uvL294eXl9dReAn1SWlqK7du3Iy8vD4GBgRW2MeTzV53jAwzz/IWEhGDQoEHlzk1FDPEcanJ8gOGdw+joaHh4eKBx48YYPXo07t69W2lbqc5fnVs4szYlJyfD1dVVbZurqyuys7NRUFAACwsLiZJph7u7O9atW4eOHTuiqKgIX331Fbp3744zZ86gffv2UserklKpxIwZM/Dcc8+hZcuWlbar7Bzq67iiR6p7fE2bNsU333yD1q1bIysrC0uXLkVQUBCuXbum8wVmayoyMhKBgYEoLCyEtbU1du/eDX9//wrbGuL50+T4DPH8bd++HRcvXsS5c+eq1d7QzqGmx2do5zAgIACbN29G06ZNkZSUhEWLFqFr1664evUqbGxsyrWX6vyxuKEaa9q0KZo2bap6HhQUhNu3b2PFihXYsmWLhMmeLiQkBFevXq3yWrEhq+7xBQYGqvUKBAUFoXnz5li/fj0++ugjXceskaZNmyIiIgJZWVn46aefMG7cOBw7dqzSAsDQaHJ8hnb+EhISMH36dBw8eFCvB83WVE2Oz9DO4YABA1R/bt26NQICAuDt7Y0dO3bgjTfekDCZOhY3OuTm5oaUlBS1bSkpKbC1tTX4XpvKdO7cWe8LhqlTp+K3335DeHj4U/9lVNk5dHNz02XEZ6LJ8T3JzMwM7dq1Q0xMjI7SPTtzc3P4+voCADp06IBz585h1apVWL9+fbm2hnj+NDm+J+n7+btw4QJSU1PVenZLS0sRHh6O1atXo6ioCCYmJmr7GNI5rMnxPUnfz+GT7O3t0aRJk0rzSnX+OOZGhwIDA3H48GG1bQcPHqzy+rmhi4iIgLu7u9QxKiSKIqZOnYrdu3fjyJEjaNSo0VP3MaRzWJPje1JpaSkiIyP19hxWRKlUoqioqMLXDOn8Vaaq43uSvp+/Xr16ITIyEhEREapHx44dMXr0aERERFT4w29I57Amx/ckfT+HT8rNzcXt27crzSvZ+dPpcGUjk5OTI166dEm8dOmSCEBcvny5eOnSJTE+Pl4URVGcM2eO+Nprr6na37lzR7S0tBTfe+898caNG+KaNWtEExMTcd++fVIdQpU0Pb4VK1aIe/bsEaOjo8XIyEhx+vTpokwmEw8dOiTVIVRpypQpop2dnRgWFiYmJSWpHvn5+ao2r732mjhnzhzV85MnT4qmpqbi0qVLxRs3bogLFy4UzczMxMjISCkOoUo1Ob5FixaJ+/fvF2/fvi1euHBBfOWVV0SFQiFeu3ZNikN4qjlz5ojHjh0TY2NjxStXrohz5swRBUEQDxw4IIqiYZ8/UdT8+Azt/FXkybuJDP0cPulpx2do53DWrFliWFiYGBsbK548eVLs3bu3WK9ePTE1NVUURf05fyxuNPDo1ucnH+PGjRNFURTHjRsnBgcHl9unbdu2orm5udi4cWNx06ZNtZ67ujQ9viVLlog+Pj6iQqEQHR0dxe7du4tHjhyRJnw1VHRsANTOSXBwsOp4H9mxY4fYpEkT0dzcXGzRooW4d+/e2g1eTTU5vhkzZogNGjQQzc3NRVdXV3HgwIHixYsXaz98Nb3++uuit7e3aG5uLjo7O4u9evVS/fCLomGfP1HU/PgM7fxV5Mkff0M/h0962vEZ2jkcOXKk6O7uLpqbm4v169cXR44cKcbExKhe15fzJ4iiKOq2b4iIiIio9nDMDRERERkVFjdERERkVFjcEBERkVFhcUNERERGhcUNERERGRUWN0RERGRUWNwQERGRUWFxQ0R1kiAI2LNnj9QxiEgHWNwQUa0bP348BEEo9+jfv7/U0YjICHBVcCKSRP/+/bFp0ya1bXK5XKI0RGRM2HNDRJKQy+Vwc3NTezg4OAAou2S0du1aDBgwABYWFmjcuDF++ukntf0jIyPRs2dPWFhYwMnJCZMmTUJubq5am2+++QYtWrSAXC6Hu7s7pk6dqvZ6Wloahg4dCktLS/j5+eGXX35RvZaRkYHRo0fD2dkZFhYW8PPzK1eMEZF+YnFDRHpp/vz5GDZsGC5fvozRo0fjlVdewY0bNwAAeXl56NevHxwcHHDu3Dn8+OOPOHTokFrxsnbtWoSEhGDSpEmIjIzEL7/8Al9fX7XPWLRoEUaMGIErV65g4MCBGD16NB48eKD6/OvXr+OPP/7AjRs3sHbtWtSrV6/2vgAiqjmdL81JRPSEcePGiSYmJqKVlZXa45NPPhFFsWyF88mTJ6vtExAQIE6ZMkUURVHcsGGD6ODgIObm5qpe37t3ryiTycTk5GRRFEXRw8ND/Pe//11pBgDivHnzVM9zc3NFAOIff/whiqIoDh48WJwwYYJ2DpiIahXH3BCRJHr06IG1a9eqbXN0dFT9OTAwUO21wMBAREREAABu3LiBNm3awMrKSvX6c889B6VSiaioKAiCgL/++gu9evWqMkPr1q1Vf7aysoKtrS1SU1MBAFOmTMGwYcNw8eJF9O3bF0OGDEFQUFCNjpWIaheLGyKShJWVVbnLRNpiYWFRrXZmZmZqzwVBgFKpBAAMGDAA8fHx+P3333Hw4EH06tULISEhWLp0qdbzEpF2ccwNEemlP//8s9zz5s2bAwCaN2+Oy5cvIy8vT/X6yZMnIZPJ0LRpU9jY2KBhw4Y4fPjwM2VwdnbGuHHjsHXrVqxcuRIbNmx4pvcjotrBnhsikkRRURGSk5PVtpmamqoG7f7444/o2LEjnn/+eWzbtg1nz57F119/DQAYPXo0Fi5ciHHjxuGDDz7A/fv3MW3aNLz22mtwdXUFAHzwwQeYPHkyXFxcMGDAAOTk5ODkyZOYNm1atfItWLAAHTp0QIsWLVBUVITffvtNVVwRkX5jcUNEkti3bx/c3d3VtjVt2hQ3b94EUHYn0/bt2/H222/D3d0d33//Pfz9/QEAlpaW2L9/P6ZPn45OnTrB0tISw4YNw/Lly1XvNW7cOBQWFmLFihV49913Ua9ePbz88svVzmdubo65c+ciLi4OFhYW6Nq1K7Zv366FIyciXRNEURSlDkFE9DhBELB7924MGTJE6ihEZIA45oaIiIiMCosbIiIiMiocc0NEeodXy4noWbDnhoiIiIwKixsiIiIyKixuiIiIyKiwuCEiIiKjwuKGiIiIjAqLGyIiIjIqLG6IiIjIqLC4ISIiIqPC4oaIiIiMyv8Dl7phoMBL5xsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "weight, loss = fit(X, y)\n",
        "plt.plot(range(1, len(loss) + 1), np.log10(loss), marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('log(Mean squared error)')\n",
        "plt.title('Adaline - Learning rate 0.0001')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "plvVLUerb_G4",
        "outputId": "6a5b7129-defa-4aa1-aaa0-32b276d324f8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0 starting.....\n",
            "Predicted Output from the Adaline Model in the 0 th step is as follows: [-0.04673288 -0.04286851 -0.04162837 -0.04263438 -0.0466493  -0.05216893\n",
            " -0.04228052 -0.04666592 -0.03928155 -0.04533506 -0.05069746 -0.04651538\n",
            " -0.04312216 -0.03684447 -0.0515101  -0.05449912 -0.04787705 -0.04586747\n",
            " -0.05434143 -0.04852496 -0.05125888 -0.04713138 -0.0399104  -0.04629922\n",
            " -0.04973428 -0.0456262  -0.04600807 -0.04841761 -0.04681646 -0.04484728\n",
            " -0.04493086 -0.04738213 -0.05245204 -0.05287711 -0.04533506 -0.04239067\n",
            " -0.04810694 -0.04533506 -0.03873676 -0.04727768 -0.04418275 -0.0347859\n",
            " -0.0397931  -0.04480543 -0.05195142 -0.04139134 -0.05046333 -0.04208958\n",
            " -0.05008571 -0.04506478 -0.08246979 -0.07177771 -0.08816799 -0.08212309\n",
            " -0.08255908 -0.09873756 -0.06050856 -0.09575143 -0.08460336 -0.09063309\n",
            " -0.07783546 -0.07759419 -0.08204085 -0.06817123 -0.06797884 -0.07677341\n",
            " -0.0828018  -0.10378225 -0.09872472 -0.07274903 -0.08412407 -0.06807102\n",
            " -0.10023134 -0.07355596 -0.08515955 -0.09350528 -0.07239941 -0.07391697\n",
            " -0.07961045 -0.09203382 -0.09282367 -0.10351767 -0.07874504 -0.07882629\n",
            " -0.08277669 -0.09225365 -0.0795715  -0.08271822 -0.07223224 -0.08210781\n",
            " -0.08043401 -0.07715809 -0.07177771 -0.08565825 -0.08169791 -0.07647937\n",
            " -0.07270718 -0.07785208 -0.07767921 -0.07483939]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [0.04673288 0.04286851 0.04162837 0.04263438 0.0466493  0.05216893\n",
            " 0.04228052 0.04666592 0.03928155 0.04533506 0.05069746 0.04651538\n",
            " 0.04312216 0.03684447 0.0515101  0.05449912 0.04787705 0.04586747\n",
            " 0.05434143 0.04852496 0.05125888 0.04713138 0.0399104  0.04629922\n",
            " 0.04973428 0.0456262  0.04600807 0.04841761 0.04681646 0.04484728\n",
            " 0.04493086 0.04738213 0.05245204 0.05287711 0.04533506 0.04239067\n",
            " 0.04810694 0.04533506 0.03873676 0.04727768 0.04418275 0.0347859\n",
            " 0.0397931  0.04480543 0.05195142 0.04139134 0.05046333 0.04208958\n",
            " 0.05008571 0.04506478 1.08246979 1.07177771 1.08816799 1.08212309\n",
            " 1.08255908 1.09873756 1.06050856 1.09575143 1.08460336 1.09063309\n",
            " 1.07783546 1.07759419 1.08204085 1.06817123 1.06797884 1.07677341\n",
            " 1.0828018  1.10378225 1.09872472 1.07274903 1.08412407 1.06807102\n",
            " 1.10023134 1.07355596 1.08515955 1.09350528 1.07239941 1.07391697\n",
            " 1.07961045 1.09203382 1.09282367 1.10351767 1.07874504 1.07882629\n",
            " 1.08277669 1.09225365 1.0795715  1.08271822 1.07223224 1.08210781\n",
            " 1.08043401 1.07715809 1.07177771 1.08565825 1.08169791 1.07647937\n",
            " 1.07270718 1.07785208 1.07767921 1.07483939]\n",
            "Current value for the Loss value is :: [29.313307773211772]\n",
            "Epoch - 1 starting.....\n",
            "Predicted Output from the Adaline Model in the 1 th step is as follows: [0.25055975 0.23861611 0.23282983 0.23253187 0.24864986 0.2742471\n",
            " 0.23601415 0.24829527 0.22210338 0.23977604 0.26405868 0.24412092\n",
            " 0.23357854 0.2123268  0.27392253 0.28532813 0.26638103 0.25252689\n",
            " 0.28033072 0.25797506 0.26451006 0.25878165 0.22850204 0.26003962\n",
            " 0.25002047 0.24561959 0.25419608 0.2555967  0.25246963 0.23872938\n",
            " 0.24063926 0.26451131 0.26059287 0.27096535 0.23977604 0.24007462\n",
            " 0.26087498 0.23977604 0.22129741 0.25136571 0.24748993 0.21821113\n",
            " 0.22361852 0.25929091 0.26780827 0.23751282 0.25797443 0.23172591\n",
            " 0.26098824 0.24516821 0.42078794 0.36897094 0.4320347  0.39450967\n",
            " 0.4136127  0.4611525  0.32328252 0.43897966 0.40608225 0.45387004\n",
            " 0.3982339  0.3913266  0.41495732 0.36358002 0.3799672  0.40499792\n",
            " 0.39984458 0.47744101 0.46941457 0.35947397 0.42821617 0.36202472\n",
            " 0.46190121 0.37842295 0.41930157 0.43349133 0.37454655 0.37576373\n",
            " 0.40232098 0.42330291 0.43892366 0.47374805 0.40428812 0.37761511\n",
            " 0.37701858 0.45832464 0.41211528 0.39793469 0.37072677 0.41722179\n",
            " 0.42091537 0.41525652 0.36897094 0.42907877 0.42717013 0.40992161\n",
            " 0.3800355  0.39787931 0.40314466 0.37355589]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.25055975 -0.23861611 -0.23282983 -0.23253187 -0.24864986 -0.2742471\n",
            " -0.23601415 -0.24829527 -0.22210338 -0.23977604 -0.26405868 -0.24412092\n",
            " -0.23357854 -0.2123268  -0.27392253 -0.28532813 -0.26638103 -0.25252689\n",
            " -0.28033072 -0.25797506 -0.26451006 -0.25878165 -0.22850204 -0.26003962\n",
            " -0.25002047 -0.24561959 -0.25419608 -0.2555967  -0.25246963 -0.23872938\n",
            " -0.24063926 -0.26451131 -0.26059287 -0.27096535 -0.23977604 -0.24007462\n",
            " -0.26087498 -0.23977604 -0.22129741 -0.25136571 -0.24748993 -0.21821113\n",
            " -0.22361852 -0.25929091 -0.26780827 -0.23751282 -0.25797443 -0.23172591\n",
            " -0.26098824 -0.24516821  0.57921206  0.63102906  0.5679653   0.60549033\n",
            "  0.5863873   0.5388475   0.67671748  0.56102034  0.59391775  0.54612996\n",
            "  0.6017661   0.6086734   0.58504268  0.63641998  0.6200328   0.59500208\n",
            "  0.60015542  0.52255899  0.53058543  0.64052603  0.57178383  0.63797528\n",
            "  0.53809879  0.62157705  0.58069843  0.56650867  0.62545345  0.62423627\n",
            "  0.59767902  0.57669709  0.56107634  0.52625195  0.59571188  0.62238489\n",
            "  0.62298142  0.54167536  0.58788472  0.60206531  0.62927323  0.58277821\n",
            "  0.57908463  0.58474348  0.63102906  0.57092123  0.57282987  0.59007839\n",
            "  0.6199645   0.60212069  0.59685534  0.62644411]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572]\n",
            "Epoch - 2 starting.....\n",
            "Predicted Output from the Adaline Model in the 2 th step is as follows: [0.35658072 0.33975752 0.33078687 0.33162976 0.35380516 0.3915064\n",
            " 0.3355753  0.35400409 0.31621792 0.34225316 0.37637842 0.34865189\n",
            " 0.33283748 0.30064962 0.38849418 0.40587642 0.37782832 0.3591149\n",
            " 0.40051951 0.36736531 0.37838657 0.36828919 0.32258364 0.37122121\n",
            " 0.35891046 0.35098242 0.36249195 0.3643861  0.35935628 0.34104544\n",
            " 0.343821   0.37661587 0.37151372 0.38539624 0.34225316 0.34052493\n",
            " 0.37070464 0.34225316 0.3144087  0.35838995 0.35130952 0.31005665\n",
            " 0.31762929 0.3691706  0.38357757 0.33790583 0.36825066 0.32982053\n",
            " 0.37199256 0.34897427 0.62157439 0.54400258 0.63827416 0.58371591\n",
            " 0.61107366 0.68414011 0.47572378 0.65151115 0.6016572  0.66929754\n",
            " 0.58528926 0.57715678 0.6114385  0.53551078 0.55828374 0.59534496\n",
            " 0.5906784  0.70736204 0.69741169 0.5311666  0.63095234 0.53253629\n",
            " 0.68619072 0.55655866 0.61872258 0.64169762 0.55036358 0.55261784\n",
            " 0.59409399 0.62656964 0.64998184 0.70080685 0.59662816 0.55740549\n",
            " 0.55997661 0.6764967  0.60697243 0.58790284 0.54481246 0.61401513\n",
            " 0.61968498 0.60882491 0.54400258 0.63340552 0.62885926 0.60186242\n",
            " 0.55929176 0.58548818 0.59321336 0.55068516]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.35658072 -0.33975752 -0.33078687 -0.33162976 -0.35380516 -0.3915064\n",
            " -0.3355753  -0.35400409 -0.31621792 -0.34225316 -0.37637842 -0.34865189\n",
            " -0.33283748 -0.30064962 -0.38849418 -0.40587642 -0.37782832 -0.3591149\n",
            " -0.40051951 -0.36736531 -0.37838657 -0.36828919 -0.32258364 -0.37122121\n",
            " -0.35891046 -0.35098242 -0.36249195 -0.3643861  -0.35935628 -0.34104544\n",
            " -0.343821   -0.37661587 -0.37151372 -0.38539624 -0.34225316 -0.34052493\n",
            " -0.37070464 -0.34225316 -0.3144087  -0.35838995 -0.35130952 -0.31005665\n",
            " -0.31762929 -0.3691706  -0.38357757 -0.33790583 -0.36825066 -0.32982053\n",
            " -0.37199256 -0.34897427  0.37842561  0.45599742  0.36172584  0.41628409\n",
            "  0.38892634  0.31585989  0.52427622  0.34848885  0.3983428   0.33070246\n",
            "  0.41471074  0.42284322  0.3885615   0.46448922  0.44171626  0.40465504\n",
            "  0.4093216   0.29263796  0.30258831  0.4688334   0.36904766  0.46746371\n",
            "  0.31380928  0.44344134  0.38127742  0.35830238  0.44963642  0.44738216\n",
            "  0.40590601  0.37343036  0.35001816  0.29919315  0.40337184  0.44259451\n",
            "  0.44002339  0.3235033   0.39302757  0.41209716  0.45518754  0.38598487\n",
            "  0.38031502  0.39117509  0.45599742  0.36659448  0.37114074  0.39813758\n",
            "  0.44070824  0.41451182  0.40678664  0.44931484]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435]\n",
            "Epoch - 3 starting.....\n",
            "Predicted Output from the Adaline Model in the 3 th step is as follows: [0.38912482 0.3715975  0.36093879 0.36306246 0.38592154 0.42839336\n",
            " 0.36646709 0.38699633 0.34604903 0.37454759 0.4109302  0.38166457\n",
            " 0.3639148  0.32719854 0.42210761 0.44220833 0.41138474 0.39201556\n",
            " 0.43828981 0.40103376 0.41466847 0.40233582 0.34974509 0.40737615\n",
            " 0.39442104 0.38489377 0.39702998 0.39816893 0.39232809 0.37369526\n",
            " 0.37689853 0.41194565 0.40481027 0.41941341 0.37454759 0.37106251\n",
            " 0.40404049 0.37454759 0.34338556 0.39178829 0.38297145 0.3399475\n",
            " 0.34656292 0.40440014 0.42093312 0.36969629 0.40239517 0.36039899\n",
            " 0.40613825 0.3811555  0.70553721 0.61643148 0.7232917  0.66193866\n",
            " 0.69317854 0.77701657 0.53883208 0.73962332 0.68325608 0.75768302\n",
            " 0.66080932 0.65368753 0.6919072  0.60710075 0.63247388 0.67319391\n",
            " 0.6688591  0.80166087 0.79399176 0.60225686 0.71416232 0.60282267\n",
            " 0.77999258 0.62899621 0.7003856  0.72684094 0.62154078 0.62417833\n",
            " 0.67381417 0.70937778 0.73721303 0.79270683 0.67670491 0.63041697\n",
            " 0.63602572 0.76632924 0.68722652 0.66565582 0.61513422 0.69403568\n",
            " 0.70162831 0.68706071 0.61643148 0.71787467 0.71194857 0.68014027\n",
            " 0.63296175 0.66188412 0.67103951 0.62309873]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38912482 -0.3715975  -0.36093879 -0.36306246 -0.38592154 -0.42839336\n",
            " -0.36646709 -0.38699633 -0.34604903 -0.37454759 -0.4109302  -0.38166457\n",
            " -0.3639148  -0.32719854 -0.42210761 -0.44220833 -0.41138474 -0.39201556\n",
            " -0.43828981 -0.40103376 -0.41466847 -0.40233582 -0.34974509 -0.40737615\n",
            " -0.39442104 -0.38489377 -0.39702998 -0.39816893 -0.39232809 -0.37369526\n",
            " -0.37689853 -0.41194565 -0.40481027 -0.41941341 -0.37454759 -0.37106251\n",
            " -0.40404049 -0.37454759 -0.34338556 -0.39178829 -0.38297145 -0.3399475\n",
            " -0.34656292 -0.40440014 -0.42093312 -0.36969629 -0.40239517 -0.36039899\n",
            " -0.40613825 -0.3811555   0.29446279  0.38356852  0.2767083   0.33806134\n",
            "  0.30682146  0.22298343  0.46116792  0.26037668  0.31674392  0.24231698\n",
            "  0.33919068  0.34631247  0.3080928   0.39289925  0.36752612  0.32680609\n",
            "  0.3311409   0.19833913  0.20600824  0.39774314  0.28583768  0.39717733\n",
            "  0.22000742  0.37100379  0.2996144   0.27315906  0.37845922  0.37582167\n",
            "  0.32618583  0.29062222  0.26278697  0.20729317  0.32329509  0.36958303\n",
            "  0.36397428  0.23367076  0.31277348  0.33434418  0.38486578  0.30596432\n",
            "  0.29837169  0.31293929  0.38356852  0.28212533  0.28805143  0.31985973\n",
            "  0.36703825  0.33811588  0.32896049  0.37690127]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211]\n",
            "Epoch - 4 starting.....\n",
            "Predicted Output from the Adaline Model in the 4 th step is as follows: [0.39359852 0.37694019 0.36518484 0.36861718 0.39013943 0.43455143\n",
            " 0.37111637 0.39219369 0.35129604 0.38000681 0.41577021 0.38732978\n",
            " 0.36892765 0.33016346 0.42483522 0.44638597 0.41520277 0.39676052\n",
            " 0.4445496  0.40577203 0.42127019 0.40754258 0.35138861 0.41481311\n",
            " 0.40184127 0.39146506 0.40335486 0.40328623 0.39705761 0.37969634\n",
            " 0.38315543 0.41791986 0.40847292 0.42274083 0.38000681 0.3748993\n",
            " 0.40816352 0.38000681 0.34785032 0.39704424 0.38707281 0.34612272\n",
            " 0.35063322 0.41107031 0.42828269 0.37525165 0.4074472  0.36517147\n",
            " 0.41091966 0.38596508 0.74425766 0.64914979 0.76140248 0.69720921\n",
            " 0.73062407 0.81951533 0.56736504 0.77957477 0.7207199  0.79692404\n",
            " 0.69322282 0.68792736 0.7275022  0.63984118 0.66635123 0.7075326\n",
            " 0.70346458 0.84349663 0.83963557 0.63440846 0.75113396 0.63432782\n",
            " 0.82325814 0.66056616 0.73650033 0.76438708 0.6522699  0.65503943\n",
            " 0.7101543  0.74560586 0.77652153 0.83236222 0.7133163  0.66214594\n",
            " 0.67068578 0.80650405 0.72313845 0.70000549 0.64535172 0.72890702\n",
            " 0.73836627 0.72071953 0.64914979 0.75595775 0.74914833 0.71446416\n",
            " 0.66578242 0.69527708 0.70545158 0.65501268]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.39359852 -0.37694019 -0.36518484 -0.36861718 -0.39013943 -0.43455143\n",
            " -0.37111637 -0.39219369 -0.35129604 -0.38000681 -0.41577021 -0.38732978\n",
            " -0.36892765 -0.33016346 -0.42483522 -0.44638597 -0.41520277 -0.39676052\n",
            " -0.4445496  -0.40577203 -0.42127019 -0.40754258 -0.35138861 -0.41481311\n",
            " -0.40184127 -0.39146506 -0.40335486 -0.40328623 -0.39705761 -0.37969634\n",
            " -0.38315543 -0.41791986 -0.40847292 -0.42274083 -0.38000681 -0.3748993\n",
            " -0.40816352 -0.38000681 -0.34785032 -0.39704424 -0.38707281 -0.34612272\n",
            " -0.35063322 -0.41107031 -0.42828269 -0.37525165 -0.4074472  -0.36517147\n",
            " -0.41091966 -0.38596508  0.25574234  0.35085021  0.23859752  0.30279079\n",
            "  0.26937593  0.18048467  0.43263496  0.22042523  0.2792801   0.20307596\n",
            "  0.30677718  0.31207264  0.2724978   0.36015882  0.33364877  0.2924674\n",
            "  0.29653542  0.15650337  0.16036443  0.36559154  0.24886604  0.36567218\n",
            "  0.17674186  0.33943384  0.26349967  0.23561292  0.3477301   0.34496057\n",
            "  0.2898457   0.25439414  0.22347847  0.16763778  0.2866837   0.33785406\n",
            "  0.32931422  0.19349595  0.27686155  0.29999451  0.35464828  0.27109298\n",
            "  0.26163373  0.27928047  0.35085021  0.24404225  0.25085167  0.28553584\n",
            "  0.33421758  0.30472292  0.29454842  0.34498732]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Adaline - Learning rate 0.0001')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters or Tuning Parameters for the model.\n",
        "eta = 0.0001\n",
        "epochs = 40"
      ],
      "metadata": {
        "id": "ctJ54bcScDKv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "weight, loss = fit(X, y)\n",
        "plt.plot(range(1, len(loss) + 1), np.log10(loss), marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('log(Mean squared error)')\n",
        "plt.title('Adaline - Learning rate 0.0001')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6pVouA9WaFea",
        "outputId": "2e378bb7-0066-4708-e4c9-10838b5e2ede"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0 starting.....\n",
            "Predicted Output from the Adaline Model in the 0 th step is as follows: [-0.04673288 -0.04286851 -0.04162837 -0.04263438 -0.0466493  -0.05216893\n",
            " -0.04228052 -0.04666592 -0.03928155 -0.04533506 -0.05069746 -0.04651538\n",
            " -0.04312216 -0.03684447 -0.0515101  -0.05449912 -0.04787705 -0.04586747\n",
            " -0.05434143 -0.04852496 -0.05125888 -0.04713138 -0.0399104  -0.04629922\n",
            " -0.04973428 -0.0456262  -0.04600807 -0.04841761 -0.04681646 -0.04484728\n",
            " -0.04493086 -0.04738213 -0.05245204 -0.05287711 -0.04533506 -0.04239067\n",
            " -0.04810694 -0.04533506 -0.03873676 -0.04727768 -0.04418275 -0.0347859\n",
            " -0.0397931  -0.04480543 -0.05195142 -0.04139134 -0.05046333 -0.04208958\n",
            " -0.05008571 -0.04506478 -0.08246979 -0.07177771 -0.08816799 -0.08212309\n",
            " -0.08255908 -0.09873756 -0.06050856 -0.09575143 -0.08460336 -0.09063309\n",
            " -0.07783546 -0.07759419 -0.08204085 -0.06817123 -0.06797884 -0.07677341\n",
            " -0.0828018  -0.10378225 -0.09872472 -0.07274903 -0.08412407 -0.06807102\n",
            " -0.10023134 -0.07355596 -0.08515955 -0.09350528 -0.07239941 -0.07391697\n",
            " -0.07961045 -0.09203382 -0.09282367 -0.10351767 -0.07874504 -0.07882629\n",
            " -0.08277669 -0.09225365 -0.0795715  -0.08271822 -0.07223224 -0.08210781\n",
            " -0.08043401 -0.07715809 -0.07177771 -0.08565825 -0.08169791 -0.07647937\n",
            " -0.07270718 -0.07785208 -0.07767921 -0.07483939]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [0.04673288 0.04286851 0.04162837 0.04263438 0.0466493  0.05216893\n",
            " 0.04228052 0.04666592 0.03928155 0.04533506 0.05069746 0.04651538\n",
            " 0.04312216 0.03684447 0.0515101  0.05449912 0.04787705 0.04586747\n",
            " 0.05434143 0.04852496 0.05125888 0.04713138 0.0399104  0.04629922\n",
            " 0.04973428 0.0456262  0.04600807 0.04841761 0.04681646 0.04484728\n",
            " 0.04493086 0.04738213 0.05245204 0.05287711 0.04533506 0.04239067\n",
            " 0.04810694 0.04533506 0.03873676 0.04727768 0.04418275 0.0347859\n",
            " 0.0397931  0.04480543 0.05195142 0.04139134 0.05046333 0.04208958\n",
            " 0.05008571 0.04506478 1.08246979 1.07177771 1.08816799 1.08212309\n",
            " 1.08255908 1.09873756 1.06050856 1.09575143 1.08460336 1.09063309\n",
            " 1.07783546 1.07759419 1.08204085 1.06817123 1.06797884 1.07677341\n",
            " 1.0828018  1.10378225 1.09872472 1.07274903 1.08412407 1.06807102\n",
            " 1.10023134 1.07355596 1.08515955 1.09350528 1.07239941 1.07391697\n",
            " 1.07961045 1.09203382 1.09282367 1.10351767 1.07874504 1.07882629\n",
            " 1.08277669 1.09225365 1.0795715  1.08271822 1.07223224 1.08210781\n",
            " 1.08043401 1.07715809 1.07177771 1.08565825 1.08169791 1.07647937\n",
            " 1.07270718 1.07785208 1.07767921 1.07483939]\n",
            "Current value for the Loss value is :: [29.313307773211772]\n",
            "Epoch - 1 starting.....\n",
            "Predicted Output from the Adaline Model in the 1 th step is as follows: [0.25055975 0.23861611 0.23282983 0.23253187 0.24864986 0.2742471\n",
            " 0.23601415 0.24829527 0.22210338 0.23977604 0.26405868 0.24412092\n",
            " 0.23357854 0.2123268  0.27392253 0.28532813 0.26638103 0.25252689\n",
            " 0.28033072 0.25797506 0.26451006 0.25878165 0.22850204 0.26003962\n",
            " 0.25002047 0.24561959 0.25419608 0.2555967  0.25246963 0.23872938\n",
            " 0.24063926 0.26451131 0.26059287 0.27096535 0.23977604 0.24007462\n",
            " 0.26087498 0.23977604 0.22129741 0.25136571 0.24748993 0.21821113\n",
            " 0.22361852 0.25929091 0.26780827 0.23751282 0.25797443 0.23172591\n",
            " 0.26098824 0.24516821 0.42078794 0.36897094 0.4320347  0.39450967\n",
            " 0.4136127  0.4611525  0.32328252 0.43897966 0.40608225 0.45387004\n",
            " 0.3982339  0.3913266  0.41495732 0.36358002 0.3799672  0.40499792\n",
            " 0.39984458 0.47744101 0.46941457 0.35947397 0.42821617 0.36202472\n",
            " 0.46190121 0.37842295 0.41930157 0.43349133 0.37454655 0.37576373\n",
            " 0.40232098 0.42330291 0.43892366 0.47374805 0.40428812 0.37761511\n",
            " 0.37701858 0.45832464 0.41211528 0.39793469 0.37072677 0.41722179\n",
            " 0.42091537 0.41525652 0.36897094 0.42907877 0.42717013 0.40992161\n",
            " 0.3800355  0.39787931 0.40314466 0.37355589]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.25055975 -0.23861611 -0.23282983 -0.23253187 -0.24864986 -0.2742471\n",
            " -0.23601415 -0.24829527 -0.22210338 -0.23977604 -0.26405868 -0.24412092\n",
            " -0.23357854 -0.2123268  -0.27392253 -0.28532813 -0.26638103 -0.25252689\n",
            " -0.28033072 -0.25797506 -0.26451006 -0.25878165 -0.22850204 -0.26003962\n",
            " -0.25002047 -0.24561959 -0.25419608 -0.2555967  -0.25246963 -0.23872938\n",
            " -0.24063926 -0.26451131 -0.26059287 -0.27096535 -0.23977604 -0.24007462\n",
            " -0.26087498 -0.23977604 -0.22129741 -0.25136571 -0.24748993 -0.21821113\n",
            " -0.22361852 -0.25929091 -0.26780827 -0.23751282 -0.25797443 -0.23172591\n",
            " -0.26098824 -0.24516821  0.57921206  0.63102906  0.5679653   0.60549033\n",
            "  0.5863873   0.5388475   0.67671748  0.56102034  0.59391775  0.54612996\n",
            "  0.6017661   0.6086734   0.58504268  0.63641998  0.6200328   0.59500208\n",
            "  0.60015542  0.52255899  0.53058543  0.64052603  0.57178383  0.63797528\n",
            "  0.53809879  0.62157705  0.58069843  0.56650867  0.62545345  0.62423627\n",
            "  0.59767902  0.57669709  0.56107634  0.52625195  0.59571188  0.62238489\n",
            "  0.62298142  0.54167536  0.58788472  0.60206531  0.62927323  0.58277821\n",
            "  0.57908463  0.58474348  0.63102906  0.57092123  0.57282987  0.59007839\n",
            "  0.6199645   0.60212069  0.59685534  0.62644411]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572]\n",
            "Epoch - 2 starting.....\n",
            "Predicted Output from the Adaline Model in the 2 th step is as follows: [0.35658072 0.33975752 0.33078687 0.33162976 0.35380516 0.3915064\n",
            " 0.3355753  0.35400409 0.31621792 0.34225316 0.37637842 0.34865189\n",
            " 0.33283748 0.30064962 0.38849418 0.40587642 0.37782832 0.3591149\n",
            " 0.40051951 0.36736531 0.37838657 0.36828919 0.32258364 0.37122121\n",
            " 0.35891046 0.35098242 0.36249195 0.3643861  0.35935628 0.34104544\n",
            " 0.343821   0.37661587 0.37151372 0.38539624 0.34225316 0.34052493\n",
            " 0.37070464 0.34225316 0.3144087  0.35838995 0.35130952 0.31005665\n",
            " 0.31762929 0.3691706  0.38357757 0.33790583 0.36825066 0.32982053\n",
            " 0.37199256 0.34897427 0.62157439 0.54400258 0.63827416 0.58371591\n",
            " 0.61107366 0.68414011 0.47572378 0.65151115 0.6016572  0.66929754\n",
            " 0.58528926 0.57715678 0.6114385  0.53551078 0.55828374 0.59534496\n",
            " 0.5906784  0.70736204 0.69741169 0.5311666  0.63095234 0.53253629\n",
            " 0.68619072 0.55655866 0.61872258 0.64169762 0.55036358 0.55261784\n",
            " 0.59409399 0.62656964 0.64998184 0.70080685 0.59662816 0.55740549\n",
            " 0.55997661 0.6764967  0.60697243 0.58790284 0.54481246 0.61401513\n",
            " 0.61968498 0.60882491 0.54400258 0.63340552 0.62885926 0.60186242\n",
            " 0.55929176 0.58548818 0.59321336 0.55068516]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.35658072 -0.33975752 -0.33078687 -0.33162976 -0.35380516 -0.3915064\n",
            " -0.3355753  -0.35400409 -0.31621792 -0.34225316 -0.37637842 -0.34865189\n",
            " -0.33283748 -0.30064962 -0.38849418 -0.40587642 -0.37782832 -0.3591149\n",
            " -0.40051951 -0.36736531 -0.37838657 -0.36828919 -0.32258364 -0.37122121\n",
            " -0.35891046 -0.35098242 -0.36249195 -0.3643861  -0.35935628 -0.34104544\n",
            " -0.343821   -0.37661587 -0.37151372 -0.38539624 -0.34225316 -0.34052493\n",
            " -0.37070464 -0.34225316 -0.3144087  -0.35838995 -0.35130952 -0.31005665\n",
            " -0.31762929 -0.3691706  -0.38357757 -0.33790583 -0.36825066 -0.32982053\n",
            " -0.37199256 -0.34897427  0.37842561  0.45599742  0.36172584  0.41628409\n",
            "  0.38892634  0.31585989  0.52427622  0.34848885  0.3983428   0.33070246\n",
            "  0.41471074  0.42284322  0.3885615   0.46448922  0.44171626  0.40465504\n",
            "  0.4093216   0.29263796  0.30258831  0.4688334   0.36904766  0.46746371\n",
            "  0.31380928  0.44344134  0.38127742  0.35830238  0.44963642  0.44738216\n",
            "  0.40590601  0.37343036  0.35001816  0.29919315  0.40337184  0.44259451\n",
            "  0.44002339  0.3235033   0.39302757  0.41209716  0.45518754  0.38598487\n",
            "  0.38031502  0.39117509  0.45599742  0.36659448  0.37114074  0.39813758\n",
            "  0.44070824  0.41451182  0.40678664  0.44931484]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435]\n",
            "Epoch - 3 starting.....\n",
            "Predicted Output from the Adaline Model in the 3 th step is as follows: [0.38912482 0.3715975  0.36093879 0.36306246 0.38592154 0.42839336\n",
            " 0.36646709 0.38699633 0.34604903 0.37454759 0.4109302  0.38166457\n",
            " 0.3639148  0.32719854 0.42210761 0.44220833 0.41138474 0.39201556\n",
            " 0.43828981 0.40103376 0.41466847 0.40233582 0.34974509 0.40737615\n",
            " 0.39442104 0.38489377 0.39702998 0.39816893 0.39232809 0.37369526\n",
            " 0.37689853 0.41194565 0.40481027 0.41941341 0.37454759 0.37106251\n",
            " 0.40404049 0.37454759 0.34338556 0.39178829 0.38297145 0.3399475\n",
            " 0.34656292 0.40440014 0.42093312 0.36969629 0.40239517 0.36039899\n",
            " 0.40613825 0.3811555  0.70553721 0.61643148 0.7232917  0.66193866\n",
            " 0.69317854 0.77701657 0.53883208 0.73962332 0.68325608 0.75768302\n",
            " 0.66080932 0.65368753 0.6919072  0.60710075 0.63247388 0.67319391\n",
            " 0.6688591  0.80166087 0.79399176 0.60225686 0.71416232 0.60282267\n",
            " 0.77999258 0.62899621 0.7003856  0.72684094 0.62154078 0.62417833\n",
            " 0.67381417 0.70937778 0.73721303 0.79270683 0.67670491 0.63041697\n",
            " 0.63602572 0.76632924 0.68722652 0.66565582 0.61513422 0.69403568\n",
            " 0.70162831 0.68706071 0.61643148 0.71787467 0.71194857 0.68014027\n",
            " 0.63296175 0.66188412 0.67103951 0.62309873]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38912482 -0.3715975  -0.36093879 -0.36306246 -0.38592154 -0.42839336\n",
            " -0.36646709 -0.38699633 -0.34604903 -0.37454759 -0.4109302  -0.38166457\n",
            " -0.3639148  -0.32719854 -0.42210761 -0.44220833 -0.41138474 -0.39201556\n",
            " -0.43828981 -0.40103376 -0.41466847 -0.40233582 -0.34974509 -0.40737615\n",
            " -0.39442104 -0.38489377 -0.39702998 -0.39816893 -0.39232809 -0.37369526\n",
            " -0.37689853 -0.41194565 -0.40481027 -0.41941341 -0.37454759 -0.37106251\n",
            " -0.40404049 -0.37454759 -0.34338556 -0.39178829 -0.38297145 -0.3399475\n",
            " -0.34656292 -0.40440014 -0.42093312 -0.36969629 -0.40239517 -0.36039899\n",
            " -0.40613825 -0.3811555   0.29446279  0.38356852  0.2767083   0.33806134\n",
            "  0.30682146  0.22298343  0.46116792  0.26037668  0.31674392  0.24231698\n",
            "  0.33919068  0.34631247  0.3080928   0.39289925  0.36752612  0.32680609\n",
            "  0.3311409   0.19833913  0.20600824  0.39774314  0.28583768  0.39717733\n",
            "  0.22000742  0.37100379  0.2996144   0.27315906  0.37845922  0.37582167\n",
            "  0.32618583  0.29062222  0.26278697  0.20729317  0.32329509  0.36958303\n",
            "  0.36397428  0.23367076  0.31277348  0.33434418  0.38486578  0.30596432\n",
            "  0.29837169  0.31293929  0.38356852  0.28212533  0.28805143  0.31985973\n",
            "  0.36703825  0.33811588  0.32896049  0.37690127]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211]\n",
            "Epoch - 4 starting.....\n",
            "Predicted Output from the Adaline Model in the 4 th step is as follows: [0.39359852 0.37694019 0.36518484 0.36861718 0.39013943 0.43455143\n",
            " 0.37111637 0.39219369 0.35129604 0.38000681 0.41577021 0.38732978\n",
            " 0.36892765 0.33016346 0.42483522 0.44638597 0.41520277 0.39676052\n",
            " 0.4445496  0.40577203 0.42127019 0.40754258 0.35138861 0.41481311\n",
            " 0.40184127 0.39146506 0.40335486 0.40328623 0.39705761 0.37969634\n",
            " 0.38315543 0.41791986 0.40847292 0.42274083 0.38000681 0.3748993\n",
            " 0.40816352 0.38000681 0.34785032 0.39704424 0.38707281 0.34612272\n",
            " 0.35063322 0.41107031 0.42828269 0.37525165 0.4074472  0.36517147\n",
            " 0.41091966 0.38596508 0.74425766 0.64914979 0.76140248 0.69720921\n",
            " 0.73062407 0.81951533 0.56736504 0.77957477 0.7207199  0.79692404\n",
            " 0.69322282 0.68792736 0.7275022  0.63984118 0.66635123 0.7075326\n",
            " 0.70346458 0.84349663 0.83963557 0.63440846 0.75113396 0.63432782\n",
            " 0.82325814 0.66056616 0.73650033 0.76438708 0.6522699  0.65503943\n",
            " 0.7101543  0.74560586 0.77652153 0.83236222 0.7133163  0.66214594\n",
            " 0.67068578 0.80650405 0.72313845 0.70000549 0.64535172 0.72890702\n",
            " 0.73836627 0.72071953 0.64914979 0.75595775 0.74914833 0.71446416\n",
            " 0.66578242 0.69527708 0.70545158 0.65501268]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.39359852 -0.37694019 -0.36518484 -0.36861718 -0.39013943 -0.43455143\n",
            " -0.37111637 -0.39219369 -0.35129604 -0.38000681 -0.41577021 -0.38732978\n",
            " -0.36892765 -0.33016346 -0.42483522 -0.44638597 -0.41520277 -0.39676052\n",
            " -0.4445496  -0.40577203 -0.42127019 -0.40754258 -0.35138861 -0.41481311\n",
            " -0.40184127 -0.39146506 -0.40335486 -0.40328623 -0.39705761 -0.37969634\n",
            " -0.38315543 -0.41791986 -0.40847292 -0.42274083 -0.38000681 -0.3748993\n",
            " -0.40816352 -0.38000681 -0.34785032 -0.39704424 -0.38707281 -0.34612272\n",
            " -0.35063322 -0.41107031 -0.42828269 -0.37525165 -0.4074472  -0.36517147\n",
            " -0.41091966 -0.38596508  0.25574234  0.35085021  0.23859752  0.30279079\n",
            "  0.26937593  0.18048467  0.43263496  0.22042523  0.2792801   0.20307596\n",
            "  0.30677718  0.31207264  0.2724978   0.36015882  0.33364877  0.2924674\n",
            "  0.29653542  0.15650337  0.16036443  0.36559154  0.24886604  0.36567218\n",
            "  0.17674186  0.33943384  0.26349967  0.23561292  0.3477301   0.34496057\n",
            "  0.2898457   0.25439414  0.22347847  0.16763778  0.2866837   0.33785406\n",
            "  0.32931422  0.19349595  0.27686155  0.29999451  0.35464828  0.27109298\n",
            "  0.26163373  0.27928047  0.35085021  0.24404225  0.25085167  0.28553584\n",
            "  0.33421758  0.30472292  0.29454842  0.34498732]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835]\n",
            "Epoch - 5 starting.....\n",
            "Predicted Output from the Adaline Model in the 5 th step is as follows: [0.38749993 0.3722815  0.35967163 0.36439812 0.38385425 0.42911222\n",
            " 0.36587323 0.38690789 0.34725849 0.37533614 0.40941767 0.38267018\n",
            " 0.36410707 0.32426094 0.41597188 0.43847172 0.40783814 0.39089624\n",
            " 0.4389178  0.39961208 0.41665738 0.40187596 0.34346772 0.41137955\n",
            " 0.39862574 0.38769665 0.39901904 0.39759656 0.3911456  0.37562719\n",
            " 0.37927286 0.41281297 0.40099489 0.41453946 0.37533614 0.36868745\n",
            " 0.40129386 0.37533614 0.34307241 0.391686   0.38079961 0.34331975\n",
            " 0.34533729 0.40694411 0.42428248 0.3708997  0.40153429 0.36021204\n",
            " 0.40463955 0.38045693 0.76533955 0.66640978 0.78126336 0.71576151\n",
            " 0.75067247 0.84238356 0.58243813 0.80077228 0.74098124 0.81705841\n",
            " 0.70891509 0.7057155  0.74565494 0.65744458 0.68452379 0.72496296\n",
            " 0.72113165 0.86493603 0.8653801  0.65140002 0.7701276  0.65074527\n",
            " 0.846819   0.67626699 0.75491119 0.78343593 0.6673028  0.67010808\n",
            " 0.72959612 0.76374138 0.79717723 0.85174407 0.73299244 0.67784752\n",
            " 0.6892227  0.82736171 0.7418016  0.71748598 0.66001145 0.74624697\n",
            " 0.75751673 0.73708404 0.66640978 0.77598653 0.76849645 0.7317139\n",
            " 0.68271694 0.71196872 0.72299013 0.6711889 ]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38749993 -0.3722815  -0.35967163 -0.36439812 -0.38385425 -0.42911222\n",
            " -0.36587323 -0.38690789 -0.34725849 -0.37533614 -0.40941767 -0.38267018\n",
            " -0.36410707 -0.32426094 -0.41597188 -0.43847172 -0.40783814 -0.39089624\n",
            " -0.4389178  -0.39961208 -0.41665738 -0.40187596 -0.34346772 -0.41137955\n",
            " -0.39862574 -0.38769665 -0.39901904 -0.39759656 -0.3911456  -0.37562719\n",
            " -0.37927286 -0.41281297 -0.40099489 -0.41453946 -0.37533614 -0.36868745\n",
            " -0.40129386 -0.37533614 -0.34307241 -0.391686   -0.38079961 -0.34331975\n",
            " -0.34533729 -0.40694411 -0.42428248 -0.3708997  -0.40153429 -0.36021204\n",
            " -0.40463955 -0.38045693  0.23466045  0.33359022  0.21873664  0.28423849\n",
            "  0.24932753  0.15761644  0.41756187  0.19922772  0.25901876  0.18294159\n",
            "  0.29108491  0.2942845   0.25434506  0.34255542  0.31547621  0.27503704\n",
            "  0.27886835  0.13506397  0.1346199   0.34859998  0.2298724   0.34925473\n",
            "  0.153181    0.32373301  0.24508881  0.21656407  0.3326972   0.32989192\n",
            "  0.27040388  0.23625862  0.20282277  0.14825593  0.26700756  0.32215248\n",
            "  0.3107773   0.17263829  0.2581984   0.28251402  0.33998855  0.25375303\n",
            "  0.24248327  0.26291596  0.33359022  0.22401347  0.23150355  0.2682861\n",
            "  0.31728306  0.28803128  0.27700987  0.3288111 ]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625]\n",
            "Epoch - 6 starting.....\n",
            "Predicted Output from the Adaline Model in the 6 th step is as follows: [0.37756752 0.36397462 0.35061725 0.3566078  0.37376483 0.419444\n",
            " 0.35703436 0.37780609 0.33982899 0.3669695  0.39900438 0.37424196\n",
            " 0.3557041  0.31515788 0.40294674 0.42619099 0.39643607 0.38117999\n",
            " 0.42895034 0.38949804 0.40794227 0.39225515 0.33212468 0.40395015\n",
            " 0.3914979  0.38013664 0.39078301 0.38797756 0.38137022 0.36787319\n",
            " 0.37167589 0.40366325 0.38949724 0.40218725 0.3669695  0.35883943\n",
            " 0.39044776 0.3669695  0.33493237 0.38246415 0.37076995 0.33721539\n",
            " 0.33664308 0.3988633  0.41611843 0.36292904 0.39163756 0.35171117\n",
            " 0.39434633 0.37119875 0.77943134 0.67756629 0.79392786 0.72771472\n",
            " 0.76384002 0.85748201 0.59219626 0.81455914 0.75442947 0.82967189\n",
            " 0.71806193 0.71701858 0.75694577 0.669058   0.69648398 0.73574524\n",
            " 0.7321342  0.87834737 0.88319951 0.66240376 0.78204344 0.66121404\n",
            " 0.86256886 0.68574014 0.76635775 0.79521121 0.67618546 0.6789901\n",
            " 0.74235482 0.7747716  0.81047034 0.8631826  0.74596728 0.68726205\n",
            " 0.70138267 0.84060509 0.75366631 0.72833151 0.66858006 0.7567072\n",
            " 0.76973246 0.7466762  0.67756629 0.78888935 0.78080762 0.74225671\n",
            " 0.69339387 0.7221032  0.73389182 0.68117795]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.37756752 -0.36397462 -0.35061725 -0.3566078  -0.37376483 -0.419444\n",
            " -0.35703436 -0.37780609 -0.33982899 -0.3669695  -0.39900438 -0.37424196\n",
            " -0.3557041  -0.31515788 -0.40294674 -0.42619099 -0.39643607 -0.38117999\n",
            " -0.42895034 -0.38949804 -0.40794227 -0.39225515 -0.33212468 -0.40395015\n",
            " -0.3914979  -0.38013664 -0.39078301 -0.38797756 -0.38137022 -0.36787319\n",
            " -0.37167589 -0.40366325 -0.38949724 -0.40218725 -0.3669695  -0.35883943\n",
            " -0.39044776 -0.3669695  -0.33493237 -0.38246415 -0.37076995 -0.33721539\n",
            " -0.33664308 -0.3988633  -0.41611843 -0.36292904 -0.39163756 -0.35171117\n",
            " -0.39434633 -0.37119875  0.22056866  0.32243371  0.20607214  0.27228528\n",
            "  0.23615998  0.14251799  0.40780374  0.18544086  0.24557053  0.17032811\n",
            "  0.28193807  0.28298142  0.24305423  0.330942    0.30351602  0.26425476\n",
            "  0.2678658   0.12165263  0.11680049  0.33759624  0.21795656  0.33878596\n",
            "  0.13743114  0.31425986  0.23364225  0.20478879  0.32381454  0.3210099\n",
            "  0.25764518  0.2252284   0.18952966  0.1368174   0.25403272  0.31273795\n",
            "  0.29861733  0.15939491  0.24633369  0.27166849  0.33141994  0.2432928\n",
            "  0.23026754  0.2533238   0.32243371  0.21111065  0.21919238  0.25774329\n",
            "  0.30660613  0.2778968   0.26610818  0.31882205]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933]\n",
            "Epoch - 7 starting.....\n",
            "Predicted Output from the Adaline Model in the 7 th step is as follows: [0.36639178 0.35446257 0.34041217 0.34763146 0.36244623 0.40838005\n",
            " 0.3470206  0.36745177 0.33127357 0.35738091 0.38727209 0.36456622\n",
            " 0.34612233 0.30503233 0.38861453 0.4125131  0.38374288 0.37020959\n",
            " 0.41755263 0.3780995  0.39786005 0.38134045 0.31971936 0.39516936\n",
            " 0.38304409 0.37130358 0.3812467  0.37707349 0.37033733 0.35889005\n",
            " 0.3628356  0.3931771  0.37671691 0.38851958 0.35738091 0.34782015\n",
            " 0.37832218 0.35738091 0.32569116 0.3719742  0.35952788 0.32999329\n",
            " 0.3268449  0.38945921 0.40655449 0.35375796 0.38044098 0.34204904\n",
            " 0.38274966 0.36071561 0.79064433 0.68623045 0.80366254 0.73697495\n",
            " 0.77418653 0.86938971 0.5997835  0.82531424 0.76507574 0.83923605\n",
            " 0.72458959 0.72568358 0.76545811 0.6782128  0.70589641 0.74383921\n",
            " 0.74043738 0.88850422 0.89771815 0.67096037 0.79108849 0.66926171\n",
            " 0.87509986 0.69270617 0.77498488 0.80404455 0.68260132 0.68539194\n",
            " 0.75237396 0.78293659 0.82075902 0.87143556 0.75619177 0.69414817\n",
            " 0.71092822 0.85075131 0.76276622 0.73649183 0.67471022 0.76439811\n",
            " 0.7791253  0.75355587 0.68623045 0.79888465 0.79025615 0.75009344\n",
            " 0.70152953 0.72959514 0.74210739 0.68866567]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.36639178 -0.35446257 -0.34041217 -0.34763146 -0.36244623 -0.40838005\n",
            " -0.3470206  -0.36745177 -0.33127357 -0.35738091 -0.38727209 -0.36456622\n",
            " -0.34612233 -0.30503233 -0.38861453 -0.4125131  -0.38374288 -0.37020959\n",
            " -0.41755263 -0.3780995  -0.39786005 -0.38134045 -0.31971936 -0.39516936\n",
            " -0.38304409 -0.37130358 -0.3812467  -0.37707349 -0.37033733 -0.35889005\n",
            " -0.3628356  -0.3931771  -0.37671691 -0.38851958 -0.35738091 -0.34782015\n",
            " -0.37832218 -0.35738091 -0.32569116 -0.3719742  -0.35952788 -0.32999329\n",
            " -0.3268449  -0.38945921 -0.40655449 -0.35375796 -0.38044098 -0.34204904\n",
            " -0.38274966 -0.36071561  0.20935567  0.31376955  0.19633746  0.26302505\n",
            "  0.22581347  0.13061029  0.4002165   0.17468576  0.23492426  0.16076395\n",
            "  0.27541041  0.27431642  0.23454189  0.3217872   0.29410359  0.25616079\n",
            "  0.25956262  0.11149578  0.10228185  0.32903963  0.20891151  0.33073829\n",
            "  0.12490014  0.30729383  0.22501512  0.19595545  0.31739868  0.31460806\n",
            "  0.24762604  0.21706341  0.17924098  0.12856444  0.24380823  0.30585183\n",
            "  0.28907178  0.14924869  0.23723378  0.26350817  0.32528978  0.23560189\n",
            "  0.2208747   0.24644413  0.31376955  0.20111535  0.20974385  0.24990656\n",
            "  0.29847047  0.27040486  0.25789261  0.31133433]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789]\n",
            "Epoch - 8 starting.....\n",
            "Predicted Output from the Adaline Model in the 8 th step is as follows: [0.35496415 0.34468096 0.32997139 0.3383828  0.3508839  0.39700545\n",
            " 0.33675877 0.35682649 0.32246026 0.34751796 0.37527018 0.35460858\n",
            " 0.33628215 0.29471747 0.37406665 0.39857398 0.37080916 0.35897947\n",
            " 0.40583736 0.36643826 0.38745861 0.37015034 0.30715364 0.38605085\n",
            " 0.37425579 0.3621626  0.3714062  0.36589671 0.3590444  0.3496186\n",
            " 0.35369886 0.3823911  0.36370083 0.3746208  0.34751796 0.33657279\n",
            " 0.36594905 0.34751796 0.31621443 0.36120998 0.3480469  0.32249056\n",
            " 0.31682091 0.37974008 0.39664987 0.34431279 0.36897201 0.33213697\n",
            " 0.37088669 0.34997418 0.80056928 0.6937988  0.81211715 0.74505279\n",
            " 0.78328244 0.87987812 0.60641581 0.83473122 0.77447194 0.84747951\n",
            " 0.73001477 0.7331979  0.77277038 0.68627508 0.71417864 0.75077538\n",
            " 0.74757394 0.89725193 0.91072651 0.67843923 0.79888914 0.67625223\n",
            " 0.88618889 0.6986028  0.78239475 0.81161023 0.68797348 0.69074554\n",
            " 0.761179   0.78987497 0.82972865 0.87834105 0.76519432 0.69995823\n",
            " 0.7193148  0.85954689 0.77066091 0.74349369 0.67981297 0.77090804\n",
            " 0.78728516 0.75929146 0.6937988  0.80760379 0.79845603 0.75677031\n",
            " 0.70856071 0.73595736 0.74916395 0.69507669]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.35496415 -0.34468096 -0.32997139 -0.3383828  -0.3508839  -0.39700545\n",
            " -0.33675877 -0.35682649 -0.32246026 -0.34751796 -0.37527018 -0.35460858\n",
            " -0.33628215 -0.29471747 -0.37406665 -0.39857398 -0.37080916 -0.35897947\n",
            " -0.40583736 -0.36643826 -0.38745861 -0.37015034 -0.30715364 -0.38605085\n",
            " -0.37425579 -0.3621626  -0.3714062  -0.36589671 -0.3590444  -0.3496186\n",
            " -0.35369886 -0.3823911  -0.36370083 -0.3746208  -0.34751796 -0.33657279\n",
            " -0.36594905 -0.34751796 -0.31621443 -0.36120998 -0.3480469  -0.32249056\n",
            " -0.31682091 -0.37974008 -0.39664987 -0.34431279 -0.36897201 -0.33213697\n",
            " -0.37088669 -0.34997418  0.19943072  0.3062012   0.18788285  0.25494721\n",
            "  0.21671756  0.12012188  0.39358419  0.16526878  0.22552806  0.15252049\n",
            "  0.26998523  0.2668021   0.22722962  0.31372492  0.28582136  0.24922462\n",
            "  0.25242606  0.10274807  0.08927349  0.32156077  0.20111086  0.32374777\n",
            "  0.11381111  0.3013972   0.21760525  0.18838977  0.31202652  0.30925446\n",
            "  0.238821    0.21012503  0.17027135  0.12165895  0.23480568  0.30004177\n",
            "  0.2806852   0.14045311  0.22933909  0.25650631  0.32018703  0.22909196\n",
            "  0.21271484  0.24070854  0.3062012   0.19239621  0.20154397  0.24322969\n",
            "  0.29143929  0.26404264  0.25083605  0.30492331]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237]\n",
            "Epoch - 9 starting.....\n",
            "Predicted Output from the Adaline Model in the 9 th step is as follows: [0.34365984 0.3349845  0.31964121 0.32920835 0.33945064 0.38573148\n",
            " 0.32659982 0.34630211 0.31371825 0.33773985 0.36339586 0.34473517\n",
            " 0.32653236 0.28452818 0.35971498 0.38480298 0.35803197 0.34786607\n",
            " 0.39422628 0.35490107 0.3771355  0.35907059 0.29476749 0.37697975\n",
            " 0.3655098  0.35308016 0.36163944 0.35483063 0.34786905 0.34041585\n",
            " 0.34462505 0.3716982  0.35084463 0.36090042 0.33773985 0.32545406\n",
            " 0.3537186  0.33773985 0.30683007 0.35054802 0.33669528 0.31502527\n",
            " 0.30690348 0.37008861 0.38680681 0.33494482 0.35761971 0.32232018\n",
            " 0.35914995 0.33934052 0.80982502 0.70081396 0.81993238 0.75253508\n",
            " 0.79173828 0.88963607 0.61256564 0.84346832 0.78322165 0.8550732\n",
            " 0.73492508 0.74013917 0.77949514 0.69377599 0.72188181 0.75714762\n",
            " 0.75413872 0.90530673 0.92292226 0.68537246 0.80607667 0.68271532\n",
            " 0.89652722 0.70398752 0.7892091  0.81855789 0.69285344 0.69560582\n",
            " 0.76936297 0.79622226 0.838034   0.88461146 0.7735692  0.70525529\n",
            " 0.72710823 0.86767005 0.77795598 0.74992952 0.68443503 0.77685288\n",
            " 0.7948295  0.7644907  0.70081396 0.81568052 0.80603402 0.76288705\n",
            " 0.71504522 0.74177655 0.75565409 0.70096376]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.34365984 -0.3349845  -0.31964121 -0.32920835 -0.33945064 -0.38573148\n",
            " -0.32659982 -0.34630211 -0.31371825 -0.33773985 -0.36339586 -0.34473517\n",
            " -0.32653236 -0.28452818 -0.35971498 -0.38480298 -0.35803197 -0.34786607\n",
            " -0.39422628 -0.35490107 -0.3771355  -0.35907059 -0.29476749 -0.37697975\n",
            " -0.3655098  -0.35308016 -0.36163944 -0.35483063 -0.34786905 -0.34041585\n",
            " -0.34462505 -0.3716982  -0.35084463 -0.36090042 -0.33773985 -0.32545406\n",
            " -0.3537186  -0.33773985 -0.30683007 -0.35054802 -0.33669528 -0.31502527\n",
            " -0.30690348 -0.37008861 -0.38680681 -0.33494482 -0.35761971 -0.32232018\n",
            " -0.35914995 -0.33934052  0.19017498  0.29918604  0.18006762  0.24746492\n",
            "  0.20826172  0.11036393  0.38743436  0.15653168  0.21677835  0.1449268\n",
            "  0.26507492  0.25986083  0.22050486  0.30622401  0.27811819  0.24285238\n",
            "  0.24586128  0.09469327  0.07707774  0.31462754  0.19392333  0.31728468\n",
            "  0.10347278  0.29601248  0.2107909   0.18144211  0.30714656  0.30439418\n",
            "  0.23063703  0.20377774  0.161966    0.11538854  0.2264308   0.29474471\n",
            "  0.27289177  0.13232995  0.22204402  0.25007048  0.31556497  0.22314712\n",
            "  0.2051705   0.2355093   0.29918604  0.18431948  0.19396598  0.23711295\n",
            "  0.28495478  0.25822345  0.24434591  0.29903624]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601]\n",
            "Epoch - 10 starting.....\n",
            "Predicted Output from the Adaline Model in the 10 th step is as follows: [0.33261669 0.32550406 0.30954893 0.32023618 0.32828327 0.37470991\n",
            " 0.31667293 0.33601563 0.30516917 0.32817919 0.35179508 0.33508117\n",
            " 0.31700154 0.27457971 0.34570963 0.37135732 0.3455567  0.33700782\n",
            " 0.38287495 0.34363004 0.36703777 0.34824321 0.28268452 0.36809907\n",
            " 0.35694607 0.34419205 0.35208621 0.34401637 0.3369501  0.33141384\n",
            " 0.33574725 0.36124345 0.33829306 0.34750802 0.32817919 0.31459478\n",
            " 0.34177392 0.32817919 0.29765883 0.34012702 0.32560814 0.30771556\n",
            " 0.29721478 0.36064646 0.37717439 0.32578381 0.34652721 0.31272585\n",
            " 0.3476837  0.32894936 0.81865547 0.70748916 0.82735977 0.7596524\n",
            " 0.7997943  0.89893482 0.61841867 0.85178437 0.79156266 0.86228015\n",
            " 0.73954985 0.74673407 0.78587241 0.70092467 0.72922283 0.76318849\n",
            " 0.76036484 0.91294941 0.9345815  0.69196922 0.81289862 0.6888589\n",
            " 0.90638742 0.70907834 0.79567155 0.82514199 0.69745663 0.70018949\n",
            " 0.77715923 0.80222716 0.84593231 0.890525   0.78155037 0.7102595\n",
            " 0.73453117 0.87538696 0.78488909 0.75603143 0.6887898  0.78247346\n",
            " 0.80200072 0.76939083 0.70748916 0.82336384 0.8132361  0.76867839\n",
            " 0.72120184 0.74728221 0.76180996 0.70654332]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.33261669 -0.32550406 -0.30954893 -0.32023618 -0.32828327 -0.37470991\n",
            " -0.31667293 -0.33601563 -0.30516917 -0.32817919 -0.35179508 -0.33508117\n",
            " -0.31700154 -0.27457971 -0.34570963 -0.37135732 -0.3455567  -0.33700782\n",
            " -0.38287495 -0.34363004 -0.36703777 -0.34824321 -0.28268452 -0.36809907\n",
            " -0.35694607 -0.34419205 -0.35208621 -0.34401637 -0.3369501  -0.33141384\n",
            " -0.33574725 -0.36124345 -0.33829306 -0.34750802 -0.32817919 -0.31459478\n",
            " -0.34177392 -0.32817919 -0.29765883 -0.34012702 -0.32560814 -0.30771556\n",
            " -0.29721478 -0.36064646 -0.37717439 -0.32578381 -0.34652721 -0.31272585\n",
            " -0.3476837  -0.32894936  0.18134453  0.29251084  0.17264023  0.2403476\n",
            "  0.2002057   0.10106518  0.38158133  0.14821563  0.20843734  0.13771985\n",
            "  0.26045015  0.25326593  0.21412759  0.29907533  0.27077717  0.23681151\n",
            "  0.23963516  0.08705059  0.0654185   0.30803078  0.18710138  0.3111411\n",
            "  0.09361258  0.29092166  0.20432845  0.17485801  0.30254337  0.29981051\n",
            "  0.22284077  0.19777284  0.15406769  0.109475    0.21844963  0.2897405\n",
            "  0.26546883  0.12461304  0.21511091  0.24396857  0.3112102   0.21752654\n",
            "  0.19799928  0.23060917  0.29251084  0.17663616  0.1867639   0.23132161\n",
            "  0.27879816  0.25271779  0.23819004  0.29345668]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998]\n",
            "Epoch - 11 starting.....\n",
            "Predicted Output from the Adaline Model in the 11 th step is as follows: [0.3218812  0.31628444 0.29973757 0.31151027 0.31742786 0.36399261\n",
            " 0.30702194 0.32601373 0.29685479 0.31888138 0.34051718 0.32569291\n",
            " 0.30773355 0.26491053 0.33210011 0.35828952 0.3334319  0.32645159\n",
            " 0.37183657 0.33267322 0.35721608 0.33771645 0.27094515 0.35945858\n",
            " 0.34861344 0.33554529 0.34279467 0.33350188 0.32633455 0.3226581\n",
            " 0.32711145 0.35107649 0.32609441 0.33449327 0.31888138 0.30403889\n",
            " 0.33016302 0.31888138 0.28874176 0.32999423 0.31483091 0.30060258\n",
            " 0.28779607 0.35146259 0.36780431 0.31687432 0.33574302 0.30339725\n",
            " 0.33653668 0.3188464  0.82715986 0.71391055 0.83450069 0.76649786\n",
            " 0.8075479  0.90788442 0.62404992 0.85978409 0.7995916  0.86920599\n",
            " 0.7439802  0.7530739  0.79199848 0.70780595 0.73628962 0.7689912\n",
            " 0.76634583 0.92029271 0.94581761 0.69831407 0.81945441 0.69476674\n",
            " 0.91588041 0.71396231 0.80187979 0.83146452 0.70186879 0.70458277\n",
            " 0.78466235 0.80798909 0.85352746 0.89619241 0.78923274 0.71505867\n",
            " 0.74167386 0.8828048  0.79155593 0.76189248 0.69296209 0.78786595\n",
            " 0.80889646 0.77408619 0.71391055 0.83075426 0.82016133 0.77423822\n",
            " 0.72711856 0.75256607 0.76772469 0.71190213]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.3218812  -0.31628444 -0.29973757 -0.31151027 -0.31742786 -0.36399261\n",
            " -0.30702194 -0.32601373 -0.29685479 -0.31888138 -0.34051718 -0.32569291\n",
            " -0.30773355 -0.26491053 -0.33210011 -0.35828952 -0.3334319  -0.32645159\n",
            " -0.37183657 -0.33267322 -0.35721608 -0.33771645 -0.27094515 -0.35945858\n",
            " -0.34861344 -0.33554529 -0.34279467 -0.33350188 -0.32633455 -0.3226581\n",
            " -0.32711145 -0.35107649 -0.32609441 -0.33449327 -0.31888138 -0.30403889\n",
            " -0.33016302 -0.31888138 -0.28874176 -0.32999423 -0.31483091 -0.30060258\n",
            " -0.28779607 -0.35146259 -0.36780431 -0.31687432 -0.33574302 -0.30339725\n",
            " -0.33653668 -0.3188464   0.17284014  0.28608945  0.16549931  0.23350214\n",
            "  0.1924521   0.09211558  0.37595008  0.14021591  0.2004084   0.13079401\n",
            "  0.2560198   0.2469261   0.20800152  0.29219405  0.26371038  0.2310088\n",
            "  0.23365417  0.07970729  0.05418239  0.30168593  0.18054559  0.30523326\n",
            "  0.08411959  0.28603769  0.19812021  0.16853548  0.29813121  0.29541723\n",
            "  0.21533765  0.19201091  0.14647254  0.10380759  0.21076726  0.28494133\n",
            "  0.25832614  0.1171952   0.20844407  0.23810752  0.30703791  0.21213405\n",
            "  0.19110354  0.22591381  0.28608945  0.16924574  0.17983867  0.22576178\n",
            "  0.27288144  0.24743393  0.23227531  0.28809787]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255]\n",
            "Epoch - 12 starting.....\n",
            "Predicted Output from the Adaline Model in the 12 th step is as follows: [0.31146492 0.3073374  0.29021785 0.30304237 0.30689566 0.35359318\n",
            " 0.29765797 0.31630841 0.28878625 0.30985838 0.32957444 0.31658263\n",
            " 0.2987398  0.2555297  0.31889737 0.34561203 0.32166905 0.31620912\n",
            " 0.36112505 0.32204257 0.34768407 0.32750263 0.25955792 0.35107232\n",
            " 0.34052573 0.32715287 0.33377783 0.32329935 0.31603418 0.31416095\n",
            " 0.31873021 0.34121041 0.31426    0.32186752 0.30985838 0.29379703\n",
            " 0.31889749 0.30985838 0.28008936 0.32016181 0.30437468 0.29369797\n",
            " 0.27865765 0.34255037 0.3587109  0.3082282  0.32527941 0.29434548\n",
            " 0.32572104 0.30904323 0.83538147 0.72011514 0.84139843 0.77311139\n",
            " 0.81504119 0.91653266 0.62949165 0.86751263 0.80735049 0.87589554\n",
            " 0.74825386 0.75919761 0.7979141  0.71445662 0.74312027 0.77459511\n",
            " 0.7721213  0.92738443 0.95668099 0.70444341 0.82578625 0.70047461\n",
            " 0.92505462 0.71867588 0.80787519 0.83756856 0.70612559 0.70882151\n",
            " 0.79191324 0.81354981 0.86086402 0.90165974 0.79665744 0.71968949\n",
            " 0.74857537 0.8899693  0.79799729 0.76755204 0.69698707 0.79307061\n",
            " 0.81555847 0.77861592 0.72011514 0.83789491 0.82685198 0.779606\n",
            " 0.73283283 0.7576666  0.77343763 0.71707677]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.31146492 -0.3073374  -0.29021785 -0.30304237 -0.30689566 -0.35359318\n",
            " -0.29765797 -0.31630841 -0.28878625 -0.30985838 -0.32957444 -0.31658263\n",
            " -0.2987398  -0.2555297  -0.31889737 -0.34561203 -0.32166905 -0.31620912\n",
            " -0.36112505 -0.32204257 -0.34768407 -0.32750263 -0.25955792 -0.35107232\n",
            " -0.34052573 -0.32715287 -0.33377783 -0.32329935 -0.31603418 -0.31416095\n",
            " -0.31873021 -0.34121041 -0.31426    -0.32186752 -0.30985838 -0.29379703\n",
            " -0.31889749 -0.30985838 -0.28008936 -0.32016181 -0.30437468 -0.29369797\n",
            " -0.27865765 -0.34255037 -0.3587109  -0.3082282  -0.32527941 -0.29434548\n",
            " -0.32572104 -0.30904323  0.16461853  0.27988486  0.15860157  0.22688861\n",
            "  0.18495881  0.08346734  0.37050835  0.13248737  0.19264951  0.12410446\n",
            "  0.25174614  0.24080239  0.2020859   0.28554338  0.25687973  0.22540489\n",
            "  0.2278787   0.07261557  0.04331901  0.29555659  0.17421375  0.29952539\n",
            "  0.07494538  0.28132412  0.19212481  0.16243144  0.29387441  0.29117849\n",
            "  0.20808676  0.18645019  0.13913598  0.09834026  0.20334256  0.28031051\n",
            "  0.25142463  0.1100307   0.20200271  0.23244796  0.30301293  0.20692939\n",
            "  0.18444153  0.22138408  0.27988486  0.16210509  0.17314802  0.220394\n",
            "  0.26716717  0.2423334   0.22656237  0.28292323]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575]\n",
            "Epoch - 13 starting.....\n",
            "Predicted Output from the Adaline Model in the 13 th step is as follows: [0.30136606 0.29866217 0.28098824 0.29483197 0.29668474 0.34351065\n",
            " 0.28857971 0.30689851 0.28096305 0.30110942 0.31896506 0.30774964\n",
            " 0.29001932 0.24643512 0.30609778 0.33332207 0.31026555 0.30627884\n",
            " 0.35073935 0.31173636 0.33844136 0.31760038 0.24851934 0.3429407\n",
            " 0.33268346 0.31901479 0.32503533 0.31340741 0.30604739 0.30592207\n",
            " 0.31060339 0.33164436 0.30278713 0.30962761 0.30110942 0.28386719\n",
            " 0.30797509 0.30110942 0.27170052 0.31062859 0.29423749 0.28700212\n",
            " 0.26979802 0.33390963 0.34989423 0.29984487 0.31513486 0.28556944\n",
            " 0.31523498 0.29953849 0.84334184 0.72612087 0.84807383 0.77951234\n",
            " 0.82229488 0.92490312 0.63475951 0.87499201 0.8148602  0.88237004\n",
            " 0.75238791 0.76512387 0.80363851 0.7208948  0.74973348 0.7800187\n",
            " 0.77770997 0.93424724 0.96719757 0.71037491 0.83191417 0.7059997\n",
            " 0.9339342  0.72323593 0.81367723 0.84347436 0.71024333 0.71292202\n",
            " 0.79893199 0.81892877 0.86796356 0.90694802 0.80384476 0.72416891\n",
            " 0.75525486 0.89690237 0.80423272 0.77302864 0.70088067 0.79810606\n",
            " 0.82200677 0.78299778 0.72612087 0.84480665 0.83332832 0.78480016\n",
            " 0.73836247 0.76260169 0.77896733 0.72208442]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.30136606 -0.29866217 -0.28098824 -0.29483197 -0.29668474 -0.34351065\n",
            " -0.28857971 -0.30689851 -0.28096305 -0.30110942 -0.31896506 -0.30774964\n",
            " -0.29001932 -0.24643512 -0.30609778 -0.33332207 -0.31026555 -0.30627884\n",
            " -0.35073935 -0.31173636 -0.33844136 -0.31760038 -0.24851934 -0.3429407\n",
            " -0.33268346 -0.31901479 -0.32503533 -0.31340741 -0.30604739 -0.30592207\n",
            " -0.31060339 -0.33164436 -0.30278713 -0.30962761 -0.30110942 -0.28386719\n",
            " -0.30797509 -0.30110942 -0.27170052 -0.31062859 -0.29423749 -0.28700212\n",
            " -0.26979802 -0.33390963 -0.34989423 -0.29984487 -0.31513486 -0.28556944\n",
            " -0.31523498 -0.29953849  0.15665816  0.27387913  0.15192617  0.22048766\n",
            "  0.17770512  0.07509688  0.36524049  0.12500799  0.1851398   0.11762996\n",
            "  0.24761209  0.23487613  0.19636149  0.2791052   0.25026652  0.2199813\n",
            "  0.22229003  0.06575276  0.03280243  0.28962509  0.16808583  0.2940003\n",
            "  0.0660658   0.27676407  0.18632277  0.15652564  0.28975667  0.28707798\n",
            "  0.20106801  0.18107123  0.13203644  0.09305198  0.19615524  0.27583109\n",
            "  0.24474514  0.10309763  0.19576728  0.22697136  0.29911933  0.20189394\n",
            "  0.17799323  0.21700222  0.27387913  0.15519335  0.16667168  0.21519984\n",
            "  0.26163753  0.23739831  0.22103267  0.27791558]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795]\n",
            "Epoch - 14 starting.....\n",
            "Predicted Output from the Adaline Model in the 14 th step is as follows: [0.29157794 0.29025326 0.27204264 0.28687396 0.28678826 0.33373863\n",
            " 0.27978125 0.297778   0.2733803  0.292629   0.30868204 0.29918838\n",
            " 0.28156655 0.23762056 0.2936923  0.32141122 0.29921359 0.29665422\n",
            " 0.34067291 0.30174775 0.32948228 0.30800327 0.23782146 0.33505903\n",
            " 0.32508215 0.31112622 0.31656181 0.30381964 0.29636762 0.29793642\n",
            " 0.3027261  0.32237231 0.29166791 0.29776501 0.292629   0.2742427\n",
            " 0.29738844 0.292629   0.2635698  0.30138844 0.28441252 0.28051121\n",
            " 0.26121132 0.32553512 0.34134906 0.2917191  0.30530273 0.27706346\n",
            " 0.3050716  0.29032598 0.851054   0.73193825 0.85453888 0.78571199\n",
            " 0.82932125 0.9330099  0.63986266 0.88223521 0.82213324 0.8886415\n",
            " 0.7563914  0.77086341 0.80918252 0.72713131 0.75614039 0.78527231\n",
            " 0.78312237 0.94089395 0.97738364 0.71611897 0.83784955 0.71135188\n",
            " 0.94253381 0.72765166 0.81929688 0.84919327 0.71423072 0.71689305\n",
            " 0.8057305  0.82413668 0.87483865 0.9120685  0.81080678 0.7285061\n",
            " 0.76172373 0.9036166  0.81027344 0.77833269 0.70465135 0.80298246\n",
            " 0.82825293 0.78724124 0.73193825 0.85150163 0.83960198 0.78983086\n",
            " 0.74371768 0.76738115 0.78432421 0.72693469]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.29157794 -0.29025326 -0.27204264 -0.28687396 -0.28678826 -0.33373863\n",
            " -0.27978125 -0.297778   -0.2733803  -0.292629   -0.30868204 -0.29918838\n",
            " -0.28156655 -0.23762056 -0.2936923  -0.32141122 -0.29921359 -0.29665422\n",
            " -0.34067291 -0.30174775 -0.32948228 -0.30800327 -0.23782146 -0.33505903\n",
            " -0.32508215 -0.31112622 -0.31656181 -0.30381964 -0.29636762 -0.29793642\n",
            " -0.3027261  -0.32237231 -0.29166791 -0.29776501 -0.292629   -0.2742427\n",
            " -0.29738844 -0.292629   -0.2635698  -0.30138844 -0.28441252 -0.28051121\n",
            " -0.26121132 -0.32553512 -0.34134906 -0.2917191  -0.30530273 -0.27706346\n",
            " -0.3050716  -0.29032598  0.148946    0.26806175  0.14546112  0.21428801\n",
            "  0.17067875  0.0669901   0.36013734  0.11776479  0.17786676  0.1113585\n",
            "  0.2436086   0.22913659  0.19081748  0.27286869  0.24385961  0.21472769\n",
            "  0.21687763  0.05910605  0.02261636  0.28388103  0.16215045  0.28864812\n",
            "  0.05746619  0.27234834  0.18070312  0.15080673  0.28576928  0.28310695\n",
            "  0.1942695   0.17586332  0.12516135  0.0879315   0.18919322  0.2714939\n",
            "  0.23827627  0.0963834   0.18972656  0.22166731  0.29534865  0.19701754\n",
            "  0.17174707  0.21275876  0.26806175  0.14849837  0.16039802  0.21016914\n",
            "  0.25628232  0.23261885  0.21567579  0.27306531]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497]\n",
            "Epoch - 15 starting.....\n",
            "Predicted Output from the Adaline Model in the 15 th step is as follows: [0.28209213 0.28210358 0.26337336 0.27916164 0.27719768 0.32426881\n",
            " 0.27125505 0.28893909 0.26603163 0.28440997 0.29871654 0.2908916\n",
            " 0.27337431 0.22907836 0.28167005 0.30986913 0.28850355 0.287327\n",
            " 0.33091719 0.29206816 0.32079932 0.29870308 0.22745482 0.32742078\n",
            " 0.31771555 0.30348061 0.30835015 0.29452784 0.28698658 0.29019731\n",
            " 0.29509176 0.31338643 0.28089267 0.28626937 0.28440997 0.26491525\n",
            " 0.28712841 0.28440997 0.25569026 0.29243349 0.27489128 0.27421989\n",
            " 0.25289016 0.31741984 0.33306829 0.28384405 0.2957746  0.26882028\n",
            " 0.29522214 0.28139783 0.85852753 0.73757477 0.86080208 0.79171837\n",
            " 0.83612923 0.94086328 0.64480764 0.88925157 0.8291788  0.89471829\n",
            " 0.76027019 0.7764238  0.81455362 0.73317403 0.76234908 0.79036303\n",
            " 0.7883658  0.94733346 0.98725156 0.72168302 0.84360029 0.71653816\n",
            " 0.95086422 0.73192927 0.8247417  0.85473307 0.71809351 0.72074032\n",
            " 0.81231743 0.8291808  0.88149826 0.91702857 0.81755231 0.73270723\n",
            " 0.76799023 0.91012085 0.81612735 0.78347135 0.70830461 0.80770665\n",
            " 0.8343051  0.79135246 0.73757477 0.85798852 0.84568118 0.79470502\n",
            " 0.74890556 0.77201161 0.78951545 0.73163415]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.28209213 -0.28210358 -0.26337336 -0.27916164 -0.27719768 -0.32426881\n",
            " -0.27125505 -0.28893909 -0.26603163 -0.28440997 -0.29871654 -0.2908916\n",
            " -0.27337431 -0.22907836 -0.28167005 -0.30986913 -0.28850355 -0.287327\n",
            " -0.33091719 -0.29206816 -0.32079932 -0.29870308 -0.22745482 -0.32742078\n",
            " -0.31771555 -0.30348061 -0.30835015 -0.29452784 -0.28698658 -0.29019731\n",
            " -0.29509176 -0.31338643 -0.28089267 -0.28626937 -0.28440997 -0.26491525\n",
            " -0.28712841 -0.28440997 -0.25569026 -0.29243349 -0.27489128 -0.27421989\n",
            " -0.25289016 -0.31741984 -0.33306829 -0.28384405 -0.2957746  -0.26882028\n",
            " -0.29522214 -0.28139783  0.14147247  0.26242523  0.13919792  0.20828163\n",
            "  0.16387077  0.05913672  0.35519236  0.11074843  0.1708212   0.10528171\n",
            "  0.23972981  0.2235762   0.18544638  0.26682597  0.23765092  0.20963697\n",
            "  0.2116342   0.05266654  0.01274844  0.27831698  0.15639971  0.28346184\n",
            "  0.04913578  0.26807073  0.1752583   0.14526693  0.28190649  0.27925968\n",
            "  0.18768257  0.1708192   0.11850174  0.08297143  0.18244769  0.26729277\n",
            "  0.23200977  0.08987915  0.18387265  0.21652865  0.29169539  0.19229335\n",
            "  0.1656949   0.20864754  0.26242523  0.14201148  0.15431882  0.20529498\n",
            "  0.25109444  0.22798839  0.21048455  0.26836585]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894]\n",
            "Epoch - 16 starting.....\n",
            "Predicted Output from the Adaline Model in the 16 th step is as follows: [0.27289973 0.27420552 0.25497228 0.27168783 0.26790398 0.31509235\n",
            " 0.2629931  0.28037353 0.25891018 0.27644466 0.28905922 0.28285158\n",
            " 0.26543496 0.22080048 0.27001967 0.2986849  0.27812535 0.27828844\n",
            " 0.32146308 0.28268849 0.31238442 0.2896911  0.21740959 0.32001891\n",
            " 0.31057683 0.29607087 0.3003927  0.28552332 0.27789547 0.28269753\n",
            " 0.28769328 0.30467834 0.27045123 0.27512983 0.27644466 0.25587607\n",
            " 0.27718537 0.27644466 0.24805454 0.28375538 0.26566484 0.26812238\n",
            " 0.24482674 0.30955622 0.32504421 0.27621239 0.28654153 0.26083218\n",
            " 0.28567738 0.27274568 0.86577055 0.74303668 0.86687043 0.79753816\n",
            " 0.8427263  0.94847192 0.64959993 0.89604889 0.83600465 0.90060723\n",
            " 0.76402883 0.78181127 0.81975788 0.73902959 0.76836634 0.79529662\n",
            " 0.79344621 0.95357304 0.99681203 0.72707327 0.84917286 0.7215643\n",
            " 0.9589346  0.73607371 0.83001784 0.8601001  0.72183621 0.72446832\n",
            " 0.81870004 0.83406697 0.88794985 0.92183406 0.82408875 0.73677718\n",
            " 0.77406132 0.91642243 0.82180094 0.78845047 0.71184472 0.81228408\n",
            " 0.84017002 0.79533625 0.74303668 0.86427451 0.85157269 0.79942821\n",
            " 0.75393196 0.77649838 0.79454688 0.73618813]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.27289973 -0.27420552 -0.25497228 -0.27168783 -0.26790398 -0.31509235\n",
            " -0.2629931  -0.28037353 -0.25891018 -0.27644466 -0.28905922 -0.28285158\n",
            " -0.26543496 -0.22080048 -0.27001967 -0.2986849  -0.27812535 -0.27828844\n",
            " -0.32146308 -0.28268849 -0.31238442 -0.2896911  -0.21740959 -0.32001891\n",
            " -0.31057683 -0.29607087 -0.3003927  -0.28552332 -0.27789547 -0.28269753\n",
            " -0.28769328 -0.30467834 -0.27045123 -0.27512983 -0.27644466 -0.25587607\n",
            " -0.27718537 -0.27644466 -0.24805454 -0.28375538 -0.26566484 -0.26812238\n",
            " -0.24482674 -0.30955622 -0.32504421 -0.27621239 -0.28654153 -0.26083218\n",
            " -0.28567738 -0.27274568  0.13422945  0.25696332  0.13312957  0.20246184\n",
            "  0.1572737   0.05152808  0.35040007  0.10395111  0.16399535  0.09939277\n",
            "  0.23597117  0.21818873  0.18024212  0.26097041  0.23163366  0.20470338\n",
            "  0.20655379  0.04642696  0.00318797  0.27292673  0.15082714  0.2784357\n",
            "  0.0410654   0.26392629  0.16998216  0.1398999   0.27816379  0.27553168\n",
            "  0.18129996  0.16593303  0.11205015  0.07816594  0.17591125  0.26322282\n",
            "  0.22593868  0.08357757  0.17819906  0.21154953  0.28815528  0.18771592\n",
            "  0.15982998  0.20466375  0.25696332  0.13572549  0.14842731  0.20057179\n",
            "  0.24606804  0.22350162  0.20545312  0.26381187]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785]\n",
            "Epoch - 17 starting.....\n",
            "Predicted Output from the Adaline Model in the 17 th step is as follows: [0.26399183 0.26655147 0.24683126 0.26444531 0.25889816 0.30620036\n",
            " 0.25498739 0.27207302 0.25200909 0.2687254  0.27970074 0.27506054\n",
            " 0.25774085 0.21277887 0.25872985 0.28784766 0.26806889 0.26952978\n",
            " 0.31230144 0.27359965 0.30422946 0.28095859 0.20767598 0.31284626\n",
            " 0.30365914 0.28888988 0.29268177 0.27679738 0.26908551 0.27542986\n",
            " 0.28052353 0.29623961 0.26033345 0.26433555 0.2687254  0.24711642\n",
            " 0.26754967 0.2687254  0.24065522 0.2753457  0.25672423 0.26221283\n",
            " 0.23701322 0.30193666 0.31726906 0.26881674 0.27759457 0.25309145\n",
            " 0.27642806 0.26436115 0.87279049 0.74832964 0.87275026 0.80317742\n",
            " 0.84911928 0.95584372 0.65424446 0.90263426 0.84261786 0.90631445\n",
            " 0.76767133 0.78703144 0.82480077 0.74470403 0.77419835 0.80007821\n",
            " 0.79836891 0.95961922 1.00607487 0.73229536 0.85457306 0.7264355\n",
            " 0.96675332 0.74008935 0.83513083 0.86529999 0.72546281 0.728081\n",
            " 0.82488492 0.83880037 0.89420014 0.92649009 0.83042286 0.74072026\n",
            " 0.7799433  0.92252794 0.82730008 0.79327524 0.71527546 0.81671958\n",
            " 0.84585378 0.79919686 0.74832964 0.87036612 0.85728259 0.80400537\n",
            " 0.75880215 0.78084619 0.79942373 0.74060138]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.26399183 -0.26655147 -0.24683126 -0.26444531 -0.25889816 -0.30620036\n",
            " -0.25498739 -0.27207302 -0.25200909 -0.2687254  -0.27970074 -0.27506054\n",
            " -0.25774085 -0.21277887 -0.25872985 -0.28784766 -0.26806889 -0.26952978\n",
            " -0.31230144 -0.27359965 -0.30422946 -0.28095859 -0.20767598 -0.31284626\n",
            " -0.30365914 -0.28888988 -0.29268177 -0.27679738 -0.26908551 -0.27542986\n",
            " -0.28052353 -0.29623961 -0.26033345 -0.26433555 -0.2687254  -0.24711642\n",
            " -0.26754967 -0.2687254  -0.24065522 -0.2753457  -0.25672423 -0.26221283\n",
            " -0.23701322 -0.30193666 -0.31726906 -0.26881674 -0.27759457 -0.25309145\n",
            " -0.27642806 -0.26436115  0.12720951  0.25167036  0.12724974  0.19682258\n",
            "  0.15088072  0.04415628  0.34575554  0.09736574  0.15738214  0.09368555\n",
            "  0.23232867  0.21296856  0.17519923  0.25529597  0.22580165  0.19992179\n",
            "  0.20163109  0.04038078 -0.00607487  0.26770464  0.14542694  0.2735645\n",
            "  0.03324668  0.25991065  0.16486917  0.13470001  0.27453719  0.271919\n",
            "  0.17511508  0.16119963  0.10579986  0.07350991  0.16957714  0.25927974\n",
            "  0.2200567   0.07747206  0.17269992  0.20672476  0.28472454  0.18328042\n",
            "  0.15414622  0.20080314  0.25167036  0.12963388  0.14271741  0.19599463\n",
            "  0.24119785  0.21915381  0.20057627  0.25939862]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607]\n",
            "Epoch - 18 starting.....\n",
            "Predicted Output from the Adaline Model in the 18 th step is as follows: [0.25535971 0.25913394 0.23894229 0.25742698 0.25017136 0.29758409\n",
            " 0.24723005 0.26402943 0.24532157 0.26124463 0.27063189 0.26751082\n",
            " 0.25028445 0.20500566 0.24778949 0.27734674 0.25832428 0.26104241\n",
            " 0.3034233  0.26479268 0.29632648 0.27249695 0.19824441 0.30589581\n",
            " 0.29695568 0.28193063 0.2852098  0.26834144 0.26054805 0.26838716\n",
            " 0.2735755  0.28806199 0.25052938 0.25387592 0.26124463 0.23862769\n",
            " 0.25821189 0.26124463 0.23348506 0.26719622 0.24806067 0.25648547\n",
            " 0.22944194 0.29455365 0.30973521 0.26164986 0.26892493 0.24559046\n",
            " 0.26746511 0.25623604 0.87959436 0.75345897 0.87844754 0.80864184\n",
            " 0.85531458 0.96298614 0.6587459  0.90901437 0.84902513 0.91184569\n",
            " 0.77120137 0.79208959 0.82968737 0.75020306 0.77985094 0.80471261\n",
            " 0.8031389  0.9654781  1.01504944 0.73735457 0.85980635 0.73115664\n",
            " 0.97432829 0.74398028 0.84008581 0.87033804 0.72897699 0.73158203\n",
            " 0.8308783  0.84338584 0.90025551 0.9310014  0.83656101 0.74454051\n",
            " 0.78564213 0.92844357 0.83263028 0.79795055 0.7186003  0.82101764\n",
            " 0.85136209 0.80293819 0.75345897 0.87626948 0.86281663 0.80844113\n",
            " 0.76352106 0.78505945 0.80415088 0.74487837]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.25535971 -0.25913394 -0.23894229 -0.25742698 -0.25017136 -0.29758409\n",
            " -0.24723005 -0.26402943 -0.24532157 -0.26124463 -0.27063189 -0.26751082\n",
            " -0.25028445 -0.20500566 -0.24778949 -0.27734674 -0.25832428 -0.26104241\n",
            " -0.3034233  -0.26479268 -0.29632648 -0.27249695 -0.19824441 -0.30589581\n",
            " -0.29695568 -0.28193063 -0.2852098  -0.26834144 -0.26054805 -0.26838716\n",
            " -0.2735755  -0.28806199 -0.25052938 -0.25387592 -0.26124463 -0.23862769\n",
            " -0.25821189 -0.26124463 -0.23348506 -0.26719622 -0.24806067 -0.25648547\n",
            " -0.22944194 -0.29455365 -0.30973521 -0.26164986 -0.26892493 -0.24559046\n",
            " -0.26746511 -0.25623604  0.12040564  0.24654103  0.12155246  0.19135816\n",
            "  0.14468542  0.03701386  0.3412541   0.09098563  0.15097487  0.08815431\n",
            "  0.22879863  0.20791041  0.17031263  0.24979694  0.22014906  0.19528739\n",
            "  0.1968611   0.0345219  -0.01504944  0.26264543  0.14019365  0.26884336\n",
            "  0.02567171  0.25601972  0.15991419  0.12966196  0.27102301  0.26841797\n",
            "  0.1691217   0.15661416  0.09974449  0.0689986   0.16343899  0.25545949\n",
            "  0.21435787  0.07155643  0.16736972  0.20204945  0.2813997   0.17898236\n",
            "  0.14863791  0.19706181  0.24654103  0.12373052  0.13718337  0.19155887\n",
            "  0.23647894  0.21494055  0.19584912  0.25512163]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743]\n",
            "Epoch - 19 starting.....\n",
            "Predicted Output from the Adaline Model in the 19 th step is as follows: [0.24699483 0.25194562 0.23129761 0.25062591 0.24171497 0.28923505\n",
            " 0.23971341 0.25623483 0.23884105 0.25399498 0.26184375 0.26019498\n",
            " 0.2430584  0.19747318 0.2371878  0.26717175 0.24888189 0.25281797\n",
            " 0.2948199  0.2562589  0.28866769 0.26429783 0.18910553 0.2991607\n",
            " 0.29045985 0.27518627 0.27796941 0.26014719 0.25227468 0.26156249\n",
            " 0.26684234 0.2801374  0.24102933 0.2437406  0.25399498 0.23040153\n",
            " 0.24916281 0.25399498 0.22653698 0.2592989  0.23966561 0.25093469\n",
            " 0.2221054  0.28739991 0.30243521 0.25470469 0.26052405 0.23832184\n",
            " 0.25877968 0.24836233 0.88618889 0.75842979 0.88396795 0.81393687\n",
            " 0.86131838 0.96990633 0.6631087  0.91519561 0.85523288 0.91720645\n",
            " 0.77462249 0.79699079 0.83442258 0.75553214 0.78532972 0.80920443\n",
            " 0.80776094 0.97115554 1.0237447  0.74225599 0.86487794 0.73573242\n",
            " 0.98166712 0.74775041 0.84488773 0.87521931 0.73238227 0.73497491\n",
            " 0.83668616 0.84782801 0.90612202 0.93537253 0.8425093  0.74824178\n",
            " 0.79116352 0.93417523 0.8377968  0.80248108 0.72182255 0.82518257\n",
            " 0.85670044 0.80656398 0.75842979 0.88199045 0.8681803  0.81273992\n",
            " 0.76809342 0.78914235 0.80873301 0.74902336]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.24699483 -0.25194562 -0.23129761 -0.25062591 -0.24171497 -0.28923505\n",
            " -0.23971341 -0.25623483 -0.23884105 -0.25399498 -0.26184375 -0.26019498\n",
            " -0.2430584  -0.19747318 -0.2371878  -0.26717175 -0.24888189 -0.25281797\n",
            " -0.2948199  -0.2562589  -0.28866769 -0.26429783 -0.18910553 -0.2991607\n",
            " -0.29045985 -0.27518627 -0.27796941 -0.26014719 -0.25227468 -0.26156249\n",
            " -0.26684234 -0.2801374  -0.24102933 -0.2437406  -0.25399498 -0.23040153\n",
            " -0.24916281 -0.25399498 -0.22653698 -0.2592989  -0.23966561 -0.25093469\n",
            " -0.2221054  -0.28739991 -0.30243521 -0.25470469 -0.26052405 -0.23832184\n",
            " -0.25877968 -0.24836233  0.11381111  0.24157021  0.11603205  0.18606313\n",
            "  0.13868162  0.03009367  0.3368913   0.08480439  0.14476712  0.08279355\n",
            "  0.22537751  0.20300921  0.16557742  0.24446786  0.21467028  0.19079557\n",
            "  0.19223906  0.02884446 -0.0237447   0.25774401  0.13512206  0.26426758\n",
            "  0.01833288  0.25224959  0.15511227  0.12478069  0.26761773  0.26502509\n",
            "  0.16331384  0.15217199  0.09387798  0.06462747  0.1574907   0.25175822\n",
            "  0.20883648  0.06582477  0.1622032   0.19751892  0.27817745  0.17481743\n",
            "  0.14329956  0.19343602  0.24157021  0.11800955  0.1318197   0.18726008\n",
            "  0.23190658  0.21085765  0.19126699  0.25097664]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667]\n",
            "Epoch - 20 starting.....\n",
            "Predicted Output from the Adaline Model in the 20 th step is as follows: [0.23888893 0.24497942 0.22388966 0.2440354  0.23352062 0.28114496\n",
            " 0.23243002 0.24868152 0.23256112 0.24696931 0.25332763 0.25310579\n",
            " 0.2360556  0.19017399 0.22691431 0.25731261 0.23973237 0.24484832\n",
            " 0.28648275 0.24798985 0.28124555 0.25635311 0.18025029 0.29263428\n",
            " 0.28416524 0.26865015 0.27095344 0.25220651 0.24425724 0.25494911\n",
            " 0.26031741 0.27245803 0.23182389 0.23391956 0.24696931 0.22242982\n",
            " 0.24039352 0.24696931 0.2198041  0.25164595 0.23153073 0.24555503\n",
            " 0.21499636 0.28046834 0.29536183 0.24797438 0.25238361 0.23127838\n",
            " 0.2503632  0.24073224 0.89258059 0.763247   0.88931699 0.81906778\n",
            " 0.86713662 0.97661119 0.66733718 0.92118416 0.8612473  0.92240203\n",
            " 0.77793807 0.8017399  0.83901109 0.76069655 0.79064007 0.81355809\n",
            " 0.81223963 0.97665718 1.03216933 0.74700453 0.86979285 0.74016735\n",
            " 0.98877713 0.75140349 0.84954134 0.87994866 0.73568204 0.738263\n",
            " 0.84231425 0.85213134 0.91180555 0.93960783 0.84827364 0.75182775\n",
            " 0.79651298 0.93972866 0.84280474 0.80687132 0.72494542 0.82921851\n",
            " 0.8618741  0.81007784 0.763247   0.88753471 0.87337889 0.81690599\n",
            " 0.77252377 0.79309896 0.81317463 0.75304043]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.23888893 -0.24497942 -0.22388966 -0.2440354  -0.23352062 -0.28114496\n",
            " -0.23243002 -0.24868152 -0.23256112 -0.24696931 -0.25332763 -0.25310579\n",
            " -0.2360556  -0.19017399 -0.22691431 -0.25731261 -0.23973237 -0.24484832\n",
            " -0.28648275 -0.24798985 -0.28124555 -0.25635311 -0.18025029 -0.29263428\n",
            " -0.28416524 -0.26865015 -0.27095344 -0.25220651 -0.24425724 -0.25494911\n",
            " -0.26031741 -0.27245803 -0.23182389 -0.23391956 -0.24696931 -0.22242982\n",
            " -0.24039352 -0.24696931 -0.2198041  -0.25164595 -0.23153073 -0.24555503\n",
            " -0.21499636 -0.28046834 -0.29536183 -0.24797438 -0.25238361 -0.23127838\n",
            " -0.2503632  -0.24073224  0.10741941  0.236753    0.11068301  0.18093222\n",
            "  0.13286338  0.02338881  0.33266282  0.07881584  0.1387527   0.07759797\n",
            "  0.22206193  0.1982601   0.16098891  0.23930345  0.20935993  0.18644191\n",
            "  0.18776037  0.02334282 -0.03216933  0.25299547  0.13020715  0.25983265\n",
            "  0.01122287  0.24859651  0.15045866  0.12005134  0.26431796  0.261737\n",
            "  0.15768575  0.14786866  0.08819445  0.06039217  0.15172636  0.24817225\n",
            "  0.20348702  0.06027134  0.15719526  0.19312868  0.27505458  0.17078149\n",
            "  0.1381259   0.18992216  0.236753    0.11246529  0.12662111  0.18309401\n",
            "  0.22747623  0.20690104  0.18682537  0.24695957]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002]\n",
            "Epoch - 21 starting.....\n",
            "Predicted Output from the Adaline Model in the 21 th step is as follows: [0.231034   0.23822848 0.21671111 0.23764891 0.22558021 0.27330581\n",
            " 0.22537266 0.24136201 0.22647558 0.24016069 0.24507511 0.24623624\n",
            " 0.22926913 0.18310085 0.21695885 0.24775954 0.23086666 0.23712557\n",
            " 0.2784036  0.23997733 0.27405272 0.2486549  0.17166992 0.28631009\n",
            " 0.2780656  0.26231584 0.26415494 0.24451157 0.23648779 0.24854047\n",
            " 0.25399426 0.26501628 0.22290395 0.22440306 0.24016069 0.21470466\n",
            " 0.23189534 0.24016069 0.21327978 0.2442298  0.22364799 0.24034119\n",
            " 0.20810776 0.27375206 0.28850805 0.24145226 0.24449555 0.22445311\n",
            " 0.24220733 0.23333823 0.89877575 0.76791538 0.89449997 0.82403965\n",
            " 0.87277506 0.9831074  0.67143549 0.926986   0.86707439 0.92743755\n",
            " 0.78115138 0.80634165 0.84345747 0.7657014  0.79578721 0.81777788\n",
            " 0.81657942 0.98198847 1.04033172 0.75160493 0.87455595 0.7444658\n",
            " 0.99566542 0.75494315 0.85405124 0.88453082 0.73887957 0.74144956\n",
            " 0.84776815 0.85630012 0.91731178 0.94371153 0.85385971 0.75530201\n",
            " 0.80169584 0.94510938 0.84765902 0.81112563 0.72797199 0.83312945\n",
            " 0.86688817 0.81348322 0.76791538 0.89290774 0.87841751 0.82094346\n",
            " 0.77681652 0.79693319 0.81748009 0.75693357]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.231034   -0.23822848 -0.21671111 -0.23764891 -0.22558021 -0.27330581\n",
            " -0.22537266 -0.24136201 -0.22647558 -0.24016069 -0.24507511 -0.24623624\n",
            " -0.22926913 -0.18310085 -0.21695885 -0.24775954 -0.23086666 -0.23712557\n",
            " -0.2784036  -0.23997733 -0.27405272 -0.2486549  -0.17166992 -0.28631009\n",
            " -0.2780656  -0.26231584 -0.26415494 -0.24451157 -0.23648779 -0.24854047\n",
            " -0.25399426 -0.26501628 -0.22290395 -0.22440306 -0.24016069 -0.21470466\n",
            " -0.23189534 -0.24016069 -0.21327978 -0.2442298  -0.22364799 -0.24034119\n",
            " -0.20810776 -0.27375206 -0.28850805 -0.24145226 -0.24449555 -0.22445311\n",
            " -0.24220733 -0.23333823  0.10122425  0.23208462  0.10550003  0.17596035\n",
            "  0.12722494  0.0168926   0.32856451  0.073014    0.13292561  0.07256245\n",
            "  0.21884862  0.19365835  0.15654253  0.2342986   0.20421279  0.18222212\n",
            "  0.18342058  0.01801153 -0.04033172  0.24839507  0.12544405  0.2555342\n",
            "  0.00433458  0.24505685  0.14594876  0.11546918  0.26112043  0.25855044\n",
            "  0.15223185  0.14369988  0.08268822  0.05628847  0.14614029  0.24469799\n",
            "  0.19830416  0.05489062  0.15234098  0.18887437  0.27202801  0.16687055\n",
            "  0.13311183  0.18651678  0.23208462  0.10709226  0.12158249  0.17905654\n",
            "  0.22318348  0.20306681  0.18251991  0.24306643]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134]\n",
            "Epoch - 22 starting.....\n",
            "Predicted Output from the Adaline Model in the 22 th step is as follows: [0.22342226 0.23168612 0.20975485 0.23146014 0.21788586 0.26570983\n",
            " 0.21853434 0.23426909 0.22057839 0.2335624  0.23707803 0.23957951\n",
            " 0.22269229 0.17624677 0.20731157 0.23850306 0.22227596 0.22964207\n",
            " 0.27057446 0.2322134  0.26708211 0.24119559 0.1633559  0.28018186\n",
            " 0.27215492 0.25617708 0.25756718 0.23705475 0.22895866 0.24233025\n",
            " 0.24786665 0.25780479 0.21426066 0.21518169 0.2335624  0.20721844\n",
            " 0.22365988 0.2335624  0.20695754 0.23704311 0.21600958 0.23528804\n",
            " 0.20143278 0.26724442 0.28186708 0.23513191 0.23685206 0.21783929\n",
            " 0.23430401 0.226173   0.90478044 0.77243954 0.89952204 0.82885742\n",
            " 0.87823926 0.98940143 0.67540768 0.93260691 0.87271996 0.93231796\n",
            " 0.7842656  0.81080061 0.84776611 0.77055162 0.80077621 0.82186795\n",
            " 0.82078461 0.98715469 1.04823999 0.75606178 0.87917193 0.74863199\n",
            " 1.00233887 0.7583729  0.85842188 0.88897034 0.74197803 0.74453772\n",
            " 0.85305325 0.86033855 0.92264618 0.9476877  0.85927306 0.75866803\n",
            " 0.80671727 0.95032273 0.85236438 0.81524821 0.73090523 0.83691928\n",
            " 0.87174761 0.8167835  0.77243954 0.89811484 0.88330112 0.8248563\n",
            " 0.78097594 0.80064883 0.82165361 0.76070661]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.22342226 -0.23168612 -0.20975485 -0.23146014 -0.21788586 -0.26570983\n",
            " -0.21853434 -0.23426909 -0.22057839 -0.2335624  -0.23707803 -0.23957951\n",
            " -0.22269229 -0.17624677 -0.20731157 -0.23850306 -0.22227596 -0.22964207\n",
            " -0.27057446 -0.2322134  -0.26708211 -0.24119559 -0.1633559  -0.28018186\n",
            " -0.27215492 -0.25617708 -0.25756718 -0.23705475 -0.22895866 -0.24233025\n",
            " -0.24786665 -0.25780479 -0.21426066 -0.21518169 -0.2335624  -0.20721844\n",
            " -0.22365988 -0.2335624  -0.20695754 -0.23704311 -0.21600958 -0.23528804\n",
            " -0.20143278 -0.26724442 -0.28186708 -0.23513191 -0.23685206 -0.21783929\n",
            " -0.23430401 -0.226173    0.09521956  0.22756046  0.10047796  0.17114258\n",
            "  0.12176074  0.01059857  0.32459232  0.06739309  0.12728004  0.06768204\n",
            "  0.2157344   0.18919939  0.15223389  0.22944838  0.19922379  0.17813205\n",
            "  0.17921539  0.01284531 -0.04823999  0.24393822  0.12082807  0.25136801\n",
            " -0.00233887  0.2416271   0.14157812  0.11102966  0.25802197  0.25546228\n",
            "  0.14694675  0.13966145  0.07735382  0.0523123   0.14072694  0.24133197\n",
            "  0.19328273  0.04967727  0.14763562  0.18475179  0.26909477  0.16308072\n",
            "  0.12825239  0.1832165   0.22756046  0.10188516  0.11669888  0.1751437\n",
            "  0.21902406  0.19935117  0.17834639  0.23929339]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094]\n",
            "Epoch - 23 starting.....\n",
            "Predicted Output from the Adaline Model in the 23 th step is as follows: [0.21604619 0.22534589 0.203014   0.22546296 0.21042996 0.25834948\n",
            " 0.21190827 0.22739572 0.21486374 0.22716791 0.22932848 0.23312903\n",
            " 0.21631859 0.16960498 0.19796294 0.22953398 0.21395176 0.22239042\n",
            " 0.2629876  0.22469036 0.26032683 0.23396776 0.15529998 0.27424352\n",
            " 0.26642732 0.25022781 0.25118363 0.22982868 0.22166241 0.23631229\n",
            " 0.24192852 0.25081645 0.20588545 0.20624628 0.22716791 0.19996376\n",
            " 0.21567901 0.22716791 0.20083114 0.23007878 0.20860793 0.23039059\n",
            " 0.19496481 0.26093893 0.27543232 0.22900706 0.22944555 0.21143037\n",
            " 0.22664541 0.21922945 0.91060057 0.77682394 0.90438819 0.83352585\n",
            " 0.88353462 0.99549953 0.67925764 0.9380525  0.87818962 0.93704808\n",
            " 0.7872838  0.81512118 0.85194128 0.77525202 0.80561196 0.82583231\n",
            " 0.82485938 0.99216094 1.05590202 0.76037951 0.88364535 0.75267003\n",
            " 1.00880412 0.76169616 0.86265758 0.89327165 0.7449805  0.74753054\n",
            " 0.85817479 0.86425064 0.9278141  0.9515403  0.86451902 0.76192915\n",
            " 0.81158227 0.95537391 0.85692545 0.81924315 0.73374804 0.84059175\n",
            " 0.87645719 0.81998192 0.77682394 0.90316115 0.88803453 0.82864839\n",
            " 0.78500616 0.80424956 0.82569928 0.76436327]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.21604619 -0.22534589 -0.203014   -0.22546296 -0.21042996 -0.25834948\n",
            " -0.21190827 -0.22739572 -0.21486374 -0.22716791 -0.22932848 -0.23312903\n",
            " -0.21631859 -0.16960498 -0.19796294 -0.22953398 -0.21395176 -0.22239042\n",
            " -0.2629876  -0.22469036 -0.26032683 -0.23396776 -0.15529998 -0.27424352\n",
            " -0.26642732 -0.25022781 -0.25118363 -0.22982868 -0.22166241 -0.23631229\n",
            " -0.24192852 -0.25081645 -0.20588545 -0.20624628 -0.22716791 -0.19996376\n",
            " -0.21567901 -0.22716791 -0.20083114 -0.23007878 -0.20860793 -0.23039059\n",
            " -0.19496481 -0.26093893 -0.27543232 -0.22900706 -0.22944555 -0.21143037\n",
            " -0.22664541 -0.21922945  0.08939943  0.22317606  0.09561181  0.16647415\n",
            "  0.11646538  0.00450047  0.32074236  0.0619475   0.12181038  0.06295192\n",
            "  0.2127162   0.18487882  0.14805872  0.22474798  0.19438804  0.17416769\n",
            "  0.17514062  0.00783906 -0.05590202  0.23962049  0.11635465  0.24732997\n",
            " -0.00880412  0.23830384  0.13734242  0.10672835  0.2550195   0.25246946\n",
            "  0.14182521  0.13574936  0.0721859   0.0484597   0.13548098  0.23807085\n",
            "  0.18841773  0.04462609  0.14307455  0.18075685  0.26625196  0.15940825\n",
            "  0.12354281  0.18001808  0.22317606  0.09683885  0.11196547  0.17135161\n",
            "  0.21499384  0.19575044  0.17430072  0.23563673]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963]\n",
            "Epoch - 24 starting.....\n",
            "Predicted Output from the Adaline Model in the 24 th step is as follows: [0.20889848 0.21920152 0.19648189 0.21965144 0.20320512 0.25121748\n",
            " 0.20548788 0.22073511 0.20932596 0.22097094 0.22181878 0.22687839\n",
            " 0.21014173 0.16316888 0.1889037  0.22084342 0.2058858  0.21536344\n",
            " 0.25563551 0.21740075 0.25378023 0.22696425 0.14749417 0.2684892\n",
            " 0.26087715 0.24446218 0.24499796 0.22282621 0.21459183 0.23048064\n",
            " 0.236174   0.24404432 0.19777003 0.197588   0.22097094 0.19293343\n",
            " 0.20794484 0.22097094 0.1948945  0.22332993 0.2014357  0.22564404\n",
            " 0.18869743 0.25482936 0.26919739 0.22307166 0.2222687  0.20521999\n",
            " 0.21922396 0.21250073 0.91624186 0.78107292 0.90910325 0.83804957\n",
            " 0.88866638 1.00140778 0.68298917 0.9433282  0.88348884 0.94163255\n",
            " 0.79020894 0.81930767 0.85598711 0.77980722 0.81029921 0.82967485\n",
            " 0.82880776 0.99701219 1.06332543 0.76456246 0.88798063 0.75658387\n",
            " 1.01506762 0.76491621 0.86676252 0.89743902 0.74788994 0.75043096\n",
            " 0.86313783 0.86804032 0.93282069 0.95527314 0.86960279 0.76508862\n",
            " 0.81629568 0.96026794 0.86134668 0.8231144  0.73650323 0.84415048\n",
            " 0.88102157 0.82308165 0.78107292 0.90805165 0.89262238 0.83232347\n",
            " 0.78891117 0.80773893 0.82962106 0.76790716]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.20889848 -0.21920152 -0.19648189 -0.21965144 -0.20320512 -0.25121748\n",
            " -0.20548788 -0.22073511 -0.20932596 -0.22097094 -0.22181878 -0.22687839\n",
            " -0.21014173 -0.16316888 -0.1889037  -0.22084342 -0.2058858  -0.21536344\n",
            " -0.25563551 -0.21740075 -0.25378023 -0.22696425 -0.14749417 -0.2684892\n",
            " -0.26087715 -0.24446218 -0.24499796 -0.22282621 -0.21459183 -0.23048064\n",
            " -0.236174   -0.24404432 -0.19777003 -0.197588   -0.22097094 -0.19293343\n",
            " -0.20794484 -0.22097094 -0.1948945  -0.22332993 -0.2014357  -0.22564404\n",
            " -0.18869743 -0.25482936 -0.26919739 -0.22307166 -0.2222687  -0.20521999\n",
            " -0.21922396 -0.21250073  0.08375814  0.21892708  0.09089675  0.16195043\n",
            "  0.11133362 -0.00140778  0.31701083  0.0566718   0.11651116  0.05836745\n",
            "  0.20979106  0.18069233  0.14401289  0.22019278  0.18970079  0.17032515\n",
            "  0.17119224  0.00298781 -0.06332543  0.23543754  0.11201937  0.24341613\n",
            " -0.01506762  0.23508379  0.13323748  0.10256098  0.25211006  0.24956904\n",
            "  0.13686217  0.13195968  0.06717931  0.04472686  0.13039721  0.23491138\n",
            "  0.18370432  0.03973206  0.13865332  0.1768856   0.26349677  0.15584952\n",
            "  0.11897843  0.17691835  0.21892708  0.09194835  0.10737762  0.16767653\n",
            "  0.21108883  0.19226107  0.17037894  0.23209284]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957]\n",
            "Epoch - 25 starting.....\n",
            "Predicted Output from the Adaline Model in the 25 th step is as follows: [0.20197206 0.21324695 0.19015205 0.21401983 0.19620419 0.24430674\n",
            " 0.19926679 0.21428067 0.20395958 0.21496534 0.21454152 0.22082142\n",
            " 0.20415563 0.15693211 0.18012488 0.21242273 0.19807009 0.20855417\n",
            " 0.24851091 0.21033734 0.24743583 0.22017812 0.13993071 0.2629132\n",
            " 0.2554989  0.23887448 0.23900406 0.21604043 0.20773993 0.22482954\n",
            " 0.23059741 0.23748173 0.18990634 0.18919825 0.21496534 0.18612051\n",
            " 0.20044973 0.21496534 0.18914175 0.21678988 0.1944858  0.22104371\n",
            " 0.18262443 0.24890962 0.2631561  0.21731986 0.21531439 0.199202\n",
            " 0.21203231 0.20598017 0.92170984 0.78519066 0.91367189 0.84243307\n",
            " 0.89363959 1.00713206 0.68660592 0.94843928 0.88862287 0.94607589\n",
            " 0.79304392 0.82336423 0.85990762 0.78422173 0.81484255 0.83339936\n",
            " 0.83263366 1.00171324 1.07051762 0.76861478 0.89218205 0.76037737\n",
            " 1.02113564 0.76803627 0.87074075 0.9014766  0.75070923 0.75324186\n",
            " 0.86794727 0.87171138 0.93767094 0.95888995 0.87452938 0.76814959\n",
            " 0.8208622  0.96500968 0.86563242 0.82686579 0.73917349 0.847599\n",
            " 0.88544524 0.82608574 0.78519066 0.91279116 0.89706919 0.83588515\n",
            " 0.79269486 0.8111204  0.83342278 0.77134177]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.20197206 -0.21324695 -0.19015205 -0.21401983 -0.19620419 -0.24430674\n",
            " -0.19926679 -0.21428067 -0.20395958 -0.21496534 -0.21454152 -0.22082142\n",
            " -0.20415563 -0.15693211 -0.18012488 -0.21242273 -0.19807009 -0.20855417\n",
            " -0.24851091 -0.21033734 -0.24743583 -0.22017812 -0.13993071 -0.2629132\n",
            " -0.2554989  -0.23887448 -0.23900406 -0.21604043 -0.20773993 -0.22482954\n",
            " -0.23059741 -0.23748173 -0.18990634 -0.18919825 -0.21496534 -0.18612051\n",
            " -0.20044973 -0.21496534 -0.18914175 -0.21678988 -0.1944858  -0.22104371\n",
            " -0.18262443 -0.24890962 -0.2631561  -0.21731986 -0.21531439 -0.199202\n",
            " -0.21203231 -0.20598017  0.07829016  0.21480934  0.08632811  0.15756693\n",
            "  0.10636041 -0.00713206  0.31339408  0.05156072  0.11137713  0.05392411\n",
            "  0.20695608  0.17663577  0.14009238  0.21577827  0.18515745  0.16660064\n",
            "  0.16736634 -0.00171324 -0.07051762  0.23138522  0.10781795  0.23962263\n",
            " -0.02113564  0.23196373  0.12925925  0.0985234   0.24929077  0.24675814\n",
            "  0.13205273  0.12828862  0.06232906  0.04111005  0.12547062  0.23185041\n",
            "  0.1791378   0.03499032  0.13436758  0.17313421  0.26082651  0.152401\n",
            "  0.11455476  0.17391426  0.21480934  0.08720884  0.10293081  0.16411485\n",
            "  0.20730514  0.1888796   0.16657722  0.22865823]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234]\n",
            "Epoch - 26 starting.....\n",
            "Predicted Output from the Adaline Model in the 26 th step is as follows: [0.19526008 0.20747631 0.18401823 0.20856255 0.18942023 0.23761041\n",
            " 0.19323884 0.20802602 0.19875929 0.2091452  0.20748949 0.21495211\n",
            " 0.19835438 0.1508885  0.17161781 0.20426356 0.19049688 0.20195586\n",
            " 0.24160677 0.20349313 0.24128737 0.21360262 0.13260211 0.25750999\n",
            " 0.25028726 0.23345922 0.23319597 0.20946461 0.20109993 0.21935337\n",
            " 0.22519323 0.23112217 0.18228659 0.18106873 0.2091452  0.17951828\n",
            " 0.19318628 0.2091452  0.1835672  0.21045216 0.18775133 0.21658506\n",
            " 0.17673979 0.24317383 0.25730245 0.21174595 0.20857573 0.19337046\n",
            " 0.20506334 0.19966134 0.92700988 0.78918123 0.91809865 0.84668069\n",
            " 0.89845917 1.01267806 0.69011146 0.95339083 0.89359685 0.95038246\n",
            " 0.79579151 0.82729487 0.86370668 0.7884999  0.81924645 0.83700948\n",
            " 0.83634089 1.00626873 1.07748574 0.77254053 0.89625375 0.76405425\n",
            " 1.02701421 0.77105941 0.87459618 0.90538842 0.75344118 0.75596601\n",
            " 0.87260789 0.87526749 0.94236969 0.96239431 0.87930367 0.77111512\n",
            " 0.82528637 0.96960386 0.86978686 0.83050104 0.74176148 0.85094073\n",
            " 0.88973256 0.82899715 0.78918123 0.91738437 0.90137932 0.83933695\n",
            " 0.79636099 0.81439731 0.83710817 0.77467048]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.19526008 -0.20747631 -0.18401823 -0.20856255 -0.18942023 -0.23761041\n",
            " -0.19323884 -0.20802602 -0.19875929 -0.2091452  -0.20748949 -0.21495211\n",
            " -0.19835438 -0.1508885  -0.17161781 -0.20426356 -0.19049688 -0.20195586\n",
            " -0.24160677 -0.20349313 -0.24128737 -0.21360262 -0.13260211 -0.25750999\n",
            " -0.25028726 -0.23345922 -0.23319597 -0.20946461 -0.20109993 -0.21935337\n",
            " -0.22519323 -0.23112217 -0.18228659 -0.18106873 -0.2091452  -0.17951828\n",
            " -0.19318628 -0.2091452  -0.1835672  -0.21045216 -0.18775133 -0.21658506\n",
            " -0.17673979 -0.24317383 -0.25730245 -0.21174595 -0.20857573 -0.19337046\n",
            " -0.20506334 -0.19966134  0.07299012  0.21081877  0.08190135  0.15331931\n",
            "  0.10154083 -0.01267806  0.30988854  0.04660917  0.10640315  0.04961754\n",
            "  0.20420849  0.17270513  0.13629332  0.2115001   0.18075355  0.16299052\n",
            "  0.16365911 -0.00626873 -0.07748574  0.22745947  0.10374625  0.23594575\n",
            " -0.02701421  0.22894059  0.12540382  0.09461158  0.24655882  0.24403399\n",
            "  0.12739211  0.12473251  0.05763031  0.03760569  0.12069633  0.22888488\n",
            "  0.17471363  0.03039614  0.13021314  0.16949896  0.25823852  0.14905927\n",
            "  0.11026744  0.17100285  0.21081877  0.08261563  0.09862068  0.16066305\n",
            "  0.20363901  0.18560269  0.16289183  0.22532952]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779]\n",
            "Epoch - 27 starting.....\n",
            "Predicted Output from the Adaline Model in the 27 th step is as follows: [0.18875589 0.20188389 0.17807434 0.20327421 0.18284652 0.23112186\n",
            " 0.18739803 0.20196496 0.19371994 0.20350478 0.20065572 0.20926466\n",
            " 0.19273225 0.14503207 0.16337406 0.19635781 0.18315865 0.19556198\n",
            " 0.23491625 0.19686132 0.23532879 0.20723123 0.12550109 0.25227422\n",
            " 0.24523706 0.22821105 0.22756795 0.20309225 0.19466527 0.21404674\n",
            " 0.21995612 0.22495936 0.17490323 0.17319136 0.20350478 0.1731202\n",
            " 0.18614731 0.20350478 0.17816532 0.20431052 0.18122563 0.21226372\n",
            " 0.17103767 0.23761631 0.25163062 0.20634443 0.20204603 0.18771959\n",
            " 0.19831016 0.19353798 0.93214718 0.79304858 0.92238792 0.85079663\n",
            " 0.90312988 1.01805131 0.69350923 0.95818779 0.89841574 0.95455651\n",
            " 0.79845444 0.83110351 0.86738805 0.79264595 0.82351521 0.84050876\n",
            " 0.83993311 1.01068318 1.08423674 0.77634363 0.90019975 0.76761813\n",
            " 1.03270922 0.77398866 0.87833263 0.90917836 0.75608848 0.75860608\n",
            " 0.87712428 0.87871222 0.94692165 0.9657897  0.88393037 0.77398816\n",
            " 0.82957262 0.97405504 0.87381406 0.83402374 0.74426972 0.85417898\n",
            " 0.89388775 0.83181875 0.79304858 0.92183579 0.905557   0.84268227\n",
            " 0.79991319 0.81757289 0.84068081 0.77789657]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.18875589 -0.20188389 -0.17807434 -0.20327421 -0.18284652 -0.23112186\n",
            " -0.18739803 -0.20196496 -0.19371994 -0.20350478 -0.20065572 -0.20926466\n",
            " -0.19273225 -0.14503207 -0.16337406 -0.19635781 -0.18315865 -0.19556198\n",
            " -0.23491625 -0.19686132 -0.23532879 -0.20723123 -0.12550109 -0.25227422\n",
            " -0.24523706 -0.22821105 -0.22756795 -0.20309225 -0.19466527 -0.21404674\n",
            " -0.21995612 -0.22495936 -0.17490323 -0.17319136 -0.20350478 -0.1731202\n",
            " -0.18614731 -0.20350478 -0.17816532 -0.20431052 -0.18122563 -0.21226372\n",
            " -0.17103767 -0.23761631 -0.25163062 -0.20634443 -0.20204603 -0.18771959\n",
            " -0.19831016 -0.19353798  0.06785282  0.20695142  0.07761208  0.14920337\n",
            "  0.09687012 -0.01805131  0.30649077  0.04181221  0.10158426  0.04544349\n",
            "  0.20154556  0.16889649  0.13261195  0.20735405  0.17648479  0.15949124\n",
            "  0.16006689 -0.01068318 -0.08423674  0.22365637  0.09980025  0.23238187\n",
            " -0.03270922  0.22601134  0.12166737  0.09082164  0.24391152  0.24139392\n",
            "  0.12287572  0.12128778  0.05307835  0.0342103   0.11606963  0.22601184\n",
            "  0.17042738  0.02594496  0.12618594  0.16597626  0.25573028  0.14582102\n",
            "  0.10611225  0.16818125  0.20695142  0.07816421  0.094443    0.15731773\n",
            "  0.20008681  0.18242711  0.15931919  0.22210343]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986]\n",
            "Epoch - 28 starting.....\n",
            "Predicted Output from the Adaline Model in the 28 th step is as follows: [0.18245307 0.19646418 0.17231451 0.19814957 0.17647655 0.22483464\n",
            " 0.18173858 0.19609151 0.18883656 0.19803851 0.19403344 0.20375342\n",
            " 0.18728369 0.13935701 0.15538549 0.18869763 0.17604812 0.18936621\n",
            " 0.22843274 0.19043534 0.2295542  0.20105764 0.1186206  0.2472007\n",
            " 0.24034331 0.2231248  0.22211441 0.19691706 0.18842959 0.20890439\n",
            " 0.21488092 0.21898721 0.16774892 0.16555834 0.19803851 0.16691995\n",
            " 0.17932587 0.19803851 0.17293076 0.19835886 0.17490222 0.20807542\n",
            " 0.16551243 0.23223152 0.24613499 0.20110996 0.19571883 0.18224378\n",
            " 0.19176608 0.18760404 0.93712678 0.79679651 0.92654397 0.85478497\n",
            " 0.90765633 1.02325716 0.69680257 0.96283495 0.90308433 0.95860214\n",
            " 0.80103532 0.83479391 0.87095538 0.79666399 0.82765303 0.84390063\n",
            " 0.84341389 1.01496096 1.09077734 0.78002788 0.90402394 0.7710725\n",
            " 1.03822634 0.7768269  0.88195378 0.91285021 0.75865375 0.76116469\n",
            " 0.88150091 0.88204901 0.95133136 0.96907951 0.88841404 0.77677158\n",
            " 0.83372521 0.97836765 0.87771796 0.83743737 0.7467007  0.85731694\n",
            " 0.89791489 0.83455333 0.79679651 0.92614984 0.90960633 0.84592441\n",
            " 0.803355   0.82065028 0.84414421 0.78102323]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.18245307 -0.19646418 -0.17231451 -0.19814957 -0.17647655 -0.22483464\n",
            " -0.18173858 -0.19609151 -0.18883656 -0.19803851 -0.19403344 -0.20375342\n",
            " -0.18728369 -0.13935701 -0.15538549 -0.18869763 -0.17604812 -0.18936621\n",
            " -0.22843274 -0.19043534 -0.2295542  -0.20105764 -0.1186206  -0.2472007\n",
            " -0.24034331 -0.2231248  -0.22211441 -0.19691706 -0.18842959 -0.20890439\n",
            " -0.21488092 -0.21898721 -0.16774892 -0.16555834 -0.19803851 -0.16691995\n",
            " -0.17932587 -0.19803851 -0.17293076 -0.19835886 -0.17490222 -0.20807542\n",
            " -0.16551243 -0.23223152 -0.24613499 -0.20110996 -0.19571883 -0.18224378\n",
            " -0.19176608 -0.18760404  0.06287322  0.20320349  0.07345603  0.14521503\n",
            "  0.09234367 -0.02325716  0.30319743  0.03716505  0.09691567  0.04139786\n",
            "  0.19896468  0.16520609  0.12904462  0.20333601  0.17234697  0.15609937\n",
            "  0.15658611 -0.01496096 -0.09077734  0.21997212  0.09597606  0.2289275\n",
            " -0.03822634  0.2231731   0.11804622  0.08714979  0.24134625  0.23883531\n",
            "  0.11849909  0.11795099  0.04866864  0.03092049  0.11158596  0.22322842\n",
            "  0.16627479  0.02163235  0.12228204  0.16256263  0.2532993   0.14268306\n",
            "  0.10208511  0.16544667  0.20320349  0.07385016  0.09039367  0.15407559\n",
            "  0.196645    0.17934972  0.15585579  0.21897677]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141]\n",
            "Epoch - 29 starting.....\n",
            "Predicted Output from the Adaline Model in the 29 th step is as follows: [0.17634537 0.19121183 0.16673303 0.19318357 0.170304   0.21874252\n",
            " 0.17625487 0.19039984 0.18410431 0.19274099 0.18761611 0.19841295\n",
            " 0.18200333 0.13385772 0.14764418 0.18127541 0.16915825 0.18336239\n",
            " 0.22214983 0.18420881 0.2239579  0.19507571 0.11195381 0.24228441\n",
            " 0.23560115 0.21819545 0.21682996 0.19093292 0.18238674 0.20392123\n",
            " 0.2099626  0.21319982 0.16081658 0.1581621  0.19274099 0.16091141\n",
            " 0.17271523 0.19274099 0.16785836 0.19259132 0.16877484 0.20401606\n",
            " 0.16015859 0.22701412 0.2408101  0.19603737 0.18958785 0.17693762\n",
            " 0.18542463 0.18185366 0.94195357 0.80042872 0.93057092 0.85864967\n",
            " 0.91204298 1.0283008  0.6999947  0.96733696 0.90760728 0.96252331\n",
            " 0.80353669 0.83836975 0.8744122  0.80055797 0.83166395 0.84718841\n",
            " 0.84678668 1.01910629 1.09711407 0.78359695 0.90773009 0.77442076\n",
            " 1.04357109 0.77957697 0.8854632  0.91640762 0.76113954 0.76364435\n",
            " 0.88574211 0.88528121 0.95560322 0.972267   0.89275913 0.77946815\n",
            " 0.83774827 0.98254599 0.88150239 0.84074532 0.7490568  0.86035773\n",
            " 0.90181797 0.83720357 0.80042872 0.93033075 0.91353129 0.84906656\n",
            " 0.80668983 0.82363253 0.84750175 0.78405352]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.17634537 -0.19121183 -0.16673303 -0.19318357 -0.170304   -0.21874252\n",
            " -0.17625487 -0.19039984 -0.18410431 -0.19274099 -0.18761611 -0.19841295\n",
            " -0.18200333 -0.13385772 -0.14764418 -0.18127541 -0.16915825 -0.18336239\n",
            " -0.22214983 -0.18420881 -0.2239579  -0.19507571 -0.11195381 -0.24228441\n",
            " -0.23560115 -0.21819545 -0.21682996 -0.19093292 -0.18238674 -0.20392123\n",
            " -0.2099626  -0.21319982 -0.16081658 -0.1581621  -0.19274099 -0.16091141\n",
            " -0.17271523 -0.19274099 -0.16785836 -0.19259132 -0.16877484 -0.20401606\n",
            " -0.16015859 -0.22701412 -0.2408101  -0.19603737 -0.18958785 -0.17693762\n",
            " -0.18542463 -0.18185366  0.05804643  0.19957128  0.06942908  0.14135033\n",
            "  0.08795702 -0.0283008   0.3000053   0.03266304  0.09239272  0.03747669\n",
            "  0.19646331  0.16163025  0.1255878   0.19944203  0.16833605  0.15281159\n",
            "  0.15321332 -0.01910629 -0.09711407  0.21640305  0.09226991  0.22557924\n",
            " -0.04357109  0.22042303  0.1145368   0.08359238  0.23886046  0.23635565\n",
            "  0.11425789  0.11471879  0.04439678  0.027733    0.10724087  0.22053185\n",
            "  0.16225173  0.01745401  0.11849761  0.15925468  0.2509432   0.13964227\n",
            "  0.09818203  0.16279643  0.19957128  0.06966925  0.08646871  0.15093344\n",
            "  0.19331017  0.17636747  0.15249825  0.21594648]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702]\n",
            "Epoch - 30 starting.....\n",
            "Predicted Output from the Adaline Model in the 30 th step is as follows: [0.17042675 0.18612166 0.16132439 0.18837129 0.16432277 0.21283946\n",
            " 0.17094145 0.18488434 0.17951851 0.187607   0.18139738 0.19323794\n",
            " 0.17688596 0.12852874 0.14014249 0.17408378 0.1624822  0.1775446\n",
            " 0.2160613  0.17817555 0.21853438 0.18927952 0.10549409 0.23752049\n",
            " 0.23100589 0.21341814 0.21170935 0.18513392 0.17653073 0.19909234\n",
            " 0.20519631 0.20759145 0.15409934 0.15099531 0.187607   0.15508863\n",
            " 0.16630885 0.187607   0.16294307 0.18700219 0.16283743 0.20008163\n",
            " 0.15497083 0.22195892 0.23565066 0.19112165 0.18364701 0.17179585\n",
            " 0.17927953 0.17628114 0.94663226 0.8039488  0.93447276 0.86239456\n",
            " 0.91629417 1.03318724 0.70308877 0.97169831 0.9119891  0.9663239\n",
            " 0.80596102 0.84183456 0.87776193 0.80433173 0.83555192 0.85037533\n",
            " 0.85005483 1.02312328 1.10325323 0.78705442 0.91132187 0.77766619\n",
            " 1.04874881 0.7822416  0.88886434 0.91985414 0.7635483  0.76604752\n",
            " 0.88985208 0.88841206 0.95974151 0.97535534 0.89696993 0.78208056\n",
            " 0.84164583 0.98659421 0.88517103 0.84395085 0.75134035 0.86330435\n",
            " 0.90560082 0.8397721  0.8039488  0.93438265 0.91733573 0.85211183\n",
            " 0.809921   0.82652258 0.8507567  0.78699044]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.17042675 -0.18612166 -0.16132439 -0.18837129 -0.16432277 -0.21283946\n",
            " -0.17094145 -0.18488434 -0.17951851 -0.187607   -0.18139738 -0.19323794\n",
            " -0.17688596 -0.12852874 -0.14014249 -0.17408378 -0.1624822  -0.1775446\n",
            " -0.2160613  -0.17817555 -0.21853438 -0.18927952 -0.10549409 -0.23752049\n",
            " -0.23100589 -0.21341814 -0.21170935 -0.18513392 -0.17653073 -0.19909234\n",
            " -0.20519631 -0.20759145 -0.15409934 -0.15099531 -0.187607   -0.15508863\n",
            " -0.16630885 -0.187607   -0.16294307 -0.18700219 -0.16283743 -0.20008163\n",
            " -0.15497083 -0.22195892 -0.23565066 -0.19112165 -0.18364701 -0.17179585\n",
            " -0.17927953 -0.17628114  0.05336774  0.1960512   0.06552724  0.13760544\n",
            "  0.08370583 -0.03318724  0.29691123  0.02830169  0.0880109   0.0336761\n",
            "  0.19403898  0.15816544  0.12223807  0.19566827  0.16444808  0.14962467\n",
            "  0.14994517 -0.02312328 -0.10325323  0.21294558  0.08867813  0.22233381\n",
            " -0.04874881  0.2177584   0.11113566  0.08014586  0.2364517   0.23395248\n",
            "  0.11014792  0.11158794  0.04025849  0.02464466  0.10303007  0.21791944\n",
            "  0.15835417  0.01340579  0.11482897  0.15604915  0.24865965  0.13669565\n",
            "  0.09439918  0.1602279   0.1960512   0.06561735  0.08266427  0.14788817\n",
            "  0.190079    0.17347742  0.1492433   0.21300956]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123]\n",
            "Epoch - 31 starting.....\n",
            "Predicted Output from the Adaline Model in the 31 th step is as follows: [0.16469136 0.18118864 0.15608322 0.18370797 0.15852694 0.20711961\n",
            " 0.16579305 0.17953954 0.17507463 0.18263148 0.17537111 0.18822329\n",
            " 0.17192653 0.1233648  0.13287298 0.16711561 0.15601335 0.17190706\n",
            " 0.21016114 0.17232957 0.21327829 0.1836633  0.09923505 0.2329042\n",
            " 0.22655299 0.20878817 0.20674751 0.17951433 0.17085578 0.19441292\n",
            " 0.20057734 0.20215657 0.14759052 0.14405086 0.18263148 0.14944588\n",
            " 0.16010042 0.18263148 0.15818004 0.18158594 0.15708409 0.19626828\n",
            " 0.14994401 0.2170609  0.23065154 0.18635793 0.17789044 0.16681338\n",
            " 0.1733247  0.17088099 0.95116746 0.80736023 0.93825338 0.86602334\n",
            " 0.92041408 1.03792137 0.70608781 0.97592336 0.91623417 0.97000762\n",
            " 0.80831068 0.84519179 0.8810079  0.80798899 0.83932073 0.85346452\n",
            " 0.85322157 1.0270159  1.10920095 0.79040375 0.91480281 0.78081197\n",
            " 1.05376467 0.78482342 0.89216057 0.9231932  0.76588243 0.76837656\n",
            " 0.89383488 0.8914447  0.96375036 0.97834761 0.90105058 0.78461142\n",
            " 0.84542177 0.99051635 0.88872748 0.84705715 0.75355358 0.86615972\n",
            " 0.90926715 0.84226143 0.80736023 0.93830953 0.92102339 0.8550632\n",
            " 0.81305172 0.82932328 0.85391224 0.78983688]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.16469136 -0.18118864 -0.15608322 -0.18370797 -0.15852694 -0.20711961\n",
            " -0.16579305 -0.17953954 -0.17507463 -0.18263148 -0.17537111 -0.18822329\n",
            " -0.17192653 -0.1233648  -0.13287298 -0.16711561 -0.15601335 -0.17190706\n",
            " -0.21016114 -0.17232957 -0.21327829 -0.1836633  -0.09923505 -0.2329042\n",
            " -0.22655299 -0.20878817 -0.20674751 -0.17951433 -0.17085578 -0.19441292\n",
            " -0.20057734 -0.20215657 -0.14759052 -0.14405086 -0.18263148 -0.14944588\n",
            " -0.16010042 -0.18263148 -0.15818004 -0.18158594 -0.15708409 -0.19626828\n",
            " -0.14994401 -0.2170609  -0.23065154 -0.18635793 -0.17789044 -0.16681338\n",
            " -0.1733247  -0.17088099  0.04883254  0.19263977  0.06174662  0.13397666\n",
            "  0.07958592 -0.03792137  0.29391219  0.02407664  0.08376583  0.02999238\n",
            "  0.19168932  0.15480821  0.1189921   0.19201101  0.16067927  0.14653548\n",
            "  0.14677843 -0.0270159  -0.10920095  0.20959625  0.08519719  0.21918803\n",
            " -0.05376467  0.21517658  0.10783943  0.0768068   0.23411757  0.23162344\n",
            "  0.10616512  0.1085553   0.03624964  0.02165239  0.09894942  0.21538858\n",
            "  0.15457823  0.00948365  0.11127252  0.15294285  0.24644642  0.13384028\n",
            "  0.09073285  0.15773857  0.19263977  0.06169047  0.07897661  0.1449368\n",
            "  0.18694828  0.17067672  0.14608776  0.21016312]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257]\n",
            "Epoch - 32 starting.....\n",
            "Predicted Output from the Adaline Model in the 32 th step is as follows: [0.15913352 0.1764079  0.15100435 0.17918899 0.15291074 0.20157728\n",
            " 0.16080456 0.17436015 0.17076826 0.17780951 0.16953132 0.18336402\n",
            " 0.16712015 0.1183608  0.12582847 0.16036396 0.14974527 0.1664442\n",
            " 0.20444351 0.16666509 0.20818443 0.17822148 0.09317046 0.22843098\n",
            " 0.22223803 0.20430097 0.20193952 0.17406859 0.16535629 0.18987836\n",
            " 0.19610113 0.1968898  0.14128368 0.13732186 0.17780951 0.14397755\n",
            " 0.15408379 0.17780951 0.15356455 0.17633722 0.15150913 0.19257224\n",
            " 0.14507315 0.21231519 0.22580778 0.18174152 0.17231241 0.16198529\n",
            " 0.16755425 0.16564786 0.9555636  0.81066636 0.94191653 0.86953962\n",
            " 0.92440679 1.04250789 0.70899476 0.98001633 0.92034672 0.97357811\n",
            " 0.810588   0.84844477 0.88415331 0.81153338 0.84297407 0.85645899\n",
            " 0.85629005 1.03078801 1.11496315 0.79364828 0.91817634 0.78386119\n",
            " 1.05862368 0.78732501 0.89535513 0.92642814 0.76814423 0.77063376\n",
            " 0.89769445 0.89438217 0.96763378 0.98124677 0.90500513 0.78706326\n",
            " 0.84907986 0.99431631 0.8921752  0.85006728 0.75569869 0.86892667\n",
            " 0.91282059 0.84467403 0.81066636 0.94211528 0.92459787 0.8579236\n",
            " 0.81608511 0.83203741 0.85697144 0.79259563]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.15913352 -0.1764079  -0.15100435 -0.17918899 -0.15291074 -0.20157728\n",
            " -0.16080456 -0.17436015 -0.17076826 -0.17780951 -0.16953132 -0.18336402\n",
            " -0.16712015 -0.1183608  -0.12582847 -0.16036396 -0.14974527 -0.1664442\n",
            " -0.20444351 -0.16666509 -0.20818443 -0.17822148 -0.09317046 -0.22843098\n",
            " -0.22223803 -0.20430097 -0.20193952 -0.17406859 -0.16535629 -0.18987836\n",
            " -0.19610113 -0.1968898  -0.14128368 -0.13732186 -0.17780951 -0.14397755\n",
            " -0.15408379 -0.17780951 -0.15356455 -0.17633722 -0.15150913 -0.19257224\n",
            " -0.14507315 -0.21231519 -0.22580778 -0.18174152 -0.17231241 -0.16198529\n",
            " -0.16755425 -0.16564786  0.0444364   0.18933364  0.05808347  0.13046038\n",
            "  0.07559321 -0.04250789  0.29100524  0.01998367  0.07965328  0.02642189\n",
            "  0.189412    0.15155523  0.11584669  0.18846662  0.15702593  0.14354101\n",
            "  0.14370995 -0.03078801 -0.11496315  0.20635172  0.08182366  0.21613881\n",
            " -0.05862368  0.21267499  0.10464487  0.07357186  0.23185577  0.22936624\n",
            "  0.10230555  0.10561783  0.03236622  0.01875323  0.09499487  0.21293674\n",
            "  0.15092014  0.00568369  0.1078248   0.14993272  0.24430131  0.13107333\n",
            "  0.08717941  0.15532597  0.18933364  0.05788472  0.07540213  0.1420764\n",
            "  0.18391489  0.16796259  0.14302856  0.20740437]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622]\n",
            "Epoch - 33 starting.....\n",
            "Predicted Output from the Adaline Model in the 33 th step is as follows: [0.15374772 0.17177473 0.14608275 0.17480989 0.14746863 0.19620698\n",
            " 0.15597103 0.16934107 0.16659516 0.17313635 0.16387224 0.17865532\n",
            " 0.16246208 0.11351177 0.11900199 0.15382213 0.14367175 0.1611506\n",
            " 0.19890275 0.16117647 0.20324779 0.17294866 0.08729429 0.2240964\n",
            " 0.21805674 0.19995213 0.19728063 0.16879131 0.16002682 0.18548417\n",
            " 0.19176326 0.19178593 0.13517255 0.13080164 0.17313635 0.13867827\n",
            " 0.14825303 0.17313635 0.14909204 0.17125084 0.14610702 0.18898989\n",
            " 0.14035341 0.20771707 0.22111457 0.17726783 0.1669074  0.15730677\n",
            " 0.16196246 0.16057657 0.95982499 0.81387045 0.94546584 0.87294687\n",
            " 0.92827624 1.04695138 0.71181248 0.9839813  0.92433085 0.97703886\n",
            " 0.81279521 0.85159674 0.88720128 0.81496837 0.84651553 0.85936168\n",
            " 0.85926331 1.03444333 1.12054558 0.79679126 0.9214458  0.78681685\n",
            " 1.06333071 0.78974885 0.89845117 0.92956216 0.77033595 0.77282136\n",
            " 0.9014346  0.89722742 0.97139566 0.98405571 0.90883748 0.78943852\n",
            " 0.85262375 0.99799787 0.89551757 0.85298422 0.75777777 0.87160793\n",
            " 0.91626462 0.84701227 0.81387045 0.94580363 0.92806268 0.86069583\n",
            " 0.81902416 0.83466764 0.8599373  0.79526941]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.15374772 -0.17177473 -0.14608275 -0.17480989 -0.14746863 -0.19620698\n",
            " -0.15597103 -0.16934107 -0.16659516 -0.17313635 -0.16387224 -0.17865532\n",
            " -0.16246208 -0.11351177 -0.11900199 -0.15382213 -0.14367175 -0.1611506\n",
            " -0.19890275 -0.16117647 -0.20324779 -0.17294866 -0.08729429 -0.2240964\n",
            " -0.21805674 -0.19995213 -0.19728063 -0.16879131 -0.16002682 -0.18548417\n",
            " -0.19176326 -0.19178593 -0.13517255 -0.13080164 -0.17313635 -0.13867827\n",
            " -0.14825303 -0.17313635 -0.14909204 -0.17125084 -0.14610702 -0.18898989\n",
            " -0.14035341 -0.20771707 -0.22111457 -0.17726783 -0.1669074  -0.15730677\n",
            " -0.16196246 -0.16057657  0.04017501  0.18612955  0.05453416  0.12705313\n",
            "  0.07172376 -0.04695138  0.28818752  0.0160187   0.07566915  0.02296114\n",
            "  0.18720479  0.14840326  0.11279872  0.18503163  0.15348447  0.14063832\n",
            "  0.14073669 -0.03444333 -0.12054558  0.20320874  0.0785542   0.21318315\n",
            " -0.06333071  0.21025115  0.10154883  0.07043784  0.22966405  0.22717864\n",
            "  0.0985654   0.10277258  0.02860434  0.01594429  0.09116252  0.21056148\n",
            "  0.14737625  0.00200213  0.10448243  0.14701578  0.24222223  0.12839207\n",
            "  0.08373538  0.15298773  0.18612955  0.05419637  0.07193732  0.13930417\n",
            "  0.18097584  0.16533236  0.1400627   0.20473059]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555]\n",
            "Epoch - 34 starting.....\n",
            "Predicted Output from the Adaline Model in the 34 th step is as follows: [0.14852865 0.16728457 0.14131353 0.17056634 0.14219521 0.19100338\n",
            " 0.15128764 0.16447731 0.16255119 0.16860738 0.15838828 0.17409252\n",
            " 0.15794773 0.10881292 0.11238679 0.14748363 0.13778677 0.15602103\n",
            " 0.19353339 0.15585827 0.1984635  0.16783961 0.08160072 0.21989617\n",
            " 0.21400498 0.19573735 0.1927662  0.16367728 0.1548621  0.18122599\n",
            " 0.18755943 0.18683993 0.12925108 0.12448374 0.16860738 0.13354279\n",
            " 0.14260238 0.16860738 0.14475806 0.16632178 0.1408724  0.1855177\n",
            " 0.13578012 0.20326197 0.21656725 0.17293247 0.16167005 0.15277322\n",
            " 0.15654381 0.15566213 0.9639558  0.81697568 0.94890484 0.87624848\n",
            " 0.93202624 1.05125627 0.71454373 0.98782226 0.92819055 0.98039328\n",
            " 0.81493448 0.8546508  0.89015482 0.81829737 0.84994856 0.86217543\n",
            " 0.8621443  1.03798549 1.12595382 0.79983584 0.9246144  0.78968183\n",
            " 1.06789046 0.79209735 0.90145174 0.93259841 0.77245976 0.7749415\n",
            " 0.90505903 0.89998331 0.97503976 0.98677723 0.9125514  0.79173958\n",
            " 0.85605697 1.00156471 0.89875785 0.85581086 0.75979287 0.87420617\n",
            " 0.91960264 0.84927845 0.81697568 0.94937823 0.93142122 0.86338263\n",
            " 0.82187182 0.83721658 0.8628127  0.79786086]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.14852865 -0.16728457 -0.14131353 -0.17056634 -0.14219521 -0.19100338\n",
            " -0.15128764 -0.16447731 -0.16255119 -0.16860738 -0.15838828 -0.17409252\n",
            " -0.15794773 -0.10881292 -0.11238679 -0.14748363 -0.13778677 -0.15602103\n",
            " -0.19353339 -0.15585827 -0.1984635  -0.16783961 -0.08160072 -0.21989617\n",
            " -0.21400498 -0.19573735 -0.1927662  -0.16367728 -0.1548621  -0.18122599\n",
            " -0.18755943 -0.18683993 -0.12925108 -0.12448374 -0.16860738 -0.13354279\n",
            " -0.14260238 -0.16860738 -0.14475806 -0.16632178 -0.1408724  -0.1855177\n",
            " -0.13578012 -0.20326197 -0.21656725 -0.17293247 -0.16167005 -0.15277322\n",
            " -0.15654381 -0.15566213  0.0360442   0.18302432  0.05109516  0.12375152\n",
            "  0.06797376 -0.05125627  0.28545627  0.01217774  0.07180945  0.01960672\n",
            "  0.18506552  0.1453492   0.10984518  0.18170263  0.15005144  0.13782457\n",
            "  0.1378557  -0.03798549 -0.12595382  0.20016416  0.0753856   0.21031817\n",
            " -0.06789046  0.20790265  0.09854826  0.06740159  0.22754024  0.2250585\n",
            "  0.09494097  0.10001669  0.02496024  0.01322277  0.0874486   0.20826042\n",
            "  0.14394303 -0.00156471  0.10124215  0.14418914  0.24020713  0.12579383\n",
            "  0.08039736  0.15072155  0.18302432  0.05062177  0.06857878  0.13661737\n",
            "  0.17812818  0.16278342  0.1371873   0.20213914]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418]\n",
            "Epoch - 35 starting.....\n",
            "Predicted Output from the Adaline Model in the 35 th step is as follows: [0.14347114 0.16293297 0.136692   0.16645413 0.13708526 0.18596132\n",
            " 0.14674977 0.15976407 0.15863235 0.16421814 0.15307401 0.16967111\n",
            " 0.15357264 0.10425959 0.10597632 0.14134215 0.13208448 0.15105039\n",
            " 0.18833013 0.1507052  0.19382683 0.16288925 0.07608408 0.21582611\n",
            " 0.21007874 0.19165248 0.18839177 0.15872144 0.14985703 0.17709963\n",
            " 0.18348551 0.1820469  0.12351339 0.11836188 0.16421814 0.12856604\n",
            " 0.13712627 0.16421814 0.14055834 0.16154515 0.1358001  0.18215227\n",
            " 0.13134874 0.19894547 0.21216129 0.16873114 0.15659517 0.14838012\n",
            " 0.15129292 0.15089966 0.96796008 0.81998509 0.95223696 0.87944771\n",
            " 0.93566049 1.05542685 0.71719118 0.99154303 0.93192967 0.98364465\n",
            " 0.81700793 0.85761001 0.89301686 0.82152364 0.85327652 0.864903\n",
            " 0.86493587 1.04141799 1.13119325 0.80278506 0.92768526 0.79245895\n",
            " 1.0723075  0.79437284 0.9043598  0.93553991 0.77451775 0.77699628\n",
            " 0.90857134 0.9026526  0.97856974 0.98941404 0.91615058 0.79396873\n",
            " 0.85938296 1.00502038 0.90189919 0.85854999 0.76174598 0.87672394\n",
            " 0.92283793 0.8514748  0.81998509 0.9528426  0.93467679 0.86598664\n",
            " 0.8246309  0.83968674 0.86560044 0.80037253]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.14347114 -0.16293297 -0.136692   -0.16645413 -0.13708526 -0.18596132\n",
            " -0.14674977 -0.15976407 -0.15863235 -0.16421814 -0.15307401 -0.16967111\n",
            " -0.15357264 -0.10425959 -0.10597632 -0.14134215 -0.13208448 -0.15105039\n",
            " -0.18833013 -0.1507052  -0.19382683 -0.16288925 -0.07608408 -0.21582611\n",
            " -0.21007874 -0.19165248 -0.18839177 -0.15872144 -0.14985703 -0.17709963\n",
            " -0.18348551 -0.1820469  -0.12351339 -0.11836188 -0.16421814 -0.12856604\n",
            " -0.13712627 -0.16421814 -0.14055834 -0.16154515 -0.1358001  -0.18215227\n",
            " -0.13134874 -0.19894547 -0.21216129 -0.16873114 -0.15659517 -0.14838012\n",
            " -0.15129292 -0.15089966  0.03203992  0.18001491  0.04776304  0.12055229\n",
            "  0.06433951 -0.05542685  0.28280882  0.00845697  0.06807033  0.01635535\n",
            "  0.18299207  0.14238999  0.10698314  0.17847636  0.14672348  0.135097\n",
            "  0.13506413 -0.04141799 -0.13119325  0.19721494  0.07231474  0.20754105\n",
            " -0.0723075   0.20562716  0.0956402   0.06446009  0.22548225  0.22300372\n",
            "  0.09142866  0.0973474   0.02143026  0.01058596  0.08384942  0.20603127\n",
            "  0.14061704 -0.00502038  0.09810081  0.14145001  0.23825402  0.12327606\n",
            "  0.07716207  0.1485252   0.18001491  0.0471574   0.06532321  0.13401336\n",
            "  0.1753691   0.16031326  0.13439956  0.19962747]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221]\n",
            "Epoch - 36 starting.....\n",
            "Predicted Output from the Adaline Model in the 36 th step is as follows: [0.13857019 0.15871566 0.13221356 0.1624692  0.13213371 0.18107579\n",
            " 0.14235289 0.15519669 0.15483478 0.1599643  0.14792418 0.16538671\n",
            " 0.14933251 0.09984729 0.09976424 0.1353916  0.12655923 0.14623378\n",
            " 0.18328781 0.14571216 0.18933321 0.15809267 0.0707389  0.21188221\n",
            " 0.20627413 0.1876935  0.184153   0.15391889 0.14500667 0.17310099\n",
            " 0.17953747 0.1774021  0.1179538  0.11243    0.1599643  0.1237431\n",
            " 0.13181929 0.1599643  0.13648872 0.15691625 0.13088507 0.17889029\n",
            " 0.12705488 0.19476326 0.20789231 0.16465969 0.15167772 0.14412314\n",
            " 0.14620462 0.14628447 0.97184174 0.82290166 0.95546549 0.88254775\n",
            " 0.93918257 1.05946729 0.71975743 0.99514734 0.93555194 0.98679617\n",
            " 0.81901757 0.8604773  0.89579024 0.82465038 0.85650267 0.86754706\n",
            " 0.86764081 1.04474423 1.13626912 0.80564189 0.93066142 0.79515092\n",
            " 1.07658624 0.79657759 0.90717821 0.9383896  0.77651197 0.77898771\n",
            " 0.91197498 0.90523798 0.98198912 0.99196875 0.91963857 0.7961282\n",
            " 0.86260504 1.00836831 0.90494467 0.86120433 0.76363901 0.87916375\n",
            " 0.92597367 0.85360349 0.82290166 0.95620015 0.93783256 0.86851043\n",
            " 0.82730415 0.84208055 0.86830324 0.80280688]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.13857019 -0.15871566 -0.13221356 -0.1624692  -0.13213371 -0.18107579\n",
            " -0.14235289 -0.15519669 -0.15483478 -0.1599643  -0.14792418 -0.16538671\n",
            " -0.14933251 -0.09984729 -0.09976424 -0.1353916  -0.12655923 -0.14623378\n",
            " -0.18328781 -0.14571216 -0.18933321 -0.15809267 -0.0707389  -0.21188221\n",
            " -0.20627413 -0.1876935  -0.184153   -0.15391889 -0.14500667 -0.17310099\n",
            " -0.17953747 -0.1774021  -0.1179538  -0.11243    -0.1599643  -0.1237431\n",
            " -0.13181929 -0.1599643  -0.13648872 -0.15691625 -0.13088507 -0.17889029\n",
            " -0.12705488 -0.19476326 -0.20789231 -0.16465969 -0.15167772 -0.14412314\n",
            " -0.14620462 -0.14628447  0.02815826  0.17709834  0.04453451  0.11745225\n",
            "  0.06081743 -0.05946729  0.28024257  0.00485266  0.06444806  0.01320383\n",
            "  0.18098243  0.1395227   0.10420976  0.17534962  0.14349733  0.13245294\n",
            "  0.13235919 -0.04474423 -0.13626912  0.19435811  0.06933858  0.20484908\n",
            " -0.07658624  0.20342241  0.09282179  0.0616104   0.22348803  0.22101229\n",
            "  0.08802502  0.09476202  0.01801088  0.00803125  0.08036143  0.2038718\n",
            "  0.13739496 -0.00836831  0.09505533  0.13879567  0.23636099  0.12083625\n",
            "  0.07402633  0.14639651  0.17709834  0.04379985  0.06216744  0.13148957\n",
            "  0.17269585  0.15791945  0.13169676  0.19719312]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884]\n",
            "Epoch - 37 starting.....\n",
            "Predicted Output from the Adaline Model in the 37 th step is as follows: [0.13382094 0.15462847 0.1278738  0.15860761 0.12733566 0.17634195\n",
            " 0.13809265 0.15077065 0.1511547  0.15584167 0.14293369 0.16123507\n",
            " 0.14522316 0.09557163 0.09374441 0.12962605 0.12120553 0.14156641\n",
            " 0.17840145 0.14087419 0.18497823 0.1534451  0.06555987 0.20806055\n",
            " 0.20258739 0.18385652 0.18004569 0.14926489 0.14030622 0.16922612\n",
            " 0.1757114  0.17290095 0.11256677 0.10668221 0.15584167 0.11906921\n",
            " 0.1266762  0.15584167 0.13254516 0.15243049 0.12612246 0.17572856\n",
            " 0.12289427 0.19071118 0.20375608 0.1607141  0.14691283 0.13999806\n",
            " 0.14127385 0.14181198 0.97560458 0.82572826 0.95859365 0.88555164\n",
            " 0.94259597 1.06338161 0.722245   0.9986388  0.93906099 0.98985093\n",
            " 0.8209654  0.86325552 0.89847771 0.82768066 0.85963016 0.87011018\n",
            " 0.87026178 1.04796749 1.14118647 0.80840917 0.93354581 0.79776039\n",
            " 1.08073097 0.79871378 0.90990975 0.94115032 0.77844439 0.78091778\n",
            " 0.91527333 0.90774205 0.98530134 0.99444391 0.9230188  0.79822015\n",
            " 0.86572642 1.01161185 0.90789724 0.8637765  0.76547383 0.881528\n",
            " 0.92901293 0.85566661 0.82572826 0.95945418 0.94089162 0.87095648\n",
            " 0.82989424 0.84440039 0.87092372 0.80516631]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.13382094 -0.15462847 -0.1278738  -0.15860761 -0.12733566 -0.17634195\n",
            " -0.13809265 -0.15077065 -0.1511547  -0.15584167 -0.14293369 -0.16123507\n",
            " -0.14522316 -0.09557163 -0.09374441 -0.12962605 -0.12120553 -0.14156641\n",
            " -0.17840145 -0.14087419 -0.18497823 -0.1534451  -0.06555987 -0.20806055\n",
            " -0.20258739 -0.18385652 -0.18004569 -0.14926489 -0.14030622 -0.16922612\n",
            " -0.1757114  -0.17290095 -0.11256677 -0.10668221 -0.15584167 -0.11906921\n",
            " -0.1266762  -0.15584167 -0.13254516 -0.15243049 -0.12612246 -0.17572856\n",
            " -0.12289427 -0.19071118 -0.20375608 -0.1607141  -0.14691283 -0.13999806\n",
            " -0.14127385 -0.14181198  0.02439542  0.17427174  0.04140635  0.11444836\n",
            "  0.05740403 -0.06338161  0.277755    0.0013612   0.06093901  0.01014907\n",
            "  0.1790346   0.13674448  0.10152229  0.17231934  0.14036984  0.12988982\n",
            "  0.12973822 -0.04796749 -0.14118647  0.19159083  0.06645419  0.20223961\n",
            " -0.08073097  0.20128622  0.09009025  0.05884968  0.22155561  0.21908222\n",
            "  0.08472667  0.09225795  0.01469866  0.00555609  0.0769812   0.20177985\n",
            "  0.13427358 -0.01161185  0.09210276  0.1362235   0.23452617  0.118472\n",
            "  0.07098707  0.14433339  0.17427174  0.04054582  0.05910838  0.12904352\n",
            "  0.17010576  0.15559961  0.12907628  0.19483369]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884, 1.0217537216677286]\n",
            "Epoch - 38 starting.....\n",
            "Predicted Output from the Adaline Model in the 38 th step is as follows: [0.1292187  0.15066737 0.1236684  0.15486553 0.12268635 0.1717551\n",
            " 0.1339648  0.14648157 0.1475885  0.15184618 0.13809761 0.15721209\n",
            " 0.14124053 0.0914284  0.08791087 0.12403979 0.11601806 0.13704367\n",
            " 0.17366622 0.13618648 0.18075757 0.14894193 0.06054183 0.20435734\n",
            " 0.19901486 0.18013776 0.17606577 0.14475483 0.13575105 0.16547118\n",
            " 0.17200353 0.16853899 0.10734697 0.10111281 0.15184618 0.11453976\n",
            " 0.12169193 0.15184618 0.12872376 0.14808344 0.12150754 0.17266397\n",
            " 0.11886279 0.18678522 0.19974849 0.15689047 0.14229577 0.13600079\n",
            " 0.13649574 0.13747779 0.97925228 0.82846768 0.96162455 0.88846239\n",
            " 0.94590404 1.06717372 0.72465631 1.00202091 0.94246032 0.99281193\n",
            " 0.82285333 0.86594742 0.90108191 0.83061748 0.86266203 0.87259488\n",
            " 0.87280139 1.05109096 1.14595023 0.81108969 0.93634127 0.8002899\n",
            " 1.08474584 0.80078354 0.91255711 0.94382482 0.78031693 0.78278836\n",
            " 0.91846965 0.91016733 0.98850971 0.99684199 0.92629462 0.80024668\n",
            " 0.86875022 1.01475423 0.91075979 0.86626904 0.76725223 0.88381904\n",
            " 0.93195872 0.8576662  0.82846768 0.96260792 0.94385698 0.8733272\n",
            " 0.83240373 0.84664855 0.87346444 0.80745313]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.1292187  -0.15066737 -0.1236684  -0.15486553 -0.12268635 -0.1717551\n",
            " -0.1339648  -0.14648157 -0.1475885  -0.15184618 -0.13809761 -0.15721209\n",
            " -0.14124053 -0.0914284  -0.08791087 -0.12403979 -0.11601806 -0.13704367\n",
            " -0.17366622 -0.13618648 -0.18075757 -0.14894193 -0.06054183 -0.20435734\n",
            " -0.19901486 -0.18013776 -0.17606577 -0.14475483 -0.13575105 -0.16547118\n",
            " -0.17200353 -0.16853899 -0.10734697 -0.10111281 -0.15184618 -0.11453976\n",
            " -0.12169193 -0.15184618 -0.12872376 -0.14808344 -0.12150754 -0.17266397\n",
            " -0.11886279 -0.18678522 -0.19974849 -0.15689047 -0.14229577 -0.13600079\n",
            " -0.13649574 -0.13747779  0.02074772  0.17153232  0.03837545  0.11153761\n",
            "  0.05409596 -0.06717372  0.27534369 -0.00202091  0.05753968  0.00718807\n",
            "  0.17714667  0.13405258  0.09891809  0.16938252  0.13733797  0.12740512\n",
            "  0.12719861 -0.05109096 -0.14595023  0.18891031  0.06365873  0.1997101\n",
            " -0.08474584  0.19921646  0.08744289  0.05617518  0.21968307  0.21721164\n",
            "  0.08153035  0.08983267  0.01149029  0.00315801  0.07370538  0.19975332\n",
            "  0.13124978 -0.01475423  0.08924021  0.13373096  0.23274777  0.11618096\n",
            "  0.06804128  0.1423338   0.17153232  0.03739208  0.05614302  0.1266728\n",
            "  0.16759627  0.15335145  0.12653556  0.19254687]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884, 1.0217537216677286, 0.9786398695092615]\n",
            "Epoch - 39 starting.....\n",
            "Predicted Output from the Adaline Model in the 39 th step is as follows: [0.12475892 0.14682845 0.11959323 0.15123927 0.11818118 0.16731068\n",
            " 0.12996525 0.14232521 0.14413263 0.1479739  0.13341116 0.15331377\n",
            " 0.1373807  0.08741348 0.08225786 0.11862724 0.11099169 0.13266108\n",
            " 0.16907745 0.13164439 0.17666709 0.14457869 0.05567981 0.20076893\n",
            " 0.19555301 0.17653354 0.17220928 0.14038426 0.13133666 0.16183247\n",
            " 0.16841021 0.16431191 0.10228922 0.09571628 0.1479739  0.11015026\n",
            " 0.11686155 0.1479739  0.12502073 0.14387081 0.11703573 0.16969351\n",
            " 0.11495644 0.18298146 0.19586553 0.15318502 0.13782197 0.13212738\n",
            " 0.13186556 0.13327761 0.9827884  0.83112261 0.9645612  0.89128287\n",
            " 0.94911005 1.07084741 0.72699375 1.00529705 0.94575333 0.99568206\n",
            " 0.82468321 0.86855567 0.90360543 0.83346372 0.86560127 0.87500359\n",
            " 0.87526217 1.05411775 1.15056515 0.81368614 0.93905055 0.80274194\n",
            " 1.08863488 0.80278893 0.91512289 0.94641577 0.78213144 0.7846013\n",
            " 0.92156709 0.91251625 0.99161745 0.99916537 0.92946925 0.8022098\n",
            " 0.87167947 1.01779859 0.9135351  0.86868443 0.76897596 0.88603913\n",
            " 0.93481392 0.85960421 0.83112261 0.96566445 0.94673154 0.87562492\n",
            " 0.83483513 0.84882725 0.87592785 0.80966961]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.12475892 -0.14682845 -0.11959323 -0.15123927 -0.11818118 -0.16731068\n",
            " -0.12996525 -0.14232521 -0.14413263 -0.1479739  -0.13341116 -0.15331377\n",
            " -0.1373807  -0.08741348 -0.08225786 -0.11862724 -0.11099169 -0.13266108\n",
            " -0.16907745 -0.13164439 -0.17666709 -0.14457869 -0.05567981 -0.20076893\n",
            " -0.19555301 -0.17653354 -0.17220928 -0.14038426 -0.13133666 -0.16183247\n",
            " -0.16841021 -0.16431191 -0.10228922 -0.09571628 -0.1479739  -0.11015026\n",
            " -0.11686155 -0.1479739  -0.12502073 -0.14387081 -0.11703573 -0.16969351\n",
            " -0.11495644 -0.18298146 -0.19586553 -0.15318502 -0.13782197 -0.13212738\n",
            " -0.13186556 -0.13327761  0.0172116   0.16887739  0.0354388   0.10871713\n",
            "  0.05088995 -0.07084741  0.27300625 -0.00529705  0.05424667  0.00431794\n",
            "  0.17531679  0.13144433  0.09639457  0.16653628  0.13439873  0.12499641\n",
            "  0.12473783 -0.05411775 -0.15056515  0.18631386  0.06094945  0.19725806\n",
            " -0.08863488  0.19721107  0.08487711  0.05358423  0.21786856  0.2153987\n",
            "  0.07843291  0.08748375  0.00838255  0.00083463  0.07053075  0.1977902\n",
            "  0.12832053 -0.01779859  0.0864649   0.13131557  0.23102404  0.11396087\n",
            "  0.06518608  0.14039579  0.16887739  0.03433555  0.05326846  0.12437508\n",
            "  0.16516487  0.15117275  0.12407215  0.19033039]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884, 1.0217537216677286, 0.9786398695092615, 0.9381518154589633]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Adaline - Learning rate 0.0001')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "weight, loss = fit(X, y)\n",
        "plt.plot(range(1, len(loss) + 1), np.log10(loss), marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('log(Mean squared error)')\n",
        "plt.title('Adaline - Learning rate 0.0001')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-v6u1KNObz7P",
        "outputId": "8bc0e7a9-b65e-49b1-c3e2-ad9f5e99a375"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0 starting.....\n",
            "Predicted Output from the Adaline Model in the 0 th step is as follows: [-0.04673288 -0.04286851 -0.04162837 -0.04263438 -0.0466493  -0.05216893\n",
            " -0.04228052 -0.04666592 -0.03928155 -0.04533506 -0.05069746 -0.04651538\n",
            " -0.04312216 -0.03684447 -0.0515101  -0.05449912 -0.04787705 -0.04586747\n",
            " -0.05434143 -0.04852496 -0.05125888 -0.04713138 -0.0399104  -0.04629922\n",
            " -0.04973428 -0.0456262  -0.04600807 -0.04841761 -0.04681646 -0.04484728\n",
            " -0.04493086 -0.04738213 -0.05245204 -0.05287711 -0.04533506 -0.04239067\n",
            " -0.04810694 -0.04533506 -0.03873676 -0.04727768 -0.04418275 -0.0347859\n",
            " -0.0397931  -0.04480543 -0.05195142 -0.04139134 -0.05046333 -0.04208958\n",
            " -0.05008571 -0.04506478 -0.08246979 -0.07177771 -0.08816799 -0.08212309\n",
            " -0.08255908 -0.09873756 -0.06050856 -0.09575143 -0.08460336 -0.09063309\n",
            " -0.07783546 -0.07759419 -0.08204085 -0.06817123 -0.06797884 -0.07677341\n",
            " -0.0828018  -0.10378225 -0.09872472 -0.07274903 -0.08412407 -0.06807102\n",
            " -0.10023134 -0.07355596 -0.08515955 -0.09350528 -0.07239941 -0.07391697\n",
            " -0.07961045 -0.09203382 -0.09282367 -0.10351767 -0.07874504 -0.07882629\n",
            " -0.08277669 -0.09225365 -0.0795715  -0.08271822 -0.07223224 -0.08210781\n",
            " -0.08043401 -0.07715809 -0.07177771 -0.08565825 -0.08169791 -0.07647937\n",
            " -0.07270718 -0.07785208 -0.07767921 -0.07483939]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [0.04673288 0.04286851 0.04162837 0.04263438 0.0466493  0.05216893\n",
            " 0.04228052 0.04666592 0.03928155 0.04533506 0.05069746 0.04651538\n",
            " 0.04312216 0.03684447 0.0515101  0.05449912 0.04787705 0.04586747\n",
            " 0.05434143 0.04852496 0.05125888 0.04713138 0.0399104  0.04629922\n",
            " 0.04973428 0.0456262  0.04600807 0.04841761 0.04681646 0.04484728\n",
            " 0.04493086 0.04738213 0.05245204 0.05287711 0.04533506 0.04239067\n",
            " 0.04810694 0.04533506 0.03873676 0.04727768 0.04418275 0.0347859\n",
            " 0.0397931  0.04480543 0.05195142 0.04139134 0.05046333 0.04208958\n",
            " 0.05008571 0.04506478 1.08246979 1.07177771 1.08816799 1.08212309\n",
            " 1.08255908 1.09873756 1.06050856 1.09575143 1.08460336 1.09063309\n",
            " 1.07783546 1.07759419 1.08204085 1.06817123 1.06797884 1.07677341\n",
            " 1.0828018  1.10378225 1.09872472 1.07274903 1.08412407 1.06807102\n",
            " 1.10023134 1.07355596 1.08515955 1.09350528 1.07239941 1.07391697\n",
            " 1.07961045 1.09203382 1.09282367 1.10351767 1.07874504 1.07882629\n",
            " 1.08277669 1.09225365 1.0795715  1.08271822 1.07223224 1.08210781\n",
            " 1.08043401 1.07715809 1.07177771 1.08565825 1.08169791 1.07647937\n",
            " 1.07270718 1.07785208 1.07767921 1.07483939]\n",
            "Current value for the Loss value is :: [29.313307773211772]\n",
            "Epoch - 1 starting.....\n",
            "Predicted Output from the Adaline Model in the 1 th step is as follows: [0.25055975 0.23861611 0.23282983 0.23253187 0.24864986 0.2742471\n",
            " 0.23601415 0.24829527 0.22210338 0.23977604 0.26405868 0.24412092\n",
            " 0.23357854 0.2123268  0.27392253 0.28532813 0.26638103 0.25252689\n",
            " 0.28033072 0.25797506 0.26451006 0.25878165 0.22850204 0.26003962\n",
            " 0.25002047 0.24561959 0.25419608 0.2555967  0.25246963 0.23872938\n",
            " 0.24063926 0.26451131 0.26059287 0.27096535 0.23977604 0.24007462\n",
            " 0.26087498 0.23977604 0.22129741 0.25136571 0.24748993 0.21821113\n",
            " 0.22361852 0.25929091 0.26780827 0.23751282 0.25797443 0.23172591\n",
            " 0.26098824 0.24516821 0.42078794 0.36897094 0.4320347  0.39450967\n",
            " 0.4136127  0.4611525  0.32328252 0.43897966 0.40608225 0.45387004\n",
            " 0.3982339  0.3913266  0.41495732 0.36358002 0.3799672  0.40499792\n",
            " 0.39984458 0.47744101 0.46941457 0.35947397 0.42821617 0.36202472\n",
            " 0.46190121 0.37842295 0.41930157 0.43349133 0.37454655 0.37576373\n",
            " 0.40232098 0.42330291 0.43892366 0.47374805 0.40428812 0.37761511\n",
            " 0.37701858 0.45832464 0.41211528 0.39793469 0.37072677 0.41722179\n",
            " 0.42091537 0.41525652 0.36897094 0.42907877 0.42717013 0.40992161\n",
            " 0.3800355  0.39787931 0.40314466 0.37355589]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.25055975 -0.23861611 -0.23282983 -0.23253187 -0.24864986 -0.2742471\n",
            " -0.23601415 -0.24829527 -0.22210338 -0.23977604 -0.26405868 -0.24412092\n",
            " -0.23357854 -0.2123268  -0.27392253 -0.28532813 -0.26638103 -0.25252689\n",
            " -0.28033072 -0.25797506 -0.26451006 -0.25878165 -0.22850204 -0.26003962\n",
            " -0.25002047 -0.24561959 -0.25419608 -0.2555967  -0.25246963 -0.23872938\n",
            " -0.24063926 -0.26451131 -0.26059287 -0.27096535 -0.23977604 -0.24007462\n",
            " -0.26087498 -0.23977604 -0.22129741 -0.25136571 -0.24748993 -0.21821113\n",
            " -0.22361852 -0.25929091 -0.26780827 -0.23751282 -0.25797443 -0.23172591\n",
            " -0.26098824 -0.24516821  0.57921206  0.63102906  0.5679653   0.60549033\n",
            "  0.5863873   0.5388475   0.67671748  0.56102034  0.59391775  0.54612996\n",
            "  0.6017661   0.6086734   0.58504268  0.63641998  0.6200328   0.59500208\n",
            "  0.60015542  0.52255899  0.53058543  0.64052603  0.57178383  0.63797528\n",
            "  0.53809879  0.62157705  0.58069843  0.56650867  0.62545345  0.62423627\n",
            "  0.59767902  0.57669709  0.56107634  0.52625195  0.59571188  0.62238489\n",
            "  0.62298142  0.54167536  0.58788472  0.60206531  0.62927323  0.58277821\n",
            "  0.57908463  0.58474348  0.63102906  0.57092123  0.57282987  0.59007839\n",
            "  0.6199645   0.60212069  0.59685534  0.62644411]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572]\n",
            "Epoch - 2 starting.....\n",
            "Predicted Output from the Adaline Model in the 2 th step is as follows: [0.35658072 0.33975752 0.33078687 0.33162976 0.35380516 0.3915064\n",
            " 0.3355753  0.35400409 0.31621792 0.34225316 0.37637842 0.34865189\n",
            " 0.33283748 0.30064962 0.38849418 0.40587642 0.37782832 0.3591149\n",
            " 0.40051951 0.36736531 0.37838657 0.36828919 0.32258364 0.37122121\n",
            " 0.35891046 0.35098242 0.36249195 0.3643861  0.35935628 0.34104544\n",
            " 0.343821   0.37661587 0.37151372 0.38539624 0.34225316 0.34052493\n",
            " 0.37070464 0.34225316 0.3144087  0.35838995 0.35130952 0.31005665\n",
            " 0.31762929 0.3691706  0.38357757 0.33790583 0.36825066 0.32982053\n",
            " 0.37199256 0.34897427 0.62157439 0.54400258 0.63827416 0.58371591\n",
            " 0.61107366 0.68414011 0.47572378 0.65151115 0.6016572  0.66929754\n",
            " 0.58528926 0.57715678 0.6114385  0.53551078 0.55828374 0.59534496\n",
            " 0.5906784  0.70736204 0.69741169 0.5311666  0.63095234 0.53253629\n",
            " 0.68619072 0.55655866 0.61872258 0.64169762 0.55036358 0.55261784\n",
            " 0.59409399 0.62656964 0.64998184 0.70080685 0.59662816 0.55740549\n",
            " 0.55997661 0.6764967  0.60697243 0.58790284 0.54481246 0.61401513\n",
            " 0.61968498 0.60882491 0.54400258 0.63340552 0.62885926 0.60186242\n",
            " 0.55929176 0.58548818 0.59321336 0.55068516]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.35658072 -0.33975752 -0.33078687 -0.33162976 -0.35380516 -0.3915064\n",
            " -0.3355753  -0.35400409 -0.31621792 -0.34225316 -0.37637842 -0.34865189\n",
            " -0.33283748 -0.30064962 -0.38849418 -0.40587642 -0.37782832 -0.3591149\n",
            " -0.40051951 -0.36736531 -0.37838657 -0.36828919 -0.32258364 -0.37122121\n",
            " -0.35891046 -0.35098242 -0.36249195 -0.3643861  -0.35935628 -0.34104544\n",
            " -0.343821   -0.37661587 -0.37151372 -0.38539624 -0.34225316 -0.34052493\n",
            " -0.37070464 -0.34225316 -0.3144087  -0.35838995 -0.35130952 -0.31005665\n",
            " -0.31762929 -0.3691706  -0.38357757 -0.33790583 -0.36825066 -0.32982053\n",
            " -0.37199256 -0.34897427  0.37842561  0.45599742  0.36172584  0.41628409\n",
            "  0.38892634  0.31585989  0.52427622  0.34848885  0.3983428   0.33070246\n",
            "  0.41471074  0.42284322  0.3885615   0.46448922  0.44171626  0.40465504\n",
            "  0.4093216   0.29263796  0.30258831  0.4688334   0.36904766  0.46746371\n",
            "  0.31380928  0.44344134  0.38127742  0.35830238  0.44963642  0.44738216\n",
            "  0.40590601  0.37343036  0.35001816  0.29919315  0.40337184  0.44259451\n",
            "  0.44002339  0.3235033   0.39302757  0.41209716  0.45518754  0.38598487\n",
            "  0.38031502  0.39117509  0.45599742  0.36659448  0.37114074  0.39813758\n",
            "  0.44070824  0.41451182  0.40678664  0.44931484]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435]\n",
            "Epoch - 3 starting.....\n",
            "Predicted Output from the Adaline Model in the 3 th step is as follows: [0.38912482 0.3715975  0.36093879 0.36306246 0.38592154 0.42839336\n",
            " 0.36646709 0.38699633 0.34604903 0.37454759 0.4109302  0.38166457\n",
            " 0.3639148  0.32719854 0.42210761 0.44220833 0.41138474 0.39201556\n",
            " 0.43828981 0.40103376 0.41466847 0.40233582 0.34974509 0.40737615\n",
            " 0.39442104 0.38489377 0.39702998 0.39816893 0.39232809 0.37369526\n",
            " 0.37689853 0.41194565 0.40481027 0.41941341 0.37454759 0.37106251\n",
            " 0.40404049 0.37454759 0.34338556 0.39178829 0.38297145 0.3399475\n",
            " 0.34656292 0.40440014 0.42093312 0.36969629 0.40239517 0.36039899\n",
            " 0.40613825 0.3811555  0.70553721 0.61643148 0.7232917  0.66193866\n",
            " 0.69317854 0.77701657 0.53883208 0.73962332 0.68325608 0.75768302\n",
            " 0.66080932 0.65368753 0.6919072  0.60710075 0.63247388 0.67319391\n",
            " 0.6688591  0.80166087 0.79399176 0.60225686 0.71416232 0.60282267\n",
            " 0.77999258 0.62899621 0.7003856  0.72684094 0.62154078 0.62417833\n",
            " 0.67381417 0.70937778 0.73721303 0.79270683 0.67670491 0.63041697\n",
            " 0.63602572 0.76632924 0.68722652 0.66565582 0.61513422 0.69403568\n",
            " 0.70162831 0.68706071 0.61643148 0.71787467 0.71194857 0.68014027\n",
            " 0.63296175 0.66188412 0.67103951 0.62309873]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38912482 -0.3715975  -0.36093879 -0.36306246 -0.38592154 -0.42839336\n",
            " -0.36646709 -0.38699633 -0.34604903 -0.37454759 -0.4109302  -0.38166457\n",
            " -0.3639148  -0.32719854 -0.42210761 -0.44220833 -0.41138474 -0.39201556\n",
            " -0.43828981 -0.40103376 -0.41466847 -0.40233582 -0.34974509 -0.40737615\n",
            " -0.39442104 -0.38489377 -0.39702998 -0.39816893 -0.39232809 -0.37369526\n",
            " -0.37689853 -0.41194565 -0.40481027 -0.41941341 -0.37454759 -0.37106251\n",
            " -0.40404049 -0.37454759 -0.34338556 -0.39178829 -0.38297145 -0.3399475\n",
            " -0.34656292 -0.40440014 -0.42093312 -0.36969629 -0.40239517 -0.36039899\n",
            " -0.40613825 -0.3811555   0.29446279  0.38356852  0.2767083   0.33806134\n",
            "  0.30682146  0.22298343  0.46116792  0.26037668  0.31674392  0.24231698\n",
            "  0.33919068  0.34631247  0.3080928   0.39289925  0.36752612  0.32680609\n",
            "  0.3311409   0.19833913  0.20600824  0.39774314  0.28583768  0.39717733\n",
            "  0.22000742  0.37100379  0.2996144   0.27315906  0.37845922  0.37582167\n",
            "  0.32618583  0.29062222  0.26278697  0.20729317  0.32329509  0.36958303\n",
            "  0.36397428  0.23367076  0.31277348  0.33434418  0.38486578  0.30596432\n",
            "  0.29837169  0.31293929  0.38356852  0.28212533  0.28805143  0.31985973\n",
            "  0.36703825  0.33811588  0.32896049  0.37690127]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211]\n",
            "Epoch - 4 starting.....\n",
            "Predicted Output from the Adaline Model in the 4 th step is as follows: [0.39359852 0.37694019 0.36518484 0.36861718 0.39013943 0.43455143\n",
            " 0.37111637 0.39219369 0.35129604 0.38000681 0.41577021 0.38732978\n",
            " 0.36892765 0.33016346 0.42483522 0.44638597 0.41520277 0.39676052\n",
            " 0.4445496  0.40577203 0.42127019 0.40754258 0.35138861 0.41481311\n",
            " 0.40184127 0.39146506 0.40335486 0.40328623 0.39705761 0.37969634\n",
            " 0.38315543 0.41791986 0.40847292 0.42274083 0.38000681 0.3748993\n",
            " 0.40816352 0.38000681 0.34785032 0.39704424 0.38707281 0.34612272\n",
            " 0.35063322 0.41107031 0.42828269 0.37525165 0.4074472  0.36517147\n",
            " 0.41091966 0.38596508 0.74425766 0.64914979 0.76140248 0.69720921\n",
            " 0.73062407 0.81951533 0.56736504 0.77957477 0.7207199  0.79692404\n",
            " 0.69322282 0.68792736 0.7275022  0.63984118 0.66635123 0.7075326\n",
            " 0.70346458 0.84349663 0.83963557 0.63440846 0.75113396 0.63432782\n",
            " 0.82325814 0.66056616 0.73650033 0.76438708 0.6522699  0.65503943\n",
            " 0.7101543  0.74560586 0.77652153 0.83236222 0.7133163  0.66214594\n",
            " 0.67068578 0.80650405 0.72313845 0.70000549 0.64535172 0.72890702\n",
            " 0.73836627 0.72071953 0.64914979 0.75595775 0.74914833 0.71446416\n",
            " 0.66578242 0.69527708 0.70545158 0.65501268]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.39359852 -0.37694019 -0.36518484 -0.36861718 -0.39013943 -0.43455143\n",
            " -0.37111637 -0.39219369 -0.35129604 -0.38000681 -0.41577021 -0.38732978\n",
            " -0.36892765 -0.33016346 -0.42483522 -0.44638597 -0.41520277 -0.39676052\n",
            " -0.4445496  -0.40577203 -0.42127019 -0.40754258 -0.35138861 -0.41481311\n",
            " -0.40184127 -0.39146506 -0.40335486 -0.40328623 -0.39705761 -0.37969634\n",
            " -0.38315543 -0.41791986 -0.40847292 -0.42274083 -0.38000681 -0.3748993\n",
            " -0.40816352 -0.38000681 -0.34785032 -0.39704424 -0.38707281 -0.34612272\n",
            " -0.35063322 -0.41107031 -0.42828269 -0.37525165 -0.4074472  -0.36517147\n",
            " -0.41091966 -0.38596508  0.25574234  0.35085021  0.23859752  0.30279079\n",
            "  0.26937593  0.18048467  0.43263496  0.22042523  0.2792801   0.20307596\n",
            "  0.30677718  0.31207264  0.2724978   0.36015882  0.33364877  0.2924674\n",
            "  0.29653542  0.15650337  0.16036443  0.36559154  0.24886604  0.36567218\n",
            "  0.17674186  0.33943384  0.26349967  0.23561292  0.3477301   0.34496057\n",
            "  0.2898457   0.25439414  0.22347847  0.16763778  0.2866837   0.33785406\n",
            "  0.32931422  0.19349595  0.27686155  0.29999451  0.35464828  0.27109298\n",
            "  0.26163373  0.27928047  0.35085021  0.24404225  0.25085167  0.28553584\n",
            "  0.33421758  0.30472292  0.29454842  0.34498732]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835]\n",
            "Epoch - 5 starting.....\n",
            "Predicted Output from the Adaline Model in the 5 th step is as follows: [0.38749993 0.3722815  0.35967163 0.36439812 0.38385425 0.42911222\n",
            " 0.36587323 0.38690789 0.34725849 0.37533614 0.40941767 0.38267018\n",
            " 0.36410707 0.32426094 0.41597188 0.43847172 0.40783814 0.39089624\n",
            " 0.4389178  0.39961208 0.41665738 0.40187596 0.34346772 0.41137955\n",
            " 0.39862574 0.38769665 0.39901904 0.39759656 0.3911456  0.37562719\n",
            " 0.37927286 0.41281297 0.40099489 0.41453946 0.37533614 0.36868745\n",
            " 0.40129386 0.37533614 0.34307241 0.391686   0.38079961 0.34331975\n",
            " 0.34533729 0.40694411 0.42428248 0.3708997  0.40153429 0.36021204\n",
            " 0.40463955 0.38045693 0.76533955 0.66640978 0.78126336 0.71576151\n",
            " 0.75067247 0.84238356 0.58243813 0.80077228 0.74098124 0.81705841\n",
            " 0.70891509 0.7057155  0.74565494 0.65744458 0.68452379 0.72496296\n",
            " 0.72113165 0.86493603 0.8653801  0.65140002 0.7701276  0.65074527\n",
            " 0.846819   0.67626699 0.75491119 0.78343593 0.6673028  0.67010808\n",
            " 0.72959612 0.76374138 0.79717723 0.85174407 0.73299244 0.67784752\n",
            " 0.6892227  0.82736171 0.7418016  0.71748598 0.66001145 0.74624697\n",
            " 0.75751673 0.73708404 0.66640978 0.77598653 0.76849645 0.7317139\n",
            " 0.68271694 0.71196872 0.72299013 0.6711889 ]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38749993 -0.3722815  -0.35967163 -0.36439812 -0.38385425 -0.42911222\n",
            " -0.36587323 -0.38690789 -0.34725849 -0.37533614 -0.40941767 -0.38267018\n",
            " -0.36410707 -0.32426094 -0.41597188 -0.43847172 -0.40783814 -0.39089624\n",
            " -0.4389178  -0.39961208 -0.41665738 -0.40187596 -0.34346772 -0.41137955\n",
            " -0.39862574 -0.38769665 -0.39901904 -0.39759656 -0.3911456  -0.37562719\n",
            " -0.37927286 -0.41281297 -0.40099489 -0.41453946 -0.37533614 -0.36868745\n",
            " -0.40129386 -0.37533614 -0.34307241 -0.391686   -0.38079961 -0.34331975\n",
            " -0.34533729 -0.40694411 -0.42428248 -0.3708997  -0.40153429 -0.36021204\n",
            " -0.40463955 -0.38045693  0.23466045  0.33359022  0.21873664  0.28423849\n",
            "  0.24932753  0.15761644  0.41756187  0.19922772  0.25901876  0.18294159\n",
            "  0.29108491  0.2942845   0.25434506  0.34255542  0.31547621  0.27503704\n",
            "  0.27886835  0.13506397  0.1346199   0.34859998  0.2298724   0.34925473\n",
            "  0.153181    0.32373301  0.24508881  0.21656407  0.3326972   0.32989192\n",
            "  0.27040388  0.23625862  0.20282277  0.14825593  0.26700756  0.32215248\n",
            "  0.3107773   0.17263829  0.2581984   0.28251402  0.33998855  0.25375303\n",
            "  0.24248327  0.26291596  0.33359022  0.22401347  0.23150355  0.2682861\n",
            "  0.31728306  0.28803128  0.27700987  0.3288111 ]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625]\n",
            "Epoch - 6 starting.....\n",
            "Predicted Output from the Adaline Model in the 6 th step is as follows: [0.37756752 0.36397462 0.35061725 0.3566078  0.37376483 0.419444\n",
            " 0.35703436 0.37780609 0.33982899 0.3669695  0.39900438 0.37424196\n",
            " 0.3557041  0.31515788 0.40294674 0.42619099 0.39643607 0.38117999\n",
            " 0.42895034 0.38949804 0.40794227 0.39225515 0.33212468 0.40395015\n",
            " 0.3914979  0.38013664 0.39078301 0.38797756 0.38137022 0.36787319\n",
            " 0.37167589 0.40366325 0.38949724 0.40218725 0.3669695  0.35883943\n",
            " 0.39044776 0.3669695  0.33493237 0.38246415 0.37076995 0.33721539\n",
            " 0.33664308 0.3988633  0.41611843 0.36292904 0.39163756 0.35171117\n",
            " 0.39434633 0.37119875 0.77943134 0.67756629 0.79392786 0.72771472\n",
            " 0.76384002 0.85748201 0.59219626 0.81455914 0.75442947 0.82967189\n",
            " 0.71806193 0.71701858 0.75694577 0.669058   0.69648398 0.73574524\n",
            " 0.7321342  0.87834737 0.88319951 0.66240376 0.78204344 0.66121404\n",
            " 0.86256886 0.68574014 0.76635775 0.79521121 0.67618546 0.6789901\n",
            " 0.74235482 0.7747716  0.81047034 0.8631826  0.74596728 0.68726205\n",
            " 0.70138267 0.84060509 0.75366631 0.72833151 0.66858006 0.7567072\n",
            " 0.76973246 0.7466762  0.67756629 0.78888935 0.78080762 0.74225671\n",
            " 0.69339387 0.7221032  0.73389182 0.68117795]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.37756752 -0.36397462 -0.35061725 -0.3566078  -0.37376483 -0.419444\n",
            " -0.35703436 -0.37780609 -0.33982899 -0.3669695  -0.39900438 -0.37424196\n",
            " -0.3557041  -0.31515788 -0.40294674 -0.42619099 -0.39643607 -0.38117999\n",
            " -0.42895034 -0.38949804 -0.40794227 -0.39225515 -0.33212468 -0.40395015\n",
            " -0.3914979  -0.38013664 -0.39078301 -0.38797756 -0.38137022 -0.36787319\n",
            " -0.37167589 -0.40366325 -0.38949724 -0.40218725 -0.3669695  -0.35883943\n",
            " -0.39044776 -0.3669695  -0.33493237 -0.38246415 -0.37076995 -0.33721539\n",
            " -0.33664308 -0.3988633  -0.41611843 -0.36292904 -0.39163756 -0.35171117\n",
            " -0.39434633 -0.37119875  0.22056866  0.32243371  0.20607214  0.27228528\n",
            "  0.23615998  0.14251799  0.40780374  0.18544086  0.24557053  0.17032811\n",
            "  0.28193807  0.28298142  0.24305423  0.330942    0.30351602  0.26425476\n",
            "  0.2678658   0.12165263  0.11680049  0.33759624  0.21795656  0.33878596\n",
            "  0.13743114  0.31425986  0.23364225  0.20478879  0.32381454  0.3210099\n",
            "  0.25764518  0.2252284   0.18952966  0.1368174   0.25403272  0.31273795\n",
            "  0.29861733  0.15939491  0.24633369  0.27166849  0.33141994  0.2432928\n",
            "  0.23026754  0.2533238   0.32243371  0.21111065  0.21919238  0.25774329\n",
            "  0.30660613  0.2778968   0.26610818  0.31882205]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933]\n",
            "Epoch - 7 starting.....\n",
            "Predicted Output from the Adaline Model in the 7 th step is as follows: [0.36639178 0.35446257 0.34041217 0.34763146 0.36244623 0.40838005\n",
            " 0.3470206  0.36745177 0.33127357 0.35738091 0.38727209 0.36456622\n",
            " 0.34612233 0.30503233 0.38861453 0.4125131  0.38374288 0.37020959\n",
            " 0.41755263 0.3780995  0.39786005 0.38134045 0.31971936 0.39516936\n",
            " 0.38304409 0.37130358 0.3812467  0.37707349 0.37033733 0.35889005\n",
            " 0.3628356  0.3931771  0.37671691 0.38851958 0.35738091 0.34782015\n",
            " 0.37832218 0.35738091 0.32569116 0.3719742  0.35952788 0.32999329\n",
            " 0.3268449  0.38945921 0.40655449 0.35375796 0.38044098 0.34204904\n",
            " 0.38274966 0.36071561 0.79064433 0.68623045 0.80366254 0.73697495\n",
            " 0.77418653 0.86938971 0.5997835  0.82531424 0.76507574 0.83923605\n",
            " 0.72458959 0.72568358 0.76545811 0.6782128  0.70589641 0.74383921\n",
            " 0.74043738 0.88850422 0.89771815 0.67096037 0.79108849 0.66926171\n",
            " 0.87509986 0.69270617 0.77498488 0.80404455 0.68260132 0.68539194\n",
            " 0.75237396 0.78293659 0.82075902 0.87143556 0.75619177 0.69414817\n",
            " 0.71092822 0.85075131 0.76276622 0.73649183 0.67471022 0.76439811\n",
            " 0.7791253  0.75355587 0.68623045 0.79888465 0.79025615 0.75009344\n",
            " 0.70152953 0.72959514 0.74210739 0.68866567]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.36639178 -0.35446257 -0.34041217 -0.34763146 -0.36244623 -0.40838005\n",
            " -0.3470206  -0.36745177 -0.33127357 -0.35738091 -0.38727209 -0.36456622\n",
            " -0.34612233 -0.30503233 -0.38861453 -0.4125131  -0.38374288 -0.37020959\n",
            " -0.41755263 -0.3780995  -0.39786005 -0.38134045 -0.31971936 -0.39516936\n",
            " -0.38304409 -0.37130358 -0.3812467  -0.37707349 -0.37033733 -0.35889005\n",
            " -0.3628356  -0.3931771  -0.37671691 -0.38851958 -0.35738091 -0.34782015\n",
            " -0.37832218 -0.35738091 -0.32569116 -0.3719742  -0.35952788 -0.32999329\n",
            " -0.3268449  -0.38945921 -0.40655449 -0.35375796 -0.38044098 -0.34204904\n",
            " -0.38274966 -0.36071561  0.20935567  0.31376955  0.19633746  0.26302505\n",
            "  0.22581347  0.13061029  0.4002165   0.17468576  0.23492426  0.16076395\n",
            "  0.27541041  0.27431642  0.23454189  0.3217872   0.29410359  0.25616079\n",
            "  0.25956262  0.11149578  0.10228185  0.32903963  0.20891151  0.33073829\n",
            "  0.12490014  0.30729383  0.22501512  0.19595545  0.31739868  0.31460806\n",
            "  0.24762604  0.21706341  0.17924098  0.12856444  0.24380823  0.30585183\n",
            "  0.28907178  0.14924869  0.23723378  0.26350817  0.32528978  0.23560189\n",
            "  0.2208747   0.24644413  0.31376955  0.20111535  0.20974385  0.24990656\n",
            "  0.29847047  0.27040486  0.25789261  0.31133433]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789]\n",
            "Epoch - 8 starting.....\n",
            "Predicted Output from the Adaline Model in the 8 th step is as follows: [0.35496415 0.34468096 0.32997139 0.3383828  0.3508839  0.39700545\n",
            " 0.33675877 0.35682649 0.32246026 0.34751796 0.37527018 0.35460858\n",
            " 0.33628215 0.29471747 0.37406665 0.39857398 0.37080916 0.35897947\n",
            " 0.40583736 0.36643826 0.38745861 0.37015034 0.30715364 0.38605085\n",
            " 0.37425579 0.3621626  0.3714062  0.36589671 0.3590444  0.3496186\n",
            " 0.35369886 0.3823911  0.36370083 0.3746208  0.34751796 0.33657279\n",
            " 0.36594905 0.34751796 0.31621443 0.36120998 0.3480469  0.32249056\n",
            " 0.31682091 0.37974008 0.39664987 0.34431279 0.36897201 0.33213697\n",
            " 0.37088669 0.34997418 0.80056928 0.6937988  0.81211715 0.74505279\n",
            " 0.78328244 0.87987812 0.60641581 0.83473122 0.77447194 0.84747951\n",
            " 0.73001477 0.7331979  0.77277038 0.68627508 0.71417864 0.75077538\n",
            " 0.74757394 0.89725193 0.91072651 0.67843923 0.79888914 0.67625223\n",
            " 0.88618889 0.6986028  0.78239475 0.81161023 0.68797348 0.69074554\n",
            " 0.761179   0.78987497 0.82972865 0.87834105 0.76519432 0.69995823\n",
            " 0.7193148  0.85954689 0.77066091 0.74349369 0.67981297 0.77090804\n",
            " 0.78728516 0.75929146 0.6937988  0.80760379 0.79845603 0.75677031\n",
            " 0.70856071 0.73595736 0.74916395 0.69507669]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.35496415 -0.34468096 -0.32997139 -0.3383828  -0.3508839  -0.39700545\n",
            " -0.33675877 -0.35682649 -0.32246026 -0.34751796 -0.37527018 -0.35460858\n",
            " -0.33628215 -0.29471747 -0.37406665 -0.39857398 -0.37080916 -0.35897947\n",
            " -0.40583736 -0.36643826 -0.38745861 -0.37015034 -0.30715364 -0.38605085\n",
            " -0.37425579 -0.3621626  -0.3714062  -0.36589671 -0.3590444  -0.3496186\n",
            " -0.35369886 -0.3823911  -0.36370083 -0.3746208  -0.34751796 -0.33657279\n",
            " -0.36594905 -0.34751796 -0.31621443 -0.36120998 -0.3480469  -0.32249056\n",
            " -0.31682091 -0.37974008 -0.39664987 -0.34431279 -0.36897201 -0.33213697\n",
            " -0.37088669 -0.34997418  0.19943072  0.3062012   0.18788285  0.25494721\n",
            "  0.21671756  0.12012188  0.39358419  0.16526878  0.22552806  0.15252049\n",
            "  0.26998523  0.2668021   0.22722962  0.31372492  0.28582136  0.24922462\n",
            "  0.25242606  0.10274807  0.08927349  0.32156077  0.20111086  0.32374777\n",
            "  0.11381111  0.3013972   0.21760525  0.18838977  0.31202652  0.30925446\n",
            "  0.238821    0.21012503  0.17027135  0.12165895  0.23480568  0.30004177\n",
            "  0.2806852   0.14045311  0.22933909  0.25650631  0.32018703  0.22909196\n",
            "  0.21271484  0.24070854  0.3062012   0.19239621  0.20154397  0.24322969\n",
            "  0.29143929  0.26404264  0.25083605  0.30492331]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237]\n",
            "Epoch - 9 starting.....\n",
            "Predicted Output from the Adaline Model in the 9 th step is as follows: [0.34365984 0.3349845  0.31964121 0.32920835 0.33945064 0.38573148\n",
            " 0.32659982 0.34630211 0.31371825 0.33773985 0.36339586 0.34473517\n",
            " 0.32653236 0.28452818 0.35971498 0.38480298 0.35803197 0.34786607\n",
            " 0.39422628 0.35490107 0.3771355  0.35907059 0.29476749 0.37697975\n",
            " 0.3655098  0.35308016 0.36163944 0.35483063 0.34786905 0.34041585\n",
            " 0.34462505 0.3716982  0.35084463 0.36090042 0.33773985 0.32545406\n",
            " 0.3537186  0.33773985 0.30683007 0.35054802 0.33669528 0.31502527\n",
            " 0.30690348 0.37008861 0.38680681 0.33494482 0.35761971 0.32232018\n",
            " 0.35914995 0.33934052 0.80982502 0.70081396 0.81993238 0.75253508\n",
            " 0.79173828 0.88963607 0.61256564 0.84346832 0.78322165 0.8550732\n",
            " 0.73492508 0.74013917 0.77949514 0.69377599 0.72188181 0.75714762\n",
            " 0.75413872 0.90530673 0.92292226 0.68537246 0.80607667 0.68271532\n",
            " 0.89652722 0.70398752 0.7892091  0.81855789 0.69285344 0.69560582\n",
            " 0.76936297 0.79622226 0.838034   0.88461146 0.7735692  0.70525529\n",
            " 0.72710823 0.86767005 0.77795598 0.74992952 0.68443503 0.77685288\n",
            " 0.7948295  0.7644907  0.70081396 0.81568052 0.80603402 0.76288705\n",
            " 0.71504522 0.74177655 0.75565409 0.70096376]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.34365984 -0.3349845  -0.31964121 -0.32920835 -0.33945064 -0.38573148\n",
            " -0.32659982 -0.34630211 -0.31371825 -0.33773985 -0.36339586 -0.34473517\n",
            " -0.32653236 -0.28452818 -0.35971498 -0.38480298 -0.35803197 -0.34786607\n",
            " -0.39422628 -0.35490107 -0.3771355  -0.35907059 -0.29476749 -0.37697975\n",
            " -0.3655098  -0.35308016 -0.36163944 -0.35483063 -0.34786905 -0.34041585\n",
            " -0.34462505 -0.3716982  -0.35084463 -0.36090042 -0.33773985 -0.32545406\n",
            " -0.3537186  -0.33773985 -0.30683007 -0.35054802 -0.33669528 -0.31502527\n",
            " -0.30690348 -0.37008861 -0.38680681 -0.33494482 -0.35761971 -0.32232018\n",
            " -0.35914995 -0.33934052  0.19017498  0.29918604  0.18006762  0.24746492\n",
            "  0.20826172  0.11036393  0.38743436  0.15653168  0.21677835  0.1449268\n",
            "  0.26507492  0.25986083  0.22050486  0.30622401  0.27811819  0.24285238\n",
            "  0.24586128  0.09469327  0.07707774  0.31462754  0.19392333  0.31728468\n",
            "  0.10347278  0.29601248  0.2107909   0.18144211  0.30714656  0.30439418\n",
            "  0.23063703  0.20377774  0.161966    0.11538854  0.2264308   0.29474471\n",
            "  0.27289177  0.13232995  0.22204402  0.25007048  0.31556497  0.22314712\n",
            "  0.2051705   0.2355093   0.29918604  0.18431948  0.19396598  0.23711295\n",
            "  0.28495478  0.25822345  0.24434591  0.29903624]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601]\n",
            "Epoch - 10 starting.....\n",
            "Predicted Output from the Adaline Model in the 10 th step is as follows: [0.33261669 0.32550406 0.30954893 0.32023618 0.32828327 0.37470991\n",
            " 0.31667293 0.33601563 0.30516917 0.32817919 0.35179508 0.33508117\n",
            " 0.31700154 0.27457971 0.34570963 0.37135732 0.3455567  0.33700782\n",
            " 0.38287495 0.34363004 0.36703777 0.34824321 0.28268452 0.36809907\n",
            " 0.35694607 0.34419205 0.35208621 0.34401637 0.3369501  0.33141384\n",
            " 0.33574725 0.36124345 0.33829306 0.34750802 0.32817919 0.31459478\n",
            " 0.34177392 0.32817919 0.29765883 0.34012702 0.32560814 0.30771556\n",
            " 0.29721478 0.36064646 0.37717439 0.32578381 0.34652721 0.31272585\n",
            " 0.3476837  0.32894936 0.81865547 0.70748916 0.82735977 0.7596524\n",
            " 0.7997943  0.89893482 0.61841867 0.85178437 0.79156266 0.86228015\n",
            " 0.73954985 0.74673407 0.78587241 0.70092467 0.72922283 0.76318849\n",
            " 0.76036484 0.91294941 0.9345815  0.69196922 0.81289862 0.6888589\n",
            " 0.90638742 0.70907834 0.79567155 0.82514199 0.69745663 0.70018949\n",
            " 0.77715923 0.80222716 0.84593231 0.890525   0.78155037 0.7102595\n",
            " 0.73453117 0.87538696 0.78488909 0.75603143 0.6887898  0.78247346\n",
            " 0.80200072 0.76939083 0.70748916 0.82336384 0.8132361  0.76867839\n",
            " 0.72120184 0.74728221 0.76180996 0.70654332]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.33261669 -0.32550406 -0.30954893 -0.32023618 -0.32828327 -0.37470991\n",
            " -0.31667293 -0.33601563 -0.30516917 -0.32817919 -0.35179508 -0.33508117\n",
            " -0.31700154 -0.27457971 -0.34570963 -0.37135732 -0.3455567  -0.33700782\n",
            " -0.38287495 -0.34363004 -0.36703777 -0.34824321 -0.28268452 -0.36809907\n",
            " -0.35694607 -0.34419205 -0.35208621 -0.34401637 -0.3369501  -0.33141384\n",
            " -0.33574725 -0.36124345 -0.33829306 -0.34750802 -0.32817919 -0.31459478\n",
            " -0.34177392 -0.32817919 -0.29765883 -0.34012702 -0.32560814 -0.30771556\n",
            " -0.29721478 -0.36064646 -0.37717439 -0.32578381 -0.34652721 -0.31272585\n",
            " -0.3476837  -0.32894936  0.18134453  0.29251084  0.17264023  0.2403476\n",
            "  0.2002057   0.10106518  0.38158133  0.14821563  0.20843734  0.13771985\n",
            "  0.26045015  0.25326593  0.21412759  0.29907533  0.27077717  0.23681151\n",
            "  0.23963516  0.08705059  0.0654185   0.30803078  0.18710138  0.3111411\n",
            "  0.09361258  0.29092166  0.20432845  0.17485801  0.30254337  0.29981051\n",
            "  0.22284077  0.19777284  0.15406769  0.109475    0.21844963  0.2897405\n",
            "  0.26546883  0.12461304  0.21511091  0.24396857  0.3112102   0.21752654\n",
            "  0.19799928  0.23060917  0.29251084  0.17663616  0.1867639   0.23132161\n",
            "  0.27879816  0.25271779  0.23819004  0.29345668]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998]\n",
            "Epoch - 11 starting.....\n",
            "Predicted Output from the Adaline Model in the 11 th step is as follows: [0.3218812  0.31628444 0.29973757 0.31151027 0.31742786 0.36399261\n",
            " 0.30702194 0.32601373 0.29685479 0.31888138 0.34051718 0.32569291\n",
            " 0.30773355 0.26491053 0.33210011 0.35828952 0.3334319  0.32645159\n",
            " 0.37183657 0.33267322 0.35721608 0.33771645 0.27094515 0.35945858\n",
            " 0.34861344 0.33554529 0.34279467 0.33350188 0.32633455 0.3226581\n",
            " 0.32711145 0.35107649 0.32609441 0.33449327 0.31888138 0.30403889\n",
            " 0.33016302 0.31888138 0.28874176 0.32999423 0.31483091 0.30060258\n",
            " 0.28779607 0.35146259 0.36780431 0.31687432 0.33574302 0.30339725\n",
            " 0.33653668 0.3188464  0.82715986 0.71391055 0.83450069 0.76649786\n",
            " 0.8075479  0.90788442 0.62404992 0.85978409 0.7995916  0.86920599\n",
            " 0.7439802  0.7530739  0.79199848 0.70780595 0.73628962 0.7689912\n",
            " 0.76634583 0.92029271 0.94581761 0.69831407 0.81945441 0.69476674\n",
            " 0.91588041 0.71396231 0.80187979 0.83146452 0.70186879 0.70458277\n",
            " 0.78466235 0.80798909 0.85352746 0.89619241 0.78923274 0.71505867\n",
            " 0.74167386 0.8828048  0.79155593 0.76189248 0.69296209 0.78786595\n",
            " 0.80889646 0.77408619 0.71391055 0.83075426 0.82016133 0.77423822\n",
            " 0.72711856 0.75256607 0.76772469 0.71190213]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.3218812  -0.31628444 -0.29973757 -0.31151027 -0.31742786 -0.36399261\n",
            " -0.30702194 -0.32601373 -0.29685479 -0.31888138 -0.34051718 -0.32569291\n",
            " -0.30773355 -0.26491053 -0.33210011 -0.35828952 -0.3334319  -0.32645159\n",
            " -0.37183657 -0.33267322 -0.35721608 -0.33771645 -0.27094515 -0.35945858\n",
            " -0.34861344 -0.33554529 -0.34279467 -0.33350188 -0.32633455 -0.3226581\n",
            " -0.32711145 -0.35107649 -0.32609441 -0.33449327 -0.31888138 -0.30403889\n",
            " -0.33016302 -0.31888138 -0.28874176 -0.32999423 -0.31483091 -0.30060258\n",
            " -0.28779607 -0.35146259 -0.36780431 -0.31687432 -0.33574302 -0.30339725\n",
            " -0.33653668 -0.3188464   0.17284014  0.28608945  0.16549931  0.23350214\n",
            "  0.1924521   0.09211558  0.37595008  0.14021591  0.2004084   0.13079401\n",
            "  0.2560198   0.2469261   0.20800152  0.29219405  0.26371038  0.2310088\n",
            "  0.23365417  0.07970729  0.05418239  0.30168593  0.18054559  0.30523326\n",
            "  0.08411959  0.28603769  0.19812021  0.16853548  0.29813121  0.29541723\n",
            "  0.21533765  0.19201091  0.14647254  0.10380759  0.21076726  0.28494133\n",
            "  0.25832614  0.1171952   0.20844407  0.23810752  0.30703791  0.21213405\n",
            "  0.19110354  0.22591381  0.28608945  0.16924574  0.17983867  0.22576178\n",
            "  0.27288144  0.24743393  0.23227531  0.28809787]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255]\n",
            "Epoch - 12 starting.....\n",
            "Predicted Output from the Adaline Model in the 12 th step is as follows: [0.31146492 0.3073374  0.29021785 0.30304237 0.30689566 0.35359318\n",
            " 0.29765797 0.31630841 0.28878625 0.30985838 0.32957444 0.31658263\n",
            " 0.2987398  0.2555297  0.31889737 0.34561203 0.32166905 0.31620912\n",
            " 0.36112505 0.32204257 0.34768407 0.32750263 0.25955792 0.35107232\n",
            " 0.34052573 0.32715287 0.33377783 0.32329935 0.31603418 0.31416095\n",
            " 0.31873021 0.34121041 0.31426    0.32186752 0.30985838 0.29379703\n",
            " 0.31889749 0.30985838 0.28008936 0.32016181 0.30437468 0.29369797\n",
            " 0.27865765 0.34255037 0.3587109  0.3082282  0.32527941 0.29434548\n",
            " 0.32572104 0.30904323 0.83538147 0.72011514 0.84139843 0.77311139\n",
            " 0.81504119 0.91653266 0.62949165 0.86751263 0.80735049 0.87589554\n",
            " 0.74825386 0.75919761 0.7979141  0.71445662 0.74312027 0.77459511\n",
            " 0.7721213  0.92738443 0.95668099 0.70444341 0.82578625 0.70047461\n",
            " 0.92505462 0.71867588 0.80787519 0.83756856 0.70612559 0.70882151\n",
            " 0.79191324 0.81354981 0.86086402 0.90165974 0.79665744 0.71968949\n",
            " 0.74857537 0.8899693  0.79799729 0.76755204 0.69698707 0.79307061\n",
            " 0.81555847 0.77861592 0.72011514 0.83789491 0.82685198 0.779606\n",
            " 0.73283283 0.7576666  0.77343763 0.71707677]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.31146492 -0.3073374  -0.29021785 -0.30304237 -0.30689566 -0.35359318\n",
            " -0.29765797 -0.31630841 -0.28878625 -0.30985838 -0.32957444 -0.31658263\n",
            " -0.2987398  -0.2555297  -0.31889737 -0.34561203 -0.32166905 -0.31620912\n",
            " -0.36112505 -0.32204257 -0.34768407 -0.32750263 -0.25955792 -0.35107232\n",
            " -0.34052573 -0.32715287 -0.33377783 -0.32329935 -0.31603418 -0.31416095\n",
            " -0.31873021 -0.34121041 -0.31426    -0.32186752 -0.30985838 -0.29379703\n",
            " -0.31889749 -0.30985838 -0.28008936 -0.32016181 -0.30437468 -0.29369797\n",
            " -0.27865765 -0.34255037 -0.3587109  -0.3082282  -0.32527941 -0.29434548\n",
            " -0.32572104 -0.30904323  0.16461853  0.27988486  0.15860157  0.22688861\n",
            "  0.18495881  0.08346734  0.37050835  0.13248737  0.19264951  0.12410446\n",
            "  0.25174614  0.24080239  0.2020859   0.28554338  0.25687973  0.22540489\n",
            "  0.2278787   0.07261557  0.04331901  0.29555659  0.17421375  0.29952539\n",
            "  0.07494538  0.28132412  0.19212481  0.16243144  0.29387441  0.29117849\n",
            "  0.20808676  0.18645019  0.13913598  0.09834026  0.20334256  0.28031051\n",
            "  0.25142463  0.1100307   0.20200271  0.23244796  0.30301293  0.20692939\n",
            "  0.18444153  0.22138408  0.27988486  0.16210509  0.17314802  0.220394\n",
            "  0.26716717  0.2423334   0.22656237  0.28292323]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575]\n",
            "Epoch - 13 starting.....\n",
            "Predicted Output from the Adaline Model in the 13 th step is as follows: [0.30136606 0.29866217 0.28098824 0.29483197 0.29668474 0.34351065\n",
            " 0.28857971 0.30689851 0.28096305 0.30110942 0.31896506 0.30774964\n",
            " 0.29001932 0.24643512 0.30609778 0.33332207 0.31026555 0.30627884\n",
            " 0.35073935 0.31173636 0.33844136 0.31760038 0.24851934 0.3429407\n",
            " 0.33268346 0.31901479 0.32503533 0.31340741 0.30604739 0.30592207\n",
            " 0.31060339 0.33164436 0.30278713 0.30962761 0.30110942 0.28386719\n",
            " 0.30797509 0.30110942 0.27170052 0.31062859 0.29423749 0.28700212\n",
            " 0.26979802 0.33390963 0.34989423 0.29984487 0.31513486 0.28556944\n",
            " 0.31523498 0.29953849 0.84334184 0.72612087 0.84807383 0.77951234\n",
            " 0.82229488 0.92490312 0.63475951 0.87499201 0.8148602  0.88237004\n",
            " 0.75238791 0.76512387 0.80363851 0.7208948  0.74973348 0.7800187\n",
            " 0.77770997 0.93424724 0.96719757 0.71037491 0.83191417 0.7059997\n",
            " 0.9339342  0.72323593 0.81367723 0.84347436 0.71024333 0.71292202\n",
            " 0.79893199 0.81892877 0.86796356 0.90694802 0.80384476 0.72416891\n",
            " 0.75525486 0.89690237 0.80423272 0.77302864 0.70088067 0.79810606\n",
            " 0.82200677 0.78299778 0.72612087 0.84480665 0.83332832 0.78480016\n",
            " 0.73836247 0.76260169 0.77896733 0.72208442]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.30136606 -0.29866217 -0.28098824 -0.29483197 -0.29668474 -0.34351065\n",
            " -0.28857971 -0.30689851 -0.28096305 -0.30110942 -0.31896506 -0.30774964\n",
            " -0.29001932 -0.24643512 -0.30609778 -0.33332207 -0.31026555 -0.30627884\n",
            " -0.35073935 -0.31173636 -0.33844136 -0.31760038 -0.24851934 -0.3429407\n",
            " -0.33268346 -0.31901479 -0.32503533 -0.31340741 -0.30604739 -0.30592207\n",
            " -0.31060339 -0.33164436 -0.30278713 -0.30962761 -0.30110942 -0.28386719\n",
            " -0.30797509 -0.30110942 -0.27170052 -0.31062859 -0.29423749 -0.28700212\n",
            " -0.26979802 -0.33390963 -0.34989423 -0.29984487 -0.31513486 -0.28556944\n",
            " -0.31523498 -0.29953849  0.15665816  0.27387913  0.15192617  0.22048766\n",
            "  0.17770512  0.07509688  0.36524049  0.12500799  0.1851398   0.11762996\n",
            "  0.24761209  0.23487613  0.19636149  0.2791052   0.25026652  0.2199813\n",
            "  0.22229003  0.06575276  0.03280243  0.28962509  0.16808583  0.2940003\n",
            "  0.0660658   0.27676407  0.18632277  0.15652564  0.28975667  0.28707798\n",
            "  0.20106801  0.18107123  0.13203644  0.09305198  0.19615524  0.27583109\n",
            "  0.24474514  0.10309763  0.19576728  0.22697136  0.29911933  0.20189394\n",
            "  0.17799323  0.21700222  0.27387913  0.15519335  0.16667168  0.21519984\n",
            "  0.26163753  0.23739831  0.22103267  0.27791558]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795]\n",
            "Epoch - 14 starting.....\n",
            "Predicted Output from the Adaline Model in the 14 th step is as follows: [0.29157794 0.29025326 0.27204264 0.28687396 0.28678826 0.33373863\n",
            " 0.27978125 0.297778   0.2733803  0.292629   0.30868204 0.29918838\n",
            " 0.28156655 0.23762056 0.2936923  0.32141122 0.29921359 0.29665422\n",
            " 0.34067291 0.30174775 0.32948228 0.30800327 0.23782146 0.33505903\n",
            " 0.32508215 0.31112622 0.31656181 0.30381964 0.29636762 0.29793642\n",
            " 0.3027261  0.32237231 0.29166791 0.29776501 0.292629   0.2742427\n",
            " 0.29738844 0.292629   0.2635698  0.30138844 0.28441252 0.28051121\n",
            " 0.26121132 0.32553512 0.34134906 0.2917191  0.30530273 0.27706346\n",
            " 0.3050716  0.29032598 0.851054   0.73193825 0.85453888 0.78571199\n",
            " 0.82932125 0.9330099  0.63986266 0.88223521 0.82213324 0.8886415\n",
            " 0.7563914  0.77086341 0.80918252 0.72713131 0.75614039 0.78527231\n",
            " 0.78312237 0.94089395 0.97738364 0.71611897 0.83784955 0.71135188\n",
            " 0.94253381 0.72765166 0.81929688 0.84919327 0.71423072 0.71689305\n",
            " 0.8057305  0.82413668 0.87483865 0.9120685  0.81080678 0.7285061\n",
            " 0.76172373 0.9036166  0.81027344 0.77833269 0.70465135 0.80298246\n",
            " 0.82825293 0.78724124 0.73193825 0.85150163 0.83960198 0.78983086\n",
            " 0.74371768 0.76738115 0.78432421 0.72693469]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.29157794 -0.29025326 -0.27204264 -0.28687396 -0.28678826 -0.33373863\n",
            " -0.27978125 -0.297778   -0.2733803  -0.292629   -0.30868204 -0.29918838\n",
            " -0.28156655 -0.23762056 -0.2936923  -0.32141122 -0.29921359 -0.29665422\n",
            " -0.34067291 -0.30174775 -0.32948228 -0.30800327 -0.23782146 -0.33505903\n",
            " -0.32508215 -0.31112622 -0.31656181 -0.30381964 -0.29636762 -0.29793642\n",
            " -0.3027261  -0.32237231 -0.29166791 -0.29776501 -0.292629   -0.2742427\n",
            " -0.29738844 -0.292629   -0.2635698  -0.30138844 -0.28441252 -0.28051121\n",
            " -0.26121132 -0.32553512 -0.34134906 -0.2917191  -0.30530273 -0.27706346\n",
            " -0.3050716  -0.29032598  0.148946    0.26806175  0.14546112  0.21428801\n",
            "  0.17067875  0.0669901   0.36013734  0.11776479  0.17786676  0.1113585\n",
            "  0.2436086   0.22913659  0.19081748  0.27286869  0.24385961  0.21472769\n",
            "  0.21687763  0.05910605  0.02261636  0.28388103  0.16215045  0.28864812\n",
            "  0.05746619  0.27234834  0.18070312  0.15080673  0.28576928  0.28310695\n",
            "  0.1942695   0.17586332  0.12516135  0.0879315   0.18919322  0.2714939\n",
            "  0.23827627  0.0963834   0.18972656  0.22166731  0.29534865  0.19701754\n",
            "  0.17174707  0.21275876  0.26806175  0.14849837  0.16039802  0.21016914\n",
            "  0.25628232  0.23261885  0.21567579  0.27306531]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497]\n",
            "Epoch - 15 starting.....\n",
            "Predicted Output from the Adaline Model in the 15 th step is as follows: [0.28209213 0.28210358 0.26337336 0.27916164 0.27719768 0.32426881\n",
            " 0.27125505 0.28893909 0.26603163 0.28440997 0.29871654 0.2908916\n",
            " 0.27337431 0.22907836 0.28167005 0.30986913 0.28850355 0.287327\n",
            " 0.33091719 0.29206816 0.32079932 0.29870308 0.22745482 0.32742078\n",
            " 0.31771555 0.30348061 0.30835015 0.29452784 0.28698658 0.29019731\n",
            " 0.29509176 0.31338643 0.28089267 0.28626937 0.28440997 0.26491525\n",
            " 0.28712841 0.28440997 0.25569026 0.29243349 0.27489128 0.27421989\n",
            " 0.25289016 0.31741984 0.33306829 0.28384405 0.2957746  0.26882028\n",
            " 0.29522214 0.28139783 0.85852753 0.73757477 0.86080208 0.79171837\n",
            " 0.83612923 0.94086328 0.64480764 0.88925157 0.8291788  0.89471829\n",
            " 0.76027019 0.7764238  0.81455362 0.73317403 0.76234908 0.79036303\n",
            " 0.7883658  0.94733346 0.98725156 0.72168302 0.84360029 0.71653816\n",
            " 0.95086422 0.73192927 0.8247417  0.85473307 0.71809351 0.72074032\n",
            " 0.81231743 0.8291808  0.88149826 0.91702857 0.81755231 0.73270723\n",
            " 0.76799023 0.91012085 0.81612735 0.78347135 0.70830461 0.80770665\n",
            " 0.8343051  0.79135246 0.73757477 0.85798852 0.84568118 0.79470502\n",
            " 0.74890556 0.77201161 0.78951545 0.73163415]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.28209213 -0.28210358 -0.26337336 -0.27916164 -0.27719768 -0.32426881\n",
            " -0.27125505 -0.28893909 -0.26603163 -0.28440997 -0.29871654 -0.2908916\n",
            " -0.27337431 -0.22907836 -0.28167005 -0.30986913 -0.28850355 -0.287327\n",
            " -0.33091719 -0.29206816 -0.32079932 -0.29870308 -0.22745482 -0.32742078\n",
            " -0.31771555 -0.30348061 -0.30835015 -0.29452784 -0.28698658 -0.29019731\n",
            " -0.29509176 -0.31338643 -0.28089267 -0.28626937 -0.28440997 -0.26491525\n",
            " -0.28712841 -0.28440997 -0.25569026 -0.29243349 -0.27489128 -0.27421989\n",
            " -0.25289016 -0.31741984 -0.33306829 -0.28384405 -0.2957746  -0.26882028\n",
            " -0.29522214 -0.28139783  0.14147247  0.26242523  0.13919792  0.20828163\n",
            "  0.16387077  0.05913672  0.35519236  0.11074843  0.1708212   0.10528171\n",
            "  0.23972981  0.2235762   0.18544638  0.26682597  0.23765092  0.20963697\n",
            "  0.2116342   0.05266654  0.01274844  0.27831698  0.15639971  0.28346184\n",
            "  0.04913578  0.26807073  0.1752583   0.14526693  0.28190649  0.27925968\n",
            "  0.18768257  0.1708192   0.11850174  0.08297143  0.18244769  0.26729277\n",
            "  0.23200977  0.08987915  0.18387265  0.21652865  0.29169539  0.19229335\n",
            "  0.1656949   0.20864754  0.26242523  0.14201148  0.15431882  0.20529498\n",
            "  0.25109444  0.22798839  0.21048455  0.26836585]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894]\n",
            "Epoch - 16 starting.....\n",
            "Predicted Output from the Adaline Model in the 16 th step is as follows: [0.27289973 0.27420552 0.25497228 0.27168783 0.26790398 0.31509235\n",
            " 0.2629931  0.28037353 0.25891018 0.27644466 0.28905922 0.28285158\n",
            " 0.26543496 0.22080048 0.27001967 0.2986849  0.27812535 0.27828844\n",
            " 0.32146308 0.28268849 0.31238442 0.2896911  0.21740959 0.32001891\n",
            " 0.31057683 0.29607087 0.3003927  0.28552332 0.27789547 0.28269753\n",
            " 0.28769328 0.30467834 0.27045123 0.27512983 0.27644466 0.25587607\n",
            " 0.27718537 0.27644466 0.24805454 0.28375538 0.26566484 0.26812238\n",
            " 0.24482674 0.30955622 0.32504421 0.27621239 0.28654153 0.26083218\n",
            " 0.28567738 0.27274568 0.86577055 0.74303668 0.86687043 0.79753816\n",
            " 0.8427263  0.94847192 0.64959993 0.89604889 0.83600465 0.90060723\n",
            " 0.76402883 0.78181127 0.81975788 0.73902959 0.76836634 0.79529662\n",
            " 0.79344621 0.95357304 0.99681203 0.72707327 0.84917286 0.7215643\n",
            " 0.9589346  0.73607371 0.83001784 0.8601001  0.72183621 0.72446832\n",
            " 0.81870004 0.83406697 0.88794985 0.92183406 0.82408875 0.73677718\n",
            " 0.77406132 0.91642243 0.82180094 0.78845047 0.71184472 0.81228408\n",
            " 0.84017002 0.79533625 0.74303668 0.86427451 0.85157269 0.79942821\n",
            " 0.75393196 0.77649838 0.79454688 0.73618813]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.27289973 -0.27420552 -0.25497228 -0.27168783 -0.26790398 -0.31509235\n",
            " -0.2629931  -0.28037353 -0.25891018 -0.27644466 -0.28905922 -0.28285158\n",
            " -0.26543496 -0.22080048 -0.27001967 -0.2986849  -0.27812535 -0.27828844\n",
            " -0.32146308 -0.28268849 -0.31238442 -0.2896911  -0.21740959 -0.32001891\n",
            " -0.31057683 -0.29607087 -0.3003927  -0.28552332 -0.27789547 -0.28269753\n",
            " -0.28769328 -0.30467834 -0.27045123 -0.27512983 -0.27644466 -0.25587607\n",
            " -0.27718537 -0.27644466 -0.24805454 -0.28375538 -0.26566484 -0.26812238\n",
            " -0.24482674 -0.30955622 -0.32504421 -0.27621239 -0.28654153 -0.26083218\n",
            " -0.28567738 -0.27274568  0.13422945  0.25696332  0.13312957  0.20246184\n",
            "  0.1572737   0.05152808  0.35040007  0.10395111  0.16399535  0.09939277\n",
            "  0.23597117  0.21818873  0.18024212  0.26097041  0.23163366  0.20470338\n",
            "  0.20655379  0.04642696  0.00318797  0.27292673  0.15082714  0.2784357\n",
            "  0.0410654   0.26392629  0.16998216  0.1398999   0.27816379  0.27553168\n",
            "  0.18129996  0.16593303  0.11205015  0.07816594  0.17591125  0.26322282\n",
            "  0.22593868  0.08357757  0.17819906  0.21154953  0.28815528  0.18771592\n",
            "  0.15982998  0.20466375  0.25696332  0.13572549  0.14842731  0.20057179\n",
            "  0.24606804  0.22350162  0.20545312  0.26381187]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785]\n",
            "Epoch - 17 starting.....\n",
            "Predicted Output from the Adaline Model in the 17 th step is as follows: [0.26399183 0.26655147 0.24683126 0.26444531 0.25889816 0.30620036\n",
            " 0.25498739 0.27207302 0.25200909 0.2687254  0.27970074 0.27506054\n",
            " 0.25774085 0.21277887 0.25872985 0.28784766 0.26806889 0.26952978\n",
            " 0.31230144 0.27359965 0.30422946 0.28095859 0.20767598 0.31284626\n",
            " 0.30365914 0.28888988 0.29268177 0.27679738 0.26908551 0.27542986\n",
            " 0.28052353 0.29623961 0.26033345 0.26433555 0.2687254  0.24711642\n",
            " 0.26754967 0.2687254  0.24065522 0.2753457  0.25672423 0.26221283\n",
            " 0.23701322 0.30193666 0.31726906 0.26881674 0.27759457 0.25309145\n",
            " 0.27642806 0.26436115 0.87279049 0.74832964 0.87275026 0.80317742\n",
            " 0.84911928 0.95584372 0.65424446 0.90263426 0.84261786 0.90631445\n",
            " 0.76767133 0.78703144 0.82480077 0.74470403 0.77419835 0.80007821\n",
            " 0.79836891 0.95961922 1.00607487 0.73229536 0.85457306 0.7264355\n",
            " 0.96675332 0.74008935 0.83513083 0.86529999 0.72546281 0.728081\n",
            " 0.82488492 0.83880037 0.89420014 0.92649009 0.83042286 0.74072026\n",
            " 0.7799433  0.92252794 0.82730008 0.79327524 0.71527546 0.81671958\n",
            " 0.84585378 0.79919686 0.74832964 0.87036612 0.85728259 0.80400537\n",
            " 0.75880215 0.78084619 0.79942373 0.74060138]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.26399183 -0.26655147 -0.24683126 -0.26444531 -0.25889816 -0.30620036\n",
            " -0.25498739 -0.27207302 -0.25200909 -0.2687254  -0.27970074 -0.27506054\n",
            " -0.25774085 -0.21277887 -0.25872985 -0.28784766 -0.26806889 -0.26952978\n",
            " -0.31230144 -0.27359965 -0.30422946 -0.28095859 -0.20767598 -0.31284626\n",
            " -0.30365914 -0.28888988 -0.29268177 -0.27679738 -0.26908551 -0.27542986\n",
            " -0.28052353 -0.29623961 -0.26033345 -0.26433555 -0.2687254  -0.24711642\n",
            " -0.26754967 -0.2687254  -0.24065522 -0.2753457  -0.25672423 -0.26221283\n",
            " -0.23701322 -0.30193666 -0.31726906 -0.26881674 -0.27759457 -0.25309145\n",
            " -0.27642806 -0.26436115  0.12720951  0.25167036  0.12724974  0.19682258\n",
            "  0.15088072  0.04415628  0.34575554  0.09736574  0.15738214  0.09368555\n",
            "  0.23232867  0.21296856  0.17519923  0.25529597  0.22580165  0.19992179\n",
            "  0.20163109  0.04038078 -0.00607487  0.26770464  0.14542694  0.2735645\n",
            "  0.03324668  0.25991065  0.16486917  0.13470001  0.27453719  0.271919\n",
            "  0.17511508  0.16119963  0.10579986  0.07350991  0.16957714  0.25927974\n",
            "  0.2200567   0.07747206  0.17269992  0.20672476  0.28472454  0.18328042\n",
            "  0.15414622  0.20080314  0.25167036  0.12963388  0.14271741  0.19599463\n",
            "  0.24119785  0.21915381  0.20057627  0.25939862]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607]\n",
            "Epoch - 18 starting.....\n",
            "Predicted Output from the Adaline Model in the 18 th step is as follows: [0.25535971 0.25913394 0.23894229 0.25742698 0.25017136 0.29758409\n",
            " 0.24723005 0.26402943 0.24532157 0.26124463 0.27063189 0.26751082\n",
            " 0.25028445 0.20500566 0.24778949 0.27734674 0.25832428 0.26104241\n",
            " 0.3034233  0.26479268 0.29632648 0.27249695 0.19824441 0.30589581\n",
            " 0.29695568 0.28193063 0.2852098  0.26834144 0.26054805 0.26838716\n",
            " 0.2735755  0.28806199 0.25052938 0.25387592 0.26124463 0.23862769\n",
            " 0.25821189 0.26124463 0.23348506 0.26719622 0.24806067 0.25648547\n",
            " 0.22944194 0.29455365 0.30973521 0.26164986 0.26892493 0.24559046\n",
            " 0.26746511 0.25623604 0.87959436 0.75345897 0.87844754 0.80864184\n",
            " 0.85531458 0.96298614 0.6587459  0.90901437 0.84902513 0.91184569\n",
            " 0.77120137 0.79208959 0.82968737 0.75020306 0.77985094 0.80471261\n",
            " 0.8031389  0.9654781  1.01504944 0.73735457 0.85980635 0.73115664\n",
            " 0.97432829 0.74398028 0.84008581 0.87033804 0.72897699 0.73158203\n",
            " 0.8308783  0.84338584 0.90025551 0.9310014  0.83656101 0.74454051\n",
            " 0.78564213 0.92844357 0.83263028 0.79795055 0.7186003  0.82101764\n",
            " 0.85136209 0.80293819 0.75345897 0.87626948 0.86281663 0.80844113\n",
            " 0.76352106 0.78505945 0.80415088 0.74487837]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.25535971 -0.25913394 -0.23894229 -0.25742698 -0.25017136 -0.29758409\n",
            " -0.24723005 -0.26402943 -0.24532157 -0.26124463 -0.27063189 -0.26751082\n",
            " -0.25028445 -0.20500566 -0.24778949 -0.27734674 -0.25832428 -0.26104241\n",
            " -0.3034233  -0.26479268 -0.29632648 -0.27249695 -0.19824441 -0.30589581\n",
            " -0.29695568 -0.28193063 -0.2852098  -0.26834144 -0.26054805 -0.26838716\n",
            " -0.2735755  -0.28806199 -0.25052938 -0.25387592 -0.26124463 -0.23862769\n",
            " -0.25821189 -0.26124463 -0.23348506 -0.26719622 -0.24806067 -0.25648547\n",
            " -0.22944194 -0.29455365 -0.30973521 -0.26164986 -0.26892493 -0.24559046\n",
            " -0.26746511 -0.25623604  0.12040564  0.24654103  0.12155246  0.19135816\n",
            "  0.14468542  0.03701386  0.3412541   0.09098563  0.15097487  0.08815431\n",
            "  0.22879863  0.20791041  0.17031263  0.24979694  0.22014906  0.19528739\n",
            "  0.1968611   0.0345219  -0.01504944  0.26264543  0.14019365  0.26884336\n",
            "  0.02567171  0.25601972  0.15991419  0.12966196  0.27102301  0.26841797\n",
            "  0.1691217   0.15661416  0.09974449  0.0689986   0.16343899  0.25545949\n",
            "  0.21435787  0.07155643  0.16736972  0.20204945  0.2813997   0.17898236\n",
            "  0.14863791  0.19706181  0.24654103  0.12373052  0.13718337  0.19155887\n",
            "  0.23647894  0.21494055  0.19584912  0.25512163]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743]\n",
            "Epoch - 19 starting.....\n",
            "Predicted Output from the Adaline Model in the 19 th step is as follows: [0.24699483 0.25194562 0.23129761 0.25062591 0.24171497 0.28923505\n",
            " 0.23971341 0.25623483 0.23884105 0.25399498 0.26184375 0.26019498\n",
            " 0.2430584  0.19747318 0.2371878  0.26717175 0.24888189 0.25281797\n",
            " 0.2948199  0.2562589  0.28866769 0.26429783 0.18910553 0.2991607\n",
            " 0.29045985 0.27518627 0.27796941 0.26014719 0.25227468 0.26156249\n",
            " 0.26684234 0.2801374  0.24102933 0.2437406  0.25399498 0.23040153\n",
            " 0.24916281 0.25399498 0.22653698 0.2592989  0.23966561 0.25093469\n",
            " 0.2221054  0.28739991 0.30243521 0.25470469 0.26052405 0.23832184\n",
            " 0.25877968 0.24836233 0.88618889 0.75842979 0.88396795 0.81393687\n",
            " 0.86131838 0.96990633 0.6631087  0.91519561 0.85523288 0.91720645\n",
            " 0.77462249 0.79699079 0.83442258 0.75553214 0.78532972 0.80920443\n",
            " 0.80776094 0.97115554 1.0237447  0.74225599 0.86487794 0.73573242\n",
            " 0.98166712 0.74775041 0.84488773 0.87521931 0.73238227 0.73497491\n",
            " 0.83668616 0.84782801 0.90612202 0.93537253 0.8425093  0.74824178\n",
            " 0.79116352 0.93417523 0.8377968  0.80248108 0.72182255 0.82518257\n",
            " 0.85670044 0.80656398 0.75842979 0.88199045 0.8681803  0.81273992\n",
            " 0.76809342 0.78914235 0.80873301 0.74902336]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.24699483 -0.25194562 -0.23129761 -0.25062591 -0.24171497 -0.28923505\n",
            " -0.23971341 -0.25623483 -0.23884105 -0.25399498 -0.26184375 -0.26019498\n",
            " -0.2430584  -0.19747318 -0.2371878  -0.26717175 -0.24888189 -0.25281797\n",
            " -0.2948199  -0.2562589  -0.28866769 -0.26429783 -0.18910553 -0.2991607\n",
            " -0.29045985 -0.27518627 -0.27796941 -0.26014719 -0.25227468 -0.26156249\n",
            " -0.26684234 -0.2801374  -0.24102933 -0.2437406  -0.25399498 -0.23040153\n",
            " -0.24916281 -0.25399498 -0.22653698 -0.2592989  -0.23966561 -0.25093469\n",
            " -0.2221054  -0.28739991 -0.30243521 -0.25470469 -0.26052405 -0.23832184\n",
            " -0.25877968 -0.24836233  0.11381111  0.24157021  0.11603205  0.18606313\n",
            "  0.13868162  0.03009367  0.3368913   0.08480439  0.14476712  0.08279355\n",
            "  0.22537751  0.20300921  0.16557742  0.24446786  0.21467028  0.19079557\n",
            "  0.19223906  0.02884446 -0.0237447   0.25774401  0.13512206  0.26426758\n",
            "  0.01833288  0.25224959  0.15511227  0.12478069  0.26761773  0.26502509\n",
            "  0.16331384  0.15217199  0.09387798  0.06462747  0.1574907   0.25175822\n",
            "  0.20883648  0.06582477  0.1622032   0.19751892  0.27817745  0.17481743\n",
            "  0.14329956  0.19343602  0.24157021  0.11800955  0.1318197   0.18726008\n",
            "  0.23190658  0.21085765  0.19126699  0.25097664]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667]\n",
            "Epoch - 20 starting.....\n",
            "Predicted Output from the Adaline Model in the 20 th step is as follows: [0.23888893 0.24497942 0.22388966 0.2440354  0.23352062 0.28114496\n",
            " 0.23243002 0.24868152 0.23256112 0.24696931 0.25332763 0.25310579\n",
            " 0.2360556  0.19017399 0.22691431 0.25731261 0.23973237 0.24484832\n",
            " 0.28648275 0.24798985 0.28124555 0.25635311 0.18025029 0.29263428\n",
            " 0.28416524 0.26865015 0.27095344 0.25220651 0.24425724 0.25494911\n",
            " 0.26031741 0.27245803 0.23182389 0.23391956 0.24696931 0.22242982\n",
            " 0.24039352 0.24696931 0.2198041  0.25164595 0.23153073 0.24555503\n",
            " 0.21499636 0.28046834 0.29536183 0.24797438 0.25238361 0.23127838\n",
            " 0.2503632  0.24073224 0.89258059 0.763247   0.88931699 0.81906778\n",
            " 0.86713662 0.97661119 0.66733718 0.92118416 0.8612473  0.92240203\n",
            " 0.77793807 0.8017399  0.83901109 0.76069655 0.79064007 0.81355809\n",
            " 0.81223963 0.97665718 1.03216933 0.74700453 0.86979285 0.74016735\n",
            " 0.98877713 0.75140349 0.84954134 0.87994866 0.73568204 0.738263\n",
            " 0.84231425 0.85213134 0.91180555 0.93960783 0.84827364 0.75182775\n",
            " 0.79651298 0.93972866 0.84280474 0.80687132 0.72494542 0.82921851\n",
            " 0.8618741  0.81007784 0.763247   0.88753471 0.87337889 0.81690599\n",
            " 0.77252377 0.79309896 0.81317463 0.75304043]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.23888893 -0.24497942 -0.22388966 -0.2440354  -0.23352062 -0.28114496\n",
            " -0.23243002 -0.24868152 -0.23256112 -0.24696931 -0.25332763 -0.25310579\n",
            " -0.2360556  -0.19017399 -0.22691431 -0.25731261 -0.23973237 -0.24484832\n",
            " -0.28648275 -0.24798985 -0.28124555 -0.25635311 -0.18025029 -0.29263428\n",
            " -0.28416524 -0.26865015 -0.27095344 -0.25220651 -0.24425724 -0.25494911\n",
            " -0.26031741 -0.27245803 -0.23182389 -0.23391956 -0.24696931 -0.22242982\n",
            " -0.24039352 -0.24696931 -0.2198041  -0.25164595 -0.23153073 -0.24555503\n",
            " -0.21499636 -0.28046834 -0.29536183 -0.24797438 -0.25238361 -0.23127838\n",
            " -0.2503632  -0.24073224  0.10741941  0.236753    0.11068301  0.18093222\n",
            "  0.13286338  0.02338881  0.33266282  0.07881584  0.1387527   0.07759797\n",
            "  0.22206193  0.1982601   0.16098891  0.23930345  0.20935993  0.18644191\n",
            "  0.18776037  0.02334282 -0.03216933  0.25299547  0.13020715  0.25983265\n",
            "  0.01122287  0.24859651  0.15045866  0.12005134  0.26431796  0.261737\n",
            "  0.15768575  0.14786866  0.08819445  0.06039217  0.15172636  0.24817225\n",
            "  0.20348702  0.06027134  0.15719526  0.19312868  0.27505458  0.17078149\n",
            "  0.1381259   0.18992216  0.236753    0.11246529  0.12662111  0.18309401\n",
            "  0.22747623  0.20690104  0.18682537  0.24695957]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002]\n",
            "Epoch - 21 starting.....\n",
            "Predicted Output from the Adaline Model in the 21 th step is as follows: [0.231034   0.23822848 0.21671111 0.23764891 0.22558021 0.27330581\n",
            " 0.22537266 0.24136201 0.22647558 0.24016069 0.24507511 0.24623624\n",
            " 0.22926913 0.18310085 0.21695885 0.24775954 0.23086666 0.23712557\n",
            " 0.2784036  0.23997733 0.27405272 0.2486549  0.17166992 0.28631009\n",
            " 0.2780656  0.26231584 0.26415494 0.24451157 0.23648779 0.24854047\n",
            " 0.25399426 0.26501628 0.22290395 0.22440306 0.24016069 0.21470466\n",
            " 0.23189534 0.24016069 0.21327978 0.2442298  0.22364799 0.24034119\n",
            " 0.20810776 0.27375206 0.28850805 0.24145226 0.24449555 0.22445311\n",
            " 0.24220733 0.23333823 0.89877575 0.76791538 0.89449997 0.82403965\n",
            " 0.87277506 0.9831074  0.67143549 0.926986   0.86707439 0.92743755\n",
            " 0.78115138 0.80634165 0.84345747 0.7657014  0.79578721 0.81777788\n",
            " 0.81657942 0.98198847 1.04033172 0.75160493 0.87455595 0.7444658\n",
            " 0.99566542 0.75494315 0.85405124 0.88453082 0.73887957 0.74144956\n",
            " 0.84776815 0.85630012 0.91731178 0.94371153 0.85385971 0.75530201\n",
            " 0.80169584 0.94510938 0.84765902 0.81112563 0.72797199 0.83312945\n",
            " 0.86688817 0.81348322 0.76791538 0.89290774 0.87841751 0.82094346\n",
            " 0.77681652 0.79693319 0.81748009 0.75693357]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.231034   -0.23822848 -0.21671111 -0.23764891 -0.22558021 -0.27330581\n",
            " -0.22537266 -0.24136201 -0.22647558 -0.24016069 -0.24507511 -0.24623624\n",
            " -0.22926913 -0.18310085 -0.21695885 -0.24775954 -0.23086666 -0.23712557\n",
            " -0.2784036  -0.23997733 -0.27405272 -0.2486549  -0.17166992 -0.28631009\n",
            " -0.2780656  -0.26231584 -0.26415494 -0.24451157 -0.23648779 -0.24854047\n",
            " -0.25399426 -0.26501628 -0.22290395 -0.22440306 -0.24016069 -0.21470466\n",
            " -0.23189534 -0.24016069 -0.21327978 -0.2442298  -0.22364799 -0.24034119\n",
            " -0.20810776 -0.27375206 -0.28850805 -0.24145226 -0.24449555 -0.22445311\n",
            " -0.24220733 -0.23333823  0.10122425  0.23208462  0.10550003  0.17596035\n",
            "  0.12722494  0.0168926   0.32856451  0.073014    0.13292561  0.07256245\n",
            "  0.21884862  0.19365835  0.15654253  0.2342986   0.20421279  0.18222212\n",
            "  0.18342058  0.01801153 -0.04033172  0.24839507  0.12544405  0.2555342\n",
            "  0.00433458  0.24505685  0.14594876  0.11546918  0.26112043  0.25855044\n",
            "  0.15223185  0.14369988  0.08268822  0.05628847  0.14614029  0.24469799\n",
            "  0.19830416  0.05489062  0.15234098  0.18887437  0.27202801  0.16687055\n",
            "  0.13311183  0.18651678  0.23208462  0.10709226  0.12158249  0.17905654\n",
            "  0.22318348  0.20306681  0.18251991  0.24306643]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134]\n",
            "Epoch - 22 starting.....\n",
            "Predicted Output from the Adaline Model in the 22 th step is as follows: [0.22342226 0.23168612 0.20975485 0.23146014 0.21788586 0.26570983\n",
            " 0.21853434 0.23426909 0.22057839 0.2335624  0.23707803 0.23957951\n",
            " 0.22269229 0.17624677 0.20731157 0.23850306 0.22227596 0.22964207\n",
            " 0.27057446 0.2322134  0.26708211 0.24119559 0.1633559  0.28018186\n",
            " 0.27215492 0.25617708 0.25756718 0.23705475 0.22895866 0.24233025\n",
            " 0.24786665 0.25780479 0.21426066 0.21518169 0.2335624  0.20721844\n",
            " 0.22365988 0.2335624  0.20695754 0.23704311 0.21600958 0.23528804\n",
            " 0.20143278 0.26724442 0.28186708 0.23513191 0.23685206 0.21783929\n",
            " 0.23430401 0.226173   0.90478044 0.77243954 0.89952204 0.82885742\n",
            " 0.87823926 0.98940143 0.67540768 0.93260691 0.87271996 0.93231796\n",
            " 0.7842656  0.81080061 0.84776611 0.77055162 0.80077621 0.82186795\n",
            " 0.82078461 0.98715469 1.04823999 0.75606178 0.87917193 0.74863199\n",
            " 1.00233887 0.7583729  0.85842188 0.88897034 0.74197803 0.74453772\n",
            " 0.85305325 0.86033855 0.92264618 0.9476877  0.85927306 0.75866803\n",
            " 0.80671727 0.95032273 0.85236438 0.81524821 0.73090523 0.83691928\n",
            " 0.87174761 0.8167835  0.77243954 0.89811484 0.88330112 0.8248563\n",
            " 0.78097594 0.80064883 0.82165361 0.76070661]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.22342226 -0.23168612 -0.20975485 -0.23146014 -0.21788586 -0.26570983\n",
            " -0.21853434 -0.23426909 -0.22057839 -0.2335624  -0.23707803 -0.23957951\n",
            " -0.22269229 -0.17624677 -0.20731157 -0.23850306 -0.22227596 -0.22964207\n",
            " -0.27057446 -0.2322134  -0.26708211 -0.24119559 -0.1633559  -0.28018186\n",
            " -0.27215492 -0.25617708 -0.25756718 -0.23705475 -0.22895866 -0.24233025\n",
            " -0.24786665 -0.25780479 -0.21426066 -0.21518169 -0.2335624  -0.20721844\n",
            " -0.22365988 -0.2335624  -0.20695754 -0.23704311 -0.21600958 -0.23528804\n",
            " -0.20143278 -0.26724442 -0.28186708 -0.23513191 -0.23685206 -0.21783929\n",
            " -0.23430401 -0.226173    0.09521956  0.22756046  0.10047796  0.17114258\n",
            "  0.12176074  0.01059857  0.32459232  0.06739309  0.12728004  0.06768204\n",
            "  0.2157344   0.18919939  0.15223389  0.22944838  0.19922379  0.17813205\n",
            "  0.17921539  0.01284531 -0.04823999  0.24393822  0.12082807  0.25136801\n",
            " -0.00233887  0.2416271   0.14157812  0.11102966  0.25802197  0.25546228\n",
            "  0.14694675  0.13966145  0.07735382  0.0523123   0.14072694  0.24133197\n",
            "  0.19328273  0.04967727  0.14763562  0.18475179  0.26909477  0.16308072\n",
            "  0.12825239  0.1832165   0.22756046  0.10188516  0.11669888  0.1751437\n",
            "  0.21902406  0.19935117  0.17834639  0.23929339]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094]\n",
            "Epoch - 23 starting.....\n",
            "Predicted Output from the Adaline Model in the 23 th step is as follows: [0.21604619 0.22534589 0.203014   0.22546296 0.21042996 0.25834948\n",
            " 0.21190827 0.22739572 0.21486374 0.22716791 0.22932848 0.23312903\n",
            " 0.21631859 0.16960498 0.19796294 0.22953398 0.21395176 0.22239042\n",
            " 0.2629876  0.22469036 0.26032683 0.23396776 0.15529998 0.27424352\n",
            " 0.26642732 0.25022781 0.25118363 0.22982868 0.22166241 0.23631229\n",
            " 0.24192852 0.25081645 0.20588545 0.20624628 0.22716791 0.19996376\n",
            " 0.21567901 0.22716791 0.20083114 0.23007878 0.20860793 0.23039059\n",
            " 0.19496481 0.26093893 0.27543232 0.22900706 0.22944555 0.21143037\n",
            " 0.22664541 0.21922945 0.91060057 0.77682394 0.90438819 0.83352585\n",
            " 0.88353462 0.99549953 0.67925764 0.9380525  0.87818962 0.93704808\n",
            " 0.7872838  0.81512118 0.85194128 0.77525202 0.80561196 0.82583231\n",
            " 0.82485938 0.99216094 1.05590202 0.76037951 0.88364535 0.75267003\n",
            " 1.00880412 0.76169616 0.86265758 0.89327165 0.7449805  0.74753054\n",
            " 0.85817479 0.86425064 0.9278141  0.9515403  0.86451902 0.76192915\n",
            " 0.81158227 0.95537391 0.85692545 0.81924315 0.73374804 0.84059175\n",
            " 0.87645719 0.81998192 0.77682394 0.90316115 0.88803453 0.82864839\n",
            " 0.78500616 0.80424956 0.82569928 0.76436327]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.21604619 -0.22534589 -0.203014   -0.22546296 -0.21042996 -0.25834948\n",
            " -0.21190827 -0.22739572 -0.21486374 -0.22716791 -0.22932848 -0.23312903\n",
            " -0.21631859 -0.16960498 -0.19796294 -0.22953398 -0.21395176 -0.22239042\n",
            " -0.2629876  -0.22469036 -0.26032683 -0.23396776 -0.15529998 -0.27424352\n",
            " -0.26642732 -0.25022781 -0.25118363 -0.22982868 -0.22166241 -0.23631229\n",
            " -0.24192852 -0.25081645 -0.20588545 -0.20624628 -0.22716791 -0.19996376\n",
            " -0.21567901 -0.22716791 -0.20083114 -0.23007878 -0.20860793 -0.23039059\n",
            " -0.19496481 -0.26093893 -0.27543232 -0.22900706 -0.22944555 -0.21143037\n",
            " -0.22664541 -0.21922945  0.08939943  0.22317606  0.09561181  0.16647415\n",
            "  0.11646538  0.00450047  0.32074236  0.0619475   0.12181038  0.06295192\n",
            "  0.2127162   0.18487882  0.14805872  0.22474798  0.19438804  0.17416769\n",
            "  0.17514062  0.00783906 -0.05590202  0.23962049  0.11635465  0.24732997\n",
            " -0.00880412  0.23830384  0.13734242  0.10672835  0.2550195   0.25246946\n",
            "  0.14182521  0.13574936  0.0721859   0.0484597   0.13548098  0.23807085\n",
            "  0.18841773  0.04462609  0.14307455  0.18075685  0.26625196  0.15940825\n",
            "  0.12354281  0.18001808  0.22317606  0.09683885  0.11196547  0.17135161\n",
            "  0.21499384  0.19575044  0.17430072  0.23563673]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963]\n",
            "Epoch - 24 starting.....\n",
            "Predicted Output from the Adaline Model in the 24 th step is as follows: [0.20889848 0.21920152 0.19648189 0.21965144 0.20320512 0.25121748\n",
            " 0.20548788 0.22073511 0.20932596 0.22097094 0.22181878 0.22687839\n",
            " 0.21014173 0.16316888 0.1889037  0.22084342 0.2058858  0.21536344\n",
            " 0.25563551 0.21740075 0.25378023 0.22696425 0.14749417 0.2684892\n",
            " 0.26087715 0.24446218 0.24499796 0.22282621 0.21459183 0.23048064\n",
            " 0.236174   0.24404432 0.19777003 0.197588   0.22097094 0.19293343\n",
            " 0.20794484 0.22097094 0.1948945  0.22332993 0.2014357  0.22564404\n",
            " 0.18869743 0.25482936 0.26919739 0.22307166 0.2222687  0.20521999\n",
            " 0.21922396 0.21250073 0.91624186 0.78107292 0.90910325 0.83804957\n",
            " 0.88866638 1.00140778 0.68298917 0.9433282  0.88348884 0.94163255\n",
            " 0.79020894 0.81930767 0.85598711 0.77980722 0.81029921 0.82967485\n",
            " 0.82880776 0.99701219 1.06332543 0.76456246 0.88798063 0.75658387\n",
            " 1.01506762 0.76491621 0.86676252 0.89743902 0.74788994 0.75043096\n",
            " 0.86313783 0.86804032 0.93282069 0.95527314 0.86960279 0.76508862\n",
            " 0.81629568 0.96026794 0.86134668 0.8231144  0.73650323 0.84415048\n",
            " 0.88102157 0.82308165 0.78107292 0.90805165 0.89262238 0.83232347\n",
            " 0.78891117 0.80773893 0.82962106 0.76790716]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.20889848 -0.21920152 -0.19648189 -0.21965144 -0.20320512 -0.25121748\n",
            " -0.20548788 -0.22073511 -0.20932596 -0.22097094 -0.22181878 -0.22687839\n",
            " -0.21014173 -0.16316888 -0.1889037  -0.22084342 -0.2058858  -0.21536344\n",
            " -0.25563551 -0.21740075 -0.25378023 -0.22696425 -0.14749417 -0.2684892\n",
            " -0.26087715 -0.24446218 -0.24499796 -0.22282621 -0.21459183 -0.23048064\n",
            " -0.236174   -0.24404432 -0.19777003 -0.197588   -0.22097094 -0.19293343\n",
            " -0.20794484 -0.22097094 -0.1948945  -0.22332993 -0.2014357  -0.22564404\n",
            " -0.18869743 -0.25482936 -0.26919739 -0.22307166 -0.2222687  -0.20521999\n",
            " -0.21922396 -0.21250073  0.08375814  0.21892708  0.09089675  0.16195043\n",
            "  0.11133362 -0.00140778  0.31701083  0.0566718   0.11651116  0.05836745\n",
            "  0.20979106  0.18069233  0.14401289  0.22019278  0.18970079  0.17032515\n",
            "  0.17119224  0.00298781 -0.06332543  0.23543754  0.11201937  0.24341613\n",
            " -0.01506762  0.23508379  0.13323748  0.10256098  0.25211006  0.24956904\n",
            "  0.13686217  0.13195968  0.06717931  0.04472686  0.13039721  0.23491138\n",
            "  0.18370432  0.03973206  0.13865332  0.1768856   0.26349677  0.15584952\n",
            "  0.11897843  0.17691835  0.21892708  0.09194835  0.10737762  0.16767653\n",
            "  0.21108883  0.19226107  0.17037894  0.23209284]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957]\n",
            "Epoch - 25 starting.....\n",
            "Predicted Output from the Adaline Model in the 25 th step is as follows: [0.20197206 0.21324695 0.19015205 0.21401983 0.19620419 0.24430674\n",
            " 0.19926679 0.21428067 0.20395958 0.21496534 0.21454152 0.22082142\n",
            " 0.20415563 0.15693211 0.18012488 0.21242273 0.19807009 0.20855417\n",
            " 0.24851091 0.21033734 0.24743583 0.22017812 0.13993071 0.2629132\n",
            " 0.2554989  0.23887448 0.23900406 0.21604043 0.20773993 0.22482954\n",
            " 0.23059741 0.23748173 0.18990634 0.18919825 0.21496534 0.18612051\n",
            " 0.20044973 0.21496534 0.18914175 0.21678988 0.1944858  0.22104371\n",
            " 0.18262443 0.24890962 0.2631561  0.21731986 0.21531439 0.199202\n",
            " 0.21203231 0.20598017 0.92170984 0.78519066 0.91367189 0.84243307\n",
            " 0.89363959 1.00713206 0.68660592 0.94843928 0.88862287 0.94607589\n",
            " 0.79304392 0.82336423 0.85990762 0.78422173 0.81484255 0.83339936\n",
            " 0.83263366 1.00171324 1.07051762 0.76861478 0.89218205 0.76037737\n",
            " 1.02113564 0.76803627 0.87074075 0.9014766  0.75070923 0.75324186\n",
            " 0.86794727 0.87171138 0.93767094 0.95888995 0.87452938 0.76814959\n",
            " 0.8208622  0.96500968 0.86563242 0.82686579 0.73917349 0.847599\n",
            " 0.88544524 0.82608574 0.78519066 0.91279116 0.89706919 0.83588515\n",
            " 0.79269486 0.8111204  0.83342278 0.77134177]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.20197206 -0.21324695 -0.19015205 -0.21401983 -0.19620419 -0.24430674\n",
            " -0.19926679 -0.21428067 -0.20395958 -0.21496534 -0.21454152 -0.22082142\n",
            " -0.20415563 -0.15693211 -0.18012488 -0.21242273 -0.19807009 -0.20855417\n",
            " -0.24851091 -0.21033734 -0.24743583 -0.22017812 -0.13993071 -0.2629132\n",
            " -0.2554989  -0.23887448 -0.23900406 -0.21604043 -0.20773993 -0.22482954\n",
            " -0.23059741 -0.23748173 -0.18990634 -0.18919825 -0.21496534 -0.18612051\n",
            " -0.20044973 -0.21496534 -0.18914175 -0.21678988 -0.1944858  -0.22104371\n",
            " -0.18262443 -0.24890962 -0.2631561  -0.21731986 -0.21531439 -0.199202\n",
            " -0.21203231 -0.20598017  0.07829016  0.21480934  0.08632811  0.15756693\n",
            "  0.10636041 -0.00713206  0.31339408  0.05156072  0.11137713  0.05392411\n",
            "  0.20695608  0.17663577  0.14009238  0.21577827  0.18515745  0.16660064\n",
            "  0.16736634 -0.00171324 -0.07051762  0.23138522  0.10781795  0.23962263\n",
            " -0.02113564  0.23196373  0.12925925  0.0985234   0.24929077  0.24675814\n",
            "  0.13205273  0.12828862  0.06232906  0.04111005  0.12547062  0.23185041\n",
            "  0.1791378   0.03499032  0.13436758  0.17313421  0.26082651  0.152401\n",
            "  0.11455476  0.17391426  0.21480934  0.08720884  0.10293081  0.16411485\n",
            "  0.20730514  0.1888796   0.16657722  0.22865823]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234]\n",
            "Epoch - 26 starting.....\n",
            "Predicted Output from the Adaline Model in the 26 th step is as follows: [0.19526008 0.20747631 0.18401823 0.20856255 0.18942023 0.23761041\n",
            " 0.19323884 0.20802602 0.19875929 0.2091452  0.20748949 0.21495211\n",
            " 0.19835438 0.1508885  0.17161781 0.20426356 0.19049688 0.20195586\n",
            " 0.24160677 0.20349313 0.24128737 0.21360262 0.13260211 0.25750999\n",
            " 0.25028726 0.23345922 0.23319597 0.20946461 0.20109993 0.21935337\n",
            " 0.22519323 0.23112217 0.18228659 0.18106873 0.2091452  0.17951828\n",
            " 0.19318628 0.2091452  0.1835672  0.21045216 0.18775133 0.21658506\n",
            " 0.17673979 0.24317383 0.25730245 0.21174595 0.20857573 0.19337046\n",
            " 0.20506334 0.19966134 0.92700988 0.78918123 0.91809865 0.84668069\n",
            " 0.89845917 1.01267806 0.69011146 0.95339083 0.89359685 0.95038246\n",
            " 0.79579151 0.82729487 0.86370668 0.7884999  0.81924645 0.83700948\n",
            " 0.83634089 1.00626873 1.07748574 0.77254053 0.89625375 0.76405425\n",
            " 1.02701421 0.77105941 0.87459618 0.90538842 0.75344118 0.75596601\n",
            " 0.87260789 0.87526749 0.94236969 0.96239431 0.87930367 0.77111512\n",
            " 0.82528637 0.96960386 0.86978686 0.83050104 0.74176148 0.85094073\n",
            " 0.88973256 0.82899715 0.78918123 0.91738437 0.90137932 0.83933695\n",
            " 0.79636099 0.81439731 0.83710817 0.77467048]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.19526008 -0.20747631 -0.18401823 -0.20856255 -0.18942023 -0.23761041\n",
            " -0.19323884 -0.20802602 -0.19875929 -0.2091452  -0.20748949 -0.21495211\n",
            " -0.19835438 -0.1508885  -0.17161781 -0.20426356 -0.19049688 -0.20195586\n",
            " -0.24160677 -0.20349313 -0.24128737 -0.21360262 -0.13260211 -0.25750999\n",
            " -0.25028726 -0.23345922 -0.23319597 -0.20946461 -0.20109993 -0.21935337\n",
            " -0.22519323 -0.23112217 -0.18228659 -0.18106873 -0.2091452  -0.17951828\n",
            " -0.19318628 -0.2091452  -0.1835672  -0.21045216 -0.18775133 -0.21658506\n",
            " -0.17673979 -0.24317383 -0.25730245 -0.21174595 -0.20857573 -0.19337046\n",
            " -0.20506334 -0.19966134  0.07299012  0.21081877  0.08190135  0.15331931\n",
            "  0.10154083 -0.01267806  0.30988854  0.04660917  0.10640315  0.04961754\n",
            "  0.20420849  0.17270513  0.13629332  0.2115001   0.18075355  0.16299052\n",
            "  0.16365911 -0.00626873 -0.07748574  0.22745947  0.10374625  0.23594575\n",
            " -0.02701421  0.22894059  0.12540382  0.09461158  0.24655882  0.24403399\n",
            "  0.12739211  0.12473251  0.05763031  0.03760569  0.12069633  0.22888488\n",
            "  0.17471363  0.03039614  0.13021314  0.16949896  0.25823852  0.14905927\n",
            "  0.11026744  0.17100285  0.21081877  0.08261563  0.09862068  0.16066305\n",
            "  0.20363901  0.18560269  0.16289183  0.22532952]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779]\n",
            "Epoch - 27 starting.....\n",
            "Predicted Output from the Adaline Model in the 27 th step is as follows: [0.18875589 0.20188389 0.17807434 0.20327421 0.18284652 0.23112186\n",
            " 0.18739803 0.20196496 0.19371994 0.20350478 0.20065572 0.20926466\n",
            " 0.19273225 0.14503207 0.16337406 0.19635781 0.18315865 0.19556198\n",
            " 0.23491625 0.19686132 0.23532879 0.20723123 0.12550109 0.25227422\n",
            " 0.24523706 0.22821105 0.22756795 0.20309225 0.19466527 0.21404674\n",
            " 0.21995612 0.22495936 0.17490323 0.17319136 0.20350478 0.1731202\n",
            " 0.18614731 0.20350478 0.17816532 0.20431052 0.18122563 0.21226372\n",
            " 0.17103767 0.23761631 0.25163062 0.20634443 0.20204603 0.18771959\n",
            " 0.19831016 0.19353798 0.93214718 0.79304858 0.92238792 0.85079663\n",
            " 0.90312988 1.01805131 0.69350923 0.95818779 0.89841574 0.95455651\n",
            " 0.79845444 0.83110351 0.86738805 0.79264595 0.82351521 0.84050876\n",
            " 0.83993311 1.01068318 1.08423674 0.77634363 0.90019975 0.76761813\n",
            " 1.03270922 0.77398866 0.87833263 0.90917836 0.75608848 0.75860608\n",
            " 0.87712428 0.87871222 0.94692165 0.9657897  0.88393037 0.77398816\n",
            " 0.82957262 0.97405504 0.87381406 0.83402374 0.74426972 0.85417898\n",
            " 0.89388775 0.83181875 0.79304858 0.92183579 0.905557   0.84268227\n",
            " 0.79991319 0.81757289 0.84068081 0.77789657]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.18875589 -0.20188389 -0.17807434 -0.20327421 -0.18284652 -0.23112186\n",
            " -0.18739803 -0.20196496 -0.19371994 -0.20350478 -0.20065572 -0.20926466\n",
            " -0.19273225 -0.14503207 -0.16337406 -0.19635781 -0.18315865 -0.19556198\n",
            " -0.23491625 -0.19686132 -0.23532879 -0.20723123 -0.12550109 -0.25227422\n",
            " -0.24523706 -0.22821105 -0.22756795 -0.20309225 -0.19466527 -0.21404674\n",
            " -0.21995612 -0.22495936 -0.17490323 -0.17319136 -0.20350478 -0.1731202\n",
            " -0.18614731 -0.20350478 -0.17816532 -0.20431052 -0.18122563 -0.21226372\n",
            " -0.17103767 -0.23761631 -0.25163062 -0.20634443 -0.20204603 -0.18771959\n",
            " -0.19831016 -0.19353798  0.06785282  0.20695142  0.07761208  0.14920337\n",
            "  0.09687012 -0.01805131  0.30649077  0.04181221  0.10158426  0.04544349\n",
            "  0.20154556  0.16889649  0.13261195  0.20735405  0.17648479  0.15949124\n",
            "  0.16006689 -0.01068318 -0.08423674  0.22365637  0.09980025  0.23238187\n",
            " -0.03270922  0.22601134  0.12166737  0.09082164  0.24391152  0.24139392\n",
            "  0.12287572  0.12128778  0.05307835  0.0342103   0.11606963  0.22601184\n",
            "  0.17042738  0.02594496  0.12618594  0.16597626  0.25573028  0.14582102\n",
            "  0.10611225  0.16818125  0.20695142  0.07816421  0.094443    0.15731773\n",
            "  0.20008681  0.18242711  0.15931919  0.22210343]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986]\n",
            "Epoch - 28 starting.....\n",
            "Predicted Output from the Adaline Model in the 28 th step is as follows: [0.18245307 0.19646418 0.17231451 0.19814957 0.17647655 0.22483464\n",
            " 0.18173858 0.19609151 0.18883656 0.19803851 0.19403344 0.20375342\n",
            " 0.18728369 0.13935701 0.15538549 0.18869763 0.17604812 0.18936621\n",
            " 0.22843274 0.19043534 0.2295542  0.20105764 0.1186206  0.2472007\n",
            " 0.24034331 0.2231248  0.22211441 0.19691706 0.18842959 0.20890439\n",
            " 0.21488092 0.21898721 0.16774892 0.16555834 0.19803851 0.16691995\n",
            " 0.17932587 0.19803851 0.17293076 0.19835886 0.17490222 0.20807542\n",
            " 0.16551243 0.23223152 0.24613499 0.20110996 0.19571883 0.18224378\n",
            " 0.19176608 0.18760404 0.93712678 0.79679651 0.92654397 0.85478497\n",
            " 0.90765633 1.02325716 0.69680257 0.96283495 0.90308433 0.95860214\n",
            " 0.80103532 0.83479391 0.87095538 0.79666399 0.82765303 0.84390063\n",
            " 0.84341389 1.01496096 1.09077734 0.78002788 0.90402394 0.7710725\n",
            " 1.03822634 0.7768269  0.88195378 0.91285021 0.75865375 0.76116469\n",
            " 0.88150091 0.88204901 0.95133136 0.96907951 0.88841404 0.77677158\n",
            " 0.83372521 0.97836765 0.87771796 0.83743737 0.7467007  0.85731694\n",
            " 0.89791489 0.83455333 0.79679651 0.92614984 0.90960633 0.84592441\n",
            " 0.803355   0.82065028 0.84414421 0.78102323]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.18245307 -0.19646418 -0.17231451 -0.19814957 -0.17647655 -0.22483464\n",
            " -0.18173858 -0.19609151 -0.18883656 -0.19803851 -0.19403344 -0.20375342\n",
            " -0.18728369 -0.13935701 -0.15538549 -0.18869763 -0.17604812 -0.18936621\n",
            " -0.22843274 -0.19043534 -0.2295542  -0.20105764 -0.1186206  -0.2472007\n",
            " -0.24034331 -0.2231248  -0.22211441 -0.19691706 -0.18842959 -0.20890439\n",
            " -0.21488092 -0.21898721 -0.16774892 -0.16555834 -0.19803851 -0.16691995\n",
            " -0.17932587 -0.19803851 -0.17293076 -0.19835886 -0.17490222 -0.20807542\n",
            " -0.16551243 -0.23223152 -0.24613499 -0.20110996 -0.19571883 -0.18224378\n",
            " -0.19176608 -0.18760404  0.06287322  0.20320349  0.07345603  0.14521503\n",
            "  0.09234367 -0.02325716  0.30319743  0.03716505  0.09691567  0.04139786\n",
            "  0.19896468  0.16520609  0.12904462  0.20333601  0.17234697  0.15609937\n",
            "  0.15658611 -0.01496096 -0.09077734  0.21997212  0.09597606  0.2289275\n",
            " -0.03822634  0.2231731   0.11804622  0.08714979  0.24134625  0.23883531\n",
            "  0.11849909  0.11795099  0.04866864  0.03092049  0.11158596  0.22322842\n",
            "  0.16627479  0.02163235  0.12228204  0.16256263  0.2532993   0.14268306\n",
            "  0.10208511  0.16544667  0.20320349  0.07385016  0.09039367  0.15407559\n",
            "  0.196645    0.17934972  0.15585579  0.21897677]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141]\n",
            "Epoch - 29 starting.....\n",
            "Predicted Output from the Adaline Model in the 29 th step is as follows: [0.17634537 0.19121183 0.16673303 0.19318357 0.170304   0.21874252\n",
            " 0.17625487 0.19039984 0.18410431 0.19274099 0.18761611 0.19841295\n",
            " 0.18200333 0.13385772 0.14764418 0.18127541 0.16915825 0.18336239\n",
            " 0.22214983 0.18420881 0.2239579  0.19507571 0.11195381 0.24228441\n",
            " 0.23560115 0.21819545 0.21682996 0.19093292 0.18238674 0.20392123\n",
            " 0.2099626  0.21319982 0.16081658 0.1581621  0.19274099 0.16091141\n",
            " 0.17271523 0.19274099 0.16785836 0.19259132 0.16877484 0.20401606\n",
            " 0.16015859 0.22701412 0.2408101  0.19603737 0.18958785 0.17693762\n",
            " 0.18542463 0.18185366 0.94195357 0.80042872 0.93057092 0.85864967\n",
            " 0.91204298 1.0283008  0.6999947  0.96733696 0.90760728 0.96252331\n",
            " 0.80353669 0.83836975 0.8744122  0.80055797 0.83166395 0.84718841\n",
            " 0.84678668 1.01910629 1.09711407 0.78359695 0.90773009 0.77442076\n",
            " 1.04357109 0.77957697 0.8854632  0.91640762 0.76113954 0.76364435\n",
            " 0.88574211 0.88528121 0.95560322 0.972267   0.89275913 0.77946815\n",
            " 0.83774827 0.98254599 0.88150239 0.84074532 0.7490568  0.86035773\n",
            " 0.90181797 0.83720357 0.80042872 0.93033075 0.91353129 0.84906656\n",
            " 0.80668983 0.82363253 0.84750175 0.78405352]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.17634537 -0.19121183 -0.16673303 -0.19318357 -0.170304   -0.21874252\n",
            " -0.17625487 -0.19039984 -0.18410431 -0.19274099 -0.18761611 -0.19841295\n",
            " -0.18200333 -0.13385772 -0.14764418 -0.18127541 -0.16915825 -0.18336239\n",
            " -0.22214983 -0.18420881 -0.2239579  -0.19507571 -0.11195381 -0.24228441\n",
            " -0.23560115 -0.21819545 -0.21682996 -0.19093292 -0.18238674 -0.20392123\n",
            " -0.2099626  -0.21319982 -0.16081658 -0.1581621  -0.19274099 -0.16091141\n",
            " -0.17271523 -0.19274099 -0.16785836 -0.19259132 -0.16877484 -0.20401606\n",
            " -0.16015859 -0.22701412 -0.2408101  -0.19603737 -0.18958785 -0.17693762\n",
            " -0.18542463 -0.18185366  0.05804643  0.19957128  0.06942908  0.14135033\n",
            "  0.08795702 -0.0283008   0.3000053   0.03266304  0.09239272  0.03747669\n",
            "  0.19646331  0.16163025  0.1255878   0.19944203  0.16833605  0.15281159\n",
            "  0.15321332 -0.01910629 -0.09711407  0.21640305  0.09226991  0.22557924\n",
            " -0.04357109  0.22042303  0.1145368   0.08359238  0.23886046  0.23635565\n",
            "  0.11425789  0.11471879  0.04439678  0.027733    0.10724087  0.22053185\n",
            "  0.16225173  0.01745401  0.11849761  0.15925468  0.2509432   0.13964227\n",
            "  0.09818203  0.16279643  0.19957128  0.06966925  0.08646871  0.15093344\n",
            "  0.19331017  0.17636747  0.15249825  0.21594648]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702]\n",
            "Epoch - 30 starting.....\n",
            "Predicted Output from the Adaline Model in the 30 th step is as follows: [0.17042675 0.18612166 0.16132439 0.18837129 0.16432277 0.21283946\n",
            " 0.17094145 0.18488434 0.17951851 0.187607   0.18139738 0.19323794\n",
            " 0.17688596 0.12852874 0.14014249 0.17408378 0.1624822  0.1775446\n",
            " 0.2160613  0.17817555 0.21853438 0.18927952 0.10549409 0.23752049\n",
            " 0.23100589 0.21341814 0.21170935 0.18513392 0.17653073 0.19909234\n",
            " 0.20519631 0.20759145 0.15409934 0.15099531 0.187607   0.15508863\n",
            " 0.16630885 0.187607   0.16294307 0.18700219 0.16283743 0.20008163\n",
            " 0.15497083 0.22195892 0.23565066 0.19112165 0.18364701 0.17179585\n",
            " 0.17927953 0.17628114 0.94663226 0.8039488  0.93447276 0.86239456\n",
            " 0.91629417 1.03318724 0.70308877 0.97169831 0.9119891  0.9663239\n",
            " 0.80596102 0.84183456 0.87776193 0.80433173 0.83555192 0.85037533\n",
            " 0.85005483 1.02312328 1.10325323 0.78705442 0.91132187 0.77766619\n",
            " 1.04874881 0.7822416  0.88886434 0.91985414 0.7635483  0.76604752\n",
            " 0.88985208 0.88841206 0.95974151 0.97535534 0.89696993 0.78208056\n",
            " 0.84164583 0.98659421 0.88517103 0.84395085 0.75134035 0.86330435\n",
            " 0.90560082 0.8397721  0.8039488  0.93438265 0.91733573 0.85211183\n",
            " 0.809921   0.82652258 0.8507567  0.78699044]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.17042675 -0.18612166 -0.16132439 -0.18837129 -0.16432277 -0.21283946\n",
            " -0.17094145 -0.18488434 -0.17951851 -0.187607   -0.18139738 -0.19323794\n",
            " -0.17688596 -0.12852874 -0.14014249 -0.17408378 -0.1624822  -0.1775446\n",
            " -0.2160613  -0.17817555 -0.21853438 -0.18927952 -0.10549409 -0.23752049\n",
            " -0.23100589 -0.21341814 -0.21170935 -0.18513392 -0.17653073 -0.19909234\n",
            " -0.20519631 -0.20759145 -0.15409934 -0.15099531 -0.187607   -0.15508863\n",
            " -0.16630885 -0.187607   -0.16294307 -0.18700219 -0.16283743 -0.20008163\n",
            " -0.15497083 -0.22195892 -0.23565066 -0.19112165 -0.18364701 -0.17179585\n",
            " -0.17927953 -0.17628114  0.05336774  0.1960512   0.06552724  0.13760544\n",
            "  0.08370583 -0.03318724  0.29691123  0.02830169  0.0880109   0.0336761\n",
            "  0.19403898  0.15816544  0.12223807  0.19566827  0.16444808  0.14962467\n",
            "  0.14994517 -0.02312328 -0.10325323  0.21294558  0.08867813  0.22233381\n",
            " -0.04874881  0.2177584   0.11113566  0.08014586  0.2364517   0.23395248\n",
            "  0.11014792  0.11158794  0.04025849  0.02464466  0.10303007  0.21791944\n",
            "  0.15835417  0.01340579  0.11482897  0.15604915  0.24865965  0.13669565\n",
            "  0.09439918  0.1602279   0.1960512   0.06561735  0.08266427  0.14788817\n",
            "  0.190079    0.17347742  0.1492433   0.21300956]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123]\n",
            "Epoch - 31 starting.....\n",
            "Predicted Output from the Adaline Model in the 31 th step is as follows: [0.16469136 0.18118864 0.15608322 0.18370797 0.15852694 0.20711961\n",
            " 0.16579305 0.17953954 0.17507463 0.18263148 0.17537111 0.18822329\n",
            " 0.17192653 0.1233648  0.13287298 0.16711561 0.15601335 0.17190706\n",
            " 0.21016114 0.17232957 0.21327829 0.1836633  0.09923505 0.2329042\n",
            " 0.22655299 0.20878817 0.20674751 0.17951433 0.17085578 0.19441292\n",
            " 0.20057734 0.20215657 0.14759052 0.14405086 0.18263148 0.14944588\n",
            " 0.16010042 0.18263148 0.15818004 0.18158594 0.15708409 0.19626828\n",
            " 0.14994401 0.2170609  0.23065154 0.18635793 0.17789044 0.16681338\n",
            " 0.1733247  0.17088099 0.95116746 0.80736023 0.93825338 0.86602334\n",
            " 0.92041408 1.03792137 0.70608781 0.97592336 0.91623417 0.97000762\n",
            " 0.80831068 0.84519179 0.8810079  0.80798899 0.83932073 0.85346452\n",
            " 0.85322157 1.0270159  1.10920095 0.79040375 0.91480281 0.78081197\n",
            " 1.05376467 0.78482342 0.89216057 0.9231932  0.76588243 0.76837656\n",
            " 0.89383488 0.8914447  0.96375036 0.97834761 0.90105058 0.78461142\n",
            " 0.84542177 0.99051635 0.88872748 0.84705715 0.75355358 0.86615972\n",
            " 0.90926715 0.84226143 0.80736023 0.93830953 0.92102339 0.8550632\n",
            " 0.81305172 0.82932328 0.85391224 0.78983688]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.16469136 -0.18118864 -0.15608322 -0.18370797 -0.15852694 -0.20711961\n",
            " -0.16579305 -0.17953954 -0.17507463 -0.18263148 -0.17537111 -0.18822329\n",
            " -0.17192653 -0.1233648  -0.13287298 -0.16711561 -0.15601335 -0.17190706\n",
            " -0.21016114 -0.17232957 -0.21327829 -0.1836633  -0.09923505 -0.2329042\n",
            " -0.22655299 -0.20878817 -0.20674751 -0.17951433 -0.17085578 -0.19441292\n",
            " -0.20057734 -0.20215657 -0.14759052 -0.14405086 -0.18263148 -0.14944588\n",
            " -0.16010042 -0.18263148 -0.15818004 -0.18158594 -0.15708409 -0.19626828\n",
            " -0.14994401 -0.2170609  -0.23065154 -0.18635793 -0.17789044 -0.16681338\n",
            " -0.1733247  -0.17088099  0.04883254  0.19263977  0.06174662  0.13397666\n",
            "  0.07958592 -0.03792137  0.29391219  0.02407664  0.08376583  0.02999238\n",
            "  0.19168932  0.15480821  0.1189921   0.19201101  0.16067927  0.14653548\n",
            "  0.14677843 -0.0270159  -0.10920095  0.20959625  0.08519719  0.21918803\n",
            " -0.05376467  0.21517658  0.10783943  0.0768068   0.23411757  0.23162344\n",
            "  0.10616512  0.1085553   0.03624964  0.02165239  0.09894942  0.21538858\n",
            "  0.15457823  0.00948365  0.11127252  0.15294285  0.24644642  0.13384028\n",
            "  0.09073285  0.15773857  0.19263977  0.06169047  0.07897661  0.1449368\n",
            "  0.18694828  0.17067672  0.14608776  0.21016312]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257]\n",
            "Epoch - 32 starting.....\n",
            "Predicted Output from the Adaline Model in the 32 th step is as follows: [0.15913352 0.1764079  0.15100435 0.17918899 0.15291074 0.20157728\n",
            " 0.16080456 0.17436015 0.17076826 0.17780951 0.16953132 0.18336402\n",
            " 0.16712015 0.1183608  0.12582847 0.16036396 0.14974527 0.1664442\n",
            " 0.20444351 0.16666509 0.20818443 0.17822148 0.09317046 0.22843098\n",
            " 0.22223803 0.20430097 0.20193952 0.17406859 0.16535629 0.18987836\n",
            " 0.19610113 0.1968898  0.14128368 0.13732186 0.17780951 0.14397755\n",
            " 0.15408379 0.17780951 0.15356455 0.17633722 0.15150913 0.19257224\n",
            " 0.14507315 0.21231519 0.22580778 0.18174152 0.17231241 0.16198529\n",
            " 0.16755425 0.16564786 0.9555636  0.81066636 0.94191653 0.86953962\n",
            " 0.92440679 1.04250789 0.70899476 0.98001633 0.92034672 0.97357811\n",
            " 0.810588   0.84844477 0.88415331 0.81153338 0.84297407 0.85645899\n",
            " 0.85629005 1.03078801 1.11496315 0.79364828 0.91817634 0.78386119\n",
            " 1.05862368 0.78732501 0.89535513 0.92642814 0.76814423 0.77063376\n",
            " 0.89769445 0.89438217 0.96763378 0.98124677 0.90500513 0.78706326\n",
            " 0.84907986 0.99431631 0.8921752  0.85006728 0.75569869 0.86892667\n",
            " 0.91282059 0.84467403 0.81066636 0.94211528 0.92459787 0.8579236\n",
            " 0.81608511 0.83203741 0.85697144 0.79259563]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.15913352 -0.1764079  -0.15100435 -0.17918899 -0.15291074 -0.20157728\n",
            " -0.16080456 -0.17436015 -0.17076826 -0.17780951 -0.16953132 -0.18336402\n",
            " -0.16712015 -0.1183608  -0.12582847 -0.16036396 -0.14974527 -0.1664442\n",
            " -0.20444351 -0.16666509 -0.20818443 -0.17822148 -0.09317046 -0.22843098\n",
            " -0.22223803 -0.20430097 -0.20193952 -0.17406859 -0.16535629 -0.18987836\n",
            " -0.19610113 -0.1968898  -0.14128368 -0.13732186 -0.17780951 -0.14397755\n",
            " -0.15408379 -0.17780951 -0.15356455 -0.17633722 -0.15150913 -0.19257224\n",
            " -0.14507315 -0.21231519 -0.22580778 -0.18174152 -0.17231241 -0.16198529\n",
            " -0.16755425 -0.16564786  0.0444364   0.18933364  0.05808347  0.13046038\n",
            "  0.07559321 -0.04250789  0.29100524  0.01998367  0.07965328  0.02642189\n",
            "  0.189412    0.15155523  0.11584669  0.18846662  0.15702593  0.14354101\n",
            "  0.14370995 -0.03078801 -0.11496315  0.20635172  0.08182366  0.21613881\n",
            " -0.05862368  0.21267499  0.10464487  0.07357186  0.23185577  0.22936624\n",
            "  0.10230555  0.10561783  0.03236622  0.01875323  0.09499487  0.21293674\n",
            "  0.15092014  0.00568369  0.1078248   0.14993272  0.24430131  0.13107333\n",
            "  0.08717941  0.15532597  0.18933364  0.05788472  0.07540213  0.1420764\n",
            "  0.18391489  0.16796259  0.14302856  0.20740437]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622]\n",
            "Epoch - 33 starting.....\n",
            "Predicted Output from the Adaline Model in the 33 th step is as follows: [0.15374772 0.17177473 0.14608275 0.17480989 0.14746863 0.19620698\n",
            " 0.15597103 0.16934107 0.16659516 0.17313635 0.16387224 0.17865532\n",
            " 0.16246208 0.11351177 0.11900199 0.15382213 0.14367175 0.1611506\n",
            " 0.19890275 0.16117647 0.20324779 0.17294866 0.08729429 0.2240964\n",
            " 0.21805674 0.19995213 0.19728063 0.16879131 0.16002682 0.18548417\n",
            " 0.19176326 0.19178593 0.13517255 0.13080164 0.17313635 0.13867827\n",
            " 0.14825303 0.17313635 0.14909204 0.17125084 0.14610702 0.18898989\n",
            " 0.14035341 0.20771707 0.22111457 0.17726783 0.1669074  0.15730677\n",
            " 0.16196246 0.16057657 0.95982499 0.81387045 0.94546584 0.87294687\n",
            " 0.92827624 1.04695138 0.71181248 0.9839813  0.92433085 0.97703886\n",
            " 0.81279521 0.85159674 0.88720128 0.81496837 0.84651553 0.85936168\n",
            " 0.85926331 1.03444333 1.12054558 0.79679126 0.9214458  0.78681685\n",
            " 1.06333071 0.78974885 0.89845117 0.92956216 0.77033595 0.77282136\n",
            " 0.9014346  0.89722742 0.97139566 0.98405571 0.90883748 0.78943852\n",
            " 0.85262375 0.99799787 0.89551757 0.85298422 0.75777777 0.87160793\n",
            " 0.91626462 0.84701227 0.81387045 0.94580363 0.92806268 0.86069583\n",
            " 0.81902416 0.83466764 0.8599373  0.79526941]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.15374772 -0.17177473 -0.14608275 -0.17480989 -0.14746863 -0.19620698\n",
            " -0.15597103 -0.16934107 -0.16659516 -0.17313635 -0.16387224 -0.17865532\n",
            " -0.16246208 -0.11351177 -0.11900199 -0.15382213 -0.14367175 -0.1611506\n",
            " -0.19890275 -0.16117647 -0.20324779 -0.17294866 -0.08729429 -0.2240964\n",
            " -0.21805674 -0.19995213 -0.19728063 -0.16879131 -0.16002682 -0.18548417\n",
            " -0.19176326 -0.19178593 -0.13517255 -0.13080164 -0.17313635 -0.13867827\n",
            " -0.14825303 -0.17313635 -0.14909204 -0.17125084 -0.14610702 -0.18898989\n",
            " -0.14035341 -0.20771707 -0.22111457 -0.17726783 -0.1669074  -0.15730677\n",
            " -0.16196246 -0.16057657  0.04017501  0.18612955  0.05453416  0.12705313\n",
            "  0.07172376 -0.04695138  0.28818752  0.0160187   0.07566915  0.02296114\n",
            "  0.18720479  0.14840326  0.11279872  0.18503163  0.15348447  0.14063832\n",
            "  0.14073669 -0.03444333 -0.12054558  0.20320874  0.0785542   0.21318315\n",
            " -0.06333071  0.21025115  0.10154883  0.07043784  0.22966405  0.22717864\n",
            "  0.0985654   0.10277258  0.02860434  0.01594429  0.09116252  0.21056148\n",
            "  0.14737625  0.00200213  0.10448243  0.14701578  0.24222223  0.12839207\n",
            "  0.08373538  0.15298773  0.18612955  0.05419637  0.07193732  0.13930417\n",
            "  0.18097584  0.16533236  0.1400627   0.20473059]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555]\n",
            "Epoch - 34 starting.....\n",
            "Predicted Output from the Adaline Model in the 34 th step is as follows: [0.14852865 0.16728457 0.14131353 0.17056634 0.14219521 0.19100338\n",
            " 0.15128764 0.16447731 0.16255119 0.16860738 0.15838828 0.17409252\n",
            " 0.15794773 0.10881292 0.11238679 0.14748363 0.13778677 0.15602103\n",
            " 0.19353339 0.15585827 0.1984635  0.16783961 0.08160072 0.21989617\n",
            " 0.21400498 0.19573735 0.1927662  0.16367728 0.1548621  0.18122599\n",
            " 0.18755943 0.18683993 0.12925108 0.12448374 0.16860738 0.13354279\n",
            " 0.14260238 0.16860738 0.14475806 0.16632178 0.1408724  0.1855177\n",
            " 0.13578012 0.20326197 0.21656725 0.17293247 0.16167005 0.15277322\n",
            " 0.15654381 0.15566213 0.9639558  0.81697568 0.94890484 0.87624848\n",
            " 0.93202624 1.05125627 0.71454373 0.98782226 0.92819055 0.98039328\n",
            " 0.81493448 0.8546508  0.89015482 0.81829737 0.84994856 0.86217543\n",
            " 0.8621443  1.03798549 1.12595382 0.79983584 0.9246144  0.78968183\n",
            " 1.06789046 0.79209735 0.90145174 0.93259841 0.77245976 0.7749415\n",
            " 0.90505903 0.89998331 0.97503976 0.98677723 0.9125514  0.79173958\n",
            " 0.85605697 1.00156471 0.89875785 0.85581086 0.75979287 0.87420617\n",
            " 0.91960264 0.84927845 0.81697568 0.94937823 0.93142122 0.86338263\n",
            " 0.82187182 0.83721658 0.8628127  0.79786086]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.14852865 -0.16728457 -0.14131353 -0.17056634 -0.14219521 -0.19100338\n",
            " -0.15128764 -0.16447731 -0.16255119 -0.16860738 -0.15838828 -0.17409252\n",
            " -0.15794773 -0.10881292 -0.11238679 -0.14748363 -0.13778677 -0.15602103\n",
            " -0.19353339 -0.15585827 -0.1984635  -0.16783961 -0.08160072 -0.21989617\n",
            " -0.21400498 -0.19573735 -0.1927662  -0.16367728 -0.1548621  -0.18122599\n",
            " -0.18755943 -0.18683993 -0.12925108 -0.12448374 -0.16860738 -0.13354279\n",
            " -0.14260238 -0.16860738 -0.14475806 -0.16632178 -0.1408724  -0.1855177\n",
            " -0.13578012 -0.20326197 -0.21656725 -0.17293247 -0.16167005 -0.15277322\n",
            " -0.15654381 -0.15566213  0.0360442   0.18302432  0.05109516  0.12375152\n",
            "  0.06797376 -0.05125627  0.28545627  0.01217774  0.07180945  0.01960672\n",
            "  0.18506552  0.1453492   0.10984518  0.18170263  0.15005144  0.13782457\n",
            "  0.1378557  -0.03798549 -0.12595382  0.20016416  0.0753856   0.21031817\n",
            " -0.06789046  0.20790265  0.09854826  0.06740159  0.22754024  0.2250585\n",
            "  0.09494097  0.10001669  0.02496024  0.01322277  0.0874486   0.20826042\n",
            "  0.14394303 -0.00156471  0.10124215  0.14418914  0.24020713  0.12579383\n",
            "  0.08039736  0.15072155  0.18302432  0.05062177  0.06857878  0.13661737\n",
            "  0.17812818  0.16278342  0.1371873   0.20213914]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418]\n",
            "Epoch - 35 starting.....\n",
            "Predicted Output from the Adaline Model in the 35 th step is as follows: [0.14347114 0.16293297 0.136692   0.16645413 0.13708526 0.18596132\n",
            " 0.14674977 0.15976407 0.15863235 0.16421814 0.15307401 0.16967111\n",
            " 0.15357264 0.10425959 0.10597632 0.14134215 0.13208448 0.15105039\n",
            " 0.18833013 0.1507052  0.19382683 0.16288925 0.07608408 0.21582611\n",
            " 0.21007874 0.19165248 0.18839177 0.15872144 0.14985703 0.17709963\n",
            " 0.18348551 0.1820469  0.12351339 0.11836188 0.16421814 0.12856604\n",
            " 0.13712627 0.16421814 0.14055834 0.16154515 0.1358001  0.18215227\n",
            " 0.13134874 0.19894547 0.21216129 0.16873114 0.15659517 0.14838012\n",
            " 0.15129292 0.15089966 0.96796008 0.81998509 0.95223696 0.87944771\n",
            " 0.93566049 1.05542685 0.71719118 0.99154303 0.93192967 0.98364465\n",
            " 0.81700793 0.85761001 0.89301686 0.82152364 0.85327652 0.864903\n",
            " 0.86493587 1.04141799 1.13119325 0.80278506 0.92768526 0.79245895\n",
            " 1.0723075  0.79437284 0.9043598  0.93553991 0.77451775 0.77699628\n",
            " 0.90857134 0.9026526  0.97856974 0.98941404 0.91615058 0.79396873\n",
            " 0.85938296 1.00502038 0.90189919 0.85854999 0.76174598 0.87672394\n",
            " 0.92283793 0.8514748  0.81998509 0.9528426  0.93467679 0.86598664\n",
            " 0.8246309  0.83968674 0.86560044 0.80037253]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.14347114 -0.16293297 -0.136692   -0.16645413 -0.13708526 -0.18596132\n",
            " -0.14674977 -0.15976407 -0.15863235 -0.16421814 -0.15307401 -0.16967111\n",
            " -0.15357264 -0.10425959 -0.10597632 -0.14134215 -0.13208448 -0.15105039\n",
            " -0.18833013 -0.1507052  -0.19382683 -0.16288925 -0.07608408 -0.21582611\n",
            " -0.21007874 -0.19165248 -0.18839177 -0.15872144 -0.14985703 -0.17709963\n",
            " -0.18348551 -0.1820469  -0.12351339 -0.11836188 -0.16421814 -0.12856604\n",
            " -0.13712627 -0.16421814 -0.14055834 -0.16154515 -0.1358001  -0.18215227\n",
            " -0.13134874 -0.19894547 -0.21216129 -0.16873114 -0.15659517 -0.14838012\n",
            " -0.15129292 -0.15089966  0.03203992  0.18001491  0.04776304  0.12055229\n",
            "  0.06433951 -0.05542685  0.28280882  0.00845697  0.06807033  0.01635535\n",
            "  0.18299207  0.14238999  0.10698314  0.17847636  0.14672348  0.135097\n",
            "  0.13506413 -0.04141799 -0.13119325  0.19721494  0.07231474  0.20754105\n",
            " -0.0723075   0.20562716  0.0956402   0.06446009  0.22548225  0.22300372\n",
            "  0.09142866  0.0973474   0.02143026  0.01058596  0.08384942  0.20603127\n",
            "  0.14061704 -0.00502038  0.09810081  0.14145001  0.23825402  0.12327606\n",
            "  0.07716207  0.1485252   0.18001491  0.0471574   0.06532321  0.13401336\n",
            "  0.1753691   0.16031326  0.13439956  0.19962747]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221]\n",
            "Epoch - 36 starting.....\n",
            "Predicted Output from the Adaline Model in the 36 th step is as follows: [0.13857019 0.15871566 0.13221356 0.1624692  0.13213371 0.18107579\n",
            " 0.14235289 0.15519669 0.15483478 0.1599643  0.14792418 0.16538671\n",
            " 0.14933251 0.09984729 0.09976424 0.1353916  0.12655923 0.14623378\n",
            " 0.18328781 0.14571216 0.18933321 0.15809267 0.0707389  0.21188221\n",
            " 0.20627413 0.1876935  0.184153   0.15391889 0.14500667 0.17310099\n",
            " 0.17953747 0.1774021  0.1179538  0.11243    0.1599643  0.1237431\n",
            " 0.13181929 0.1599643  0.13648872 0.15691625 0.13088507 0.17889029\n",
            " 0.12705488 0.19476326 0.20789231 0.16465969 0.15167772 0.14412314\n",
            " 0.14620462 0.14628447 0.97184174 0.82290166 0.95546549 0.88254775\n",
            " 0.93918257 1.05946729 0.71975743 0.99514734 0.93555194 0.98679617\n",
            " 0.81901757 0.8604773  0.89579024 0.82465038 0.85650267 0.86754706\n",
            " 0.86764081 1.04474423 1.13626912 0.80564189 0.93066142 0.79515092\n",
            " 1.07658624 0.79657759 0.90717821 0.9383896  0.77651197 0.77898771\n",
            " 0.91197498 0.90523798 0.98198912 0.99196875 0.91963857 0.7961282\n",
            " 0.86260504 1.00836831 0.90494467 0.86120433 0.76363901 0.87916375\n",
            " 0.92597367 0.85360349 0.82290166 0.95620015 0.93783256 0.86851043\n",
            " 0.82730415 0.84208055 0.86830324 0.80280688]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.13857019 -0.15871566 -0.13221356 -0.1624692  -0.13213371 -0.18107579\n",
            " -0.14235289 -0.15519669 -0.15483478 -0.1599643  -0.14792418 -0.16538671\n",
            " -0.14933251 -0.09984729 -0.09976424 -0.1353916  -0.12655923 -0.14623378\n",
            " -0.18328781 -0.14571216 -0.18933321 -0.15809267 -0.0707389  -0.21188221\n",
            " -0.20627413 -0.1876935  -0.184153   -0.15391889 -0.14500667 -0.17310099\n",
            " -0.17953747 -0.1774021  -0.1179538  -0.11243    -0.1599643  -0.1237431\n",
            " -0.13181929 -0.1599643  -0.13648872 -0.15691625 -0.13088507 -0.17889029\n",
            " -0.12705488 -0.19476326 -0.20789231 -0.16465969 -0.15167772 -0.14412314\n",
            " -0.14620462 -0.14628447  0.02815826  0.17709834  0.04453451  0.11745225\n",
            "  0.06081743 -0.05946729  0.28024257  0.00485266  0.06444806  0.01320383\n",
            "  0.18098243  0.1395227   0.10420976  0.17534962  0.14349733  0.13245294\n",
            "  0.13235919 -0.04474423 -0.13626912  0.19435811  0.06933858  0.20484908\n",
            " -0.07658624  0.20342241  0.09282179  0.0616104   0.22348803  0.22101229\n",
            "  0.08802502  0.09476202  0.01801088  0.00803125  0.08036143  0.2038718\n",
            "  0.13739496 -0.00836831  0.09505533  0.13879567  0.23636099  0.12083625\n",
            "  0.07402633  0.14639651  0.17709834  0.04379985  0.06216744  0.13148957\n",
            "  0.17269585  0.15791945  0.13169676  0.19719312]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884]\n",
            "Epoch - 37 starting.....\n",
            "Predicted Output from the Adaline Model in the 37 th step is as follows: [0.13382094 0.15462847 0.1278738  0.15860761 0.12733566 0.17634195\n",
            " 0.13809265 0.15077065 0.1511547  0.15584167 0.14293369 0.16123507\n",
            " 0.14522316 0.09557163 0.09374441 0.12962605 0.12120553 0.14156641\n",
            " 0.17840145 0.14087419 0.18497823 0.1534451  0.06555987 0.20806055\n",
            " 0.20258739 0.18385652 0.18004569 0.14926489 0.14030622 0.16922612\n",
            " 0.1757114  0.17290095 0.11256677 0.10668221 0.15584167 0.11906921\n",
            " 0.1266762  0.15584167 0.13254516 0.15243049 0.12612246 0.17572856\n",
            " 0.12289427 0.19071118 0.20375608 0.1607141  0.14691283 0.13999806\n",
            " 0.14127385 0.14181198 0.97560458 0.82572826 0.95859365 0.88555164\n",
            " 0.94259597 1.06338161 0.722245   0.9986388  0.93906099 0.98985093\n",
            " 0.8209654  0.86325552 0.89847771 0.82768066 0.85963016 0.87011018\n",
            " 0.87026178 1.04796749 1.14118647 0.80840917 0.93354581 0.79776039\n",
            " 1.08073097 0.79871378 0.90990975 0.94115032 0.77844439 0.78091778\n",
            " 0.91527333 0.90774205 0.98530134 0.99444391 0.9230188  0.79822015\n",
            " 0.86572642 1.01161185 0.90789724 0.8637765  0.76547383 0.881528\n",
            " 0.92901293 0.85566661 0.82572826 0.95945418 0.94089162 0.87095648\n",
            " 0.82989424 0.84440039 0.87092372 0.80516631]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.13382094 -0.15462847 -0.1278738  -0.15860761 -0.12733566 -0.17634195\n",
            " -0.13809265 -0.15077065 -0.1511547  -0.15584167 -0.14293369 -0.16123507\n",
            " -0.14522316 -0.09557163 -0.09374441 -0.12962605 -0.12120553 -0.14156641\n",
            " -0.17840145 -0.14087419 -0.18497823 -0.1534451  -0.06555987 -0.20806055\n",
            " -0.20258739 -0.18385652 -0.18004569 -0.14926489 -0.14030622 -0.16922612\n",
            " -0.1757114  -0.17290095 -0.11256677 -0.10668221 -0.15584167 -0.11906921\n",
            " -0.1266762  -0.15584167 -0.13254516 -0.15243049 -0.12612246 -0.17572856\n",
            " -0.12289427 -0.19071118 -0.20375608 -0.1607141  -0.14691283 -0.13999806\n",
            " -0.14127385 -0.14181198  0.02439542  0.17427174  0.04140635  0.11444836\n",
            "  0.05740403 -0.06338161  0.277755    0.0013612   0.06093901  0.01014907\n",
            "  0.1790346   0.13674448  0.10152229  0.17231934  0.14036984  0.12988982\n",
            "  0.12973822 -0.04796749 -0.14118647  0.19159083  0.06645419  0.20223961\n",
            " -0.08073097  0.20128622  0.09009025  0.05884968  0.22155561  0.21908222\n",
            "  0.08472667  0.09225795  0.01469866  0.00555609  0.0769812   0.20177985\n",
            "  0.13427358 -0.01161185  0.09210276  0.1362235   0.23452617  0.118472\n",
            "  0.07098707  0.14433339  0.17427174  0.04054582  0.05910838  0.12904352\n",
            "  0.17010576  0.15559961  0.12907628  0.19483369]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884, 1.0217537216677286]\n",
            "Epoch - 38 starting.....\n",
            "Predicted Output from the Adaline Model in the 38 th step is as follows: [0.1292187  0.15066737 0.1236684  0.15486553 0.12268635 0.1717551\n",
            " 0.1339648  0.14648157 0.1475885  0.15184618 0.13809761 0.15721209\n",
            " 0.14124053 0.0914284  0.08791087 0.12403979 0.11601806 0.13704367\n",
            " 0.17366622 0.13618648 0.18075757 0.14894193 0.06054183 0.20435734\n",
            " 0.19901486 0.18013776 0.17606577 0.14475483 0.13575105 0.16547118\n",
            " 0.17200353 0.16853899 0.10734697 0.10111281 0.15184618 0.11453976\n",
            " 0.12169193 0.15184618 0.12872376 0.14808344 0.12150754 0.17266397\n",
            " 0.11886279 0.18678522 0.19974849 0.15689047 0.14229577 0.13600079\n",
            " 0.13649574 0.13747779 0.97925228 0.82846768 0.96162455 0.88846239\n",
            " 0.94590404 1.06717372 0.72465631 1.00202091 0.94246032 0.99281193\n",
            " 0.82285333 0.86594742 0.90108191 0.83061748 0.86266203 0.87259488\n",
            " 0.87280139 1.05109096 1.14595023 0.81108969 0.93634127 0.8002899\n",
            " 1.08474584 0.80078354 0.91255711 0.94382482 0.78031693 0.78278836\n",
            " 0.91846965 0.91016733 0.98850971 0.99684199 0.92629462 0.80024668\n",
            " 0.86875022 1.01475423 0.91075979 0.86626904 0.76725223 0.88381904\n",
            " 0.93195872 0.8576662  0.82846768 0.96260792 0.94385698 0.8733272\n",
            " 0.83240373 0.84664855 0.87346444 0.80745313]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.1292187  -0.15066737 -0.1236684  -0.15486553 -0.12268635 -0.1717551\n",
            " -0.1339648  -0.14648157 -0.1475885  -0.15184618 -0.13809761 -0.15721209\n",
            " -0.14124053 -0.0914284  -0.08791087 -0.12403979 -0.11601806 -0.13704367\n",
            " -0.17366622 -0.13618648 -0.18075757 -0.14894193 -0.06054183 -0.20435734\n",
            " -0.19901486 -0.18013776 -0.17606577 -0.14475483 -0.13575105 -0.16547118\n",
            " -0.17200353 -0.16853899 -0.10734697 -0.10111281 -0.15184618 -0.11453976\n",
            " -0.12169193 -0.15184618 -0.12872376 -0.14808344 -0.12150754 -0.17266397\n",
            " -0.11886279 -0.18678522 -0.19974849 -0.15689047 -0.14229577 -0.13600079\n",
            " -0.13649574 -0.13747779  0.02074772  0.17153232  0.03837545  0.11153761\n",
            "  0.05409596 -0.06717372  0.27534369 -0.00202091  0.05753968  0.00718807\n",
            "  0.17714667  0.13405258  0.09891809  0.16938252  0.13733797  0.12740512\n",
            "  0.12719861 -0.05109096 -0.14595023  0.18891031  0.06365873  0.1997101\n",
            " -0.08474584  0.19921646  0.08744289  0.05617518  0.21968307  0.21721164\n",
            "  0.08153035  0.08983267  0.01149029  0.00315801  0.07370538  0.19975332\n",
            "  0.13124978 -0.01475423  0.08924021  0.13373096  0.23274777  0.11618096\n",
            "  0.06804128  0.1423338   0.17153232  0.03739208  0.05614302  0.1266728\n",
            "  0.16759627  0.15335145  0.12653556  0.19254687]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884, 1.0217537216677286, 0.9786398695092615]\n",
            "Epoch - 39 starting.....\n",
            "Predicted Output from the Adaline Model in the 39 th step is as follows: [0.12475892 0.14682845 0.11959323 0.15123927 0.11818118 0.16731068\n",
            " 0.12996525 0.14232521 0.14413263 0.1479739  0.13341116 0.15331377\n",
            " 0.1373807  0.08741348 0.08225786 0.11862724 0.11099169 0.13266108\n",
            " 0.16907745 0.13164439 0.17666709 0.14457869 0.05567981 0.20076893\n",
            " 0.19555301 0.17653354 0.17220928 0.14038426 0.13133666 0.16183247\n",
            " 0.16841021 0.16431191 0.10228922 0.09571628 0.1479739  0.11015026\n",
            " 0.11686155 0.1479739  0.12502073 0.14387081 0.11703573 0.16969351\n",
            " 0.11495644 0.18298146 0.19586553 0.15318502 0.13782197 0.13212738\n",
            " 0.13186556 0.13327761 0.9827884  0.83112261 0.9645612  0.89128287\n",
            " 0.94911005 1.07084741 0.72699375 1.00529705 0.94575333 0.99568206\n",
            " 0.82468321 0.86855567 0.90360543 0.83346372 0.86560127 0.87500359\n",
            " 0.87526217 1.05411775 1.15056515 0.81368614 0.93905055 0.80274194\n",
            " 1.08863488 0.80278893 0.91512289 0.94641577 0.78213144 0.7846013\n",
            " 0.92156709 0.91251625 0.99161745 0.99916537 0.92946925 0.8022098\n",
            " 0.87167947 1.01779859 0.9135351  0.86868443 0.76897596 0.88603913\n",
            " 0.93481392 0.85960421 0.83112261 0.96566445 0.94673154 0.87562492\n",
            " 0.83483513 0.84882725 0.87592785 0.80966961]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.12475892 -0.14682845 -0.11959323 -0.15123927 -0.11818118 -0.16731068\n",
            " -0.12996525 -0.14232521 -0.14413263 -0.1479739  -0.13341116 -0.15331377\n",
            " -0.1373807  -0.08741348 -0.08225786 -0.11862724 -0.11099169 -0.13266108\n",
            " -0.16907745 -0.13164439 -0.17666709 -0.14457869 -0.05567981 -0.20076893\n",
            " -0.19555301 -0.17653354 -0.17220928 -0.14038426 -0.13133666 -0.16183247\n",
            " -0.16841021 -0.16431191 -0.10228922 -0.09571628 -0.1479739  -0.11015026\n",
            " -0.11686155 -0.1479739  -0.12502073 -0.14387081 -0.11703573 -0.16969351\n",
            " -0.11495644 -0.18298146 -0.19586553 -0.15318502 -0.13782197 -0.13212738\n",
            " -0.13186556 -0.13327761  0.0172116   0.16887739  0.0354388   0.10871713\n",
            "  0.05088995 -0.07084741  0.27300625 -0.00529705  0.05424667  0.00431794\n",
            "  0.17531679  0.13144433  0.09639457  0.16653628  0.13439873  0.12499641\n",
            "  0.12473783 -0.05411775 -0.15056515  0.18631386  0.06094945  0.19725806\n",
            " -0.08863488  0.19721107  0.08487711  0.05358423  0.21786856  0.2153987\n",
            "  0.07843291  0.08748375  0.00838255  0.00083463  0.07053075  0.1977902\n",
            "  0.12832053 -0.01779859  0.0864649   0.13131557  0.23102404  0.11396087\n",
            "  0.06518608  0.14039579  0.16887739  0.03433555  0.05326846  0.12437508\n",
            "  0.16516487  0.15117275  0.12407215  0.19033039]\n",
            "Current value for the Loss value is :: [29.313307773211772, 10.352455180882572, 7.18491081039435, 6.386206794096211, 5.959604088866835, 5.60708408473625, 5.283203842134933, 4.980133608439789, 4.695700092022237, 4.428632350334601, 4.17785137463998, 3.9423609671253255, 3.7212282103448575, 3.5135774557285795, 3.3185865111572497, 3.1354833334152894, 2.9635429628385785, 2.8020846509179607, 2.6504691639676743, 2.5080962513599667, 2.3744022681768002, 2.2488579428448134, 2.1309662809094, 2.0202605966451963, 1.916302664706957, 1.818680984500234, 1.72700915039779, 1.6409243213467986, 1.5600857838056141, 1.4841736023184702, 1.4128873523836123, 1.345944930596257, 1.2830814373538622, 1.224048127698555, 1.1686114261414418, 1.1165520015669221, 1.0676638985530884, 1.0217537216677286, 0.9786398695092615, 0.9381518154589633]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Adaline - Learning rate 0.0001')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Plot the decision regions of the Adaline Model"
      ],
      "metadata": {
        "id": "gDmtXQzCTOFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_decision_boundary(X, y, weight):\n",
        "    # Labels and colors for the two classes\n",
        "    labels = ['Iris-setosa', 'Iris-virginica']\n",
        "    colors = ['blue', 'red']\n",
        "\n",
        "    for i, label in enumerate(np.unique(y)):\n",
        "        plt.scatter(X[y == label, 0], X[y == label, 1], c=colors[i], label=labels[i], marker='o', edgecolor='k', s=50)\n",
        "\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01), np.arange(x2_min, x2_max, 0.01))\n",
        "\n",
        "    grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
        "    grid_with_bias = np.insert(grid, 0, 1, axis=1)\n",
        "\n",
        "    Z = predict(net_input(grid_with_bias, weight), weight)\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "\n",
        "    # Plotting the decision boundary\n",
        "    plt.contourf(xx1, xx2, Z, alpha=0.2, levels=[-1, 0, 1], colors=['#0000FF40', '#FF000040'])\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "    plt.xlabel('Sepal length')\n",
        "    plt.ylabel('Petal length')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gq3eTtnYcSs1"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_reduced = X[:, [0, 2]]\n",
        "weight, loss = fit(X_reduced, y)\n",
        "plot_decision_boundary(X_reduced, y, weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DhBN9mwWTYdB",
        "outputId": "7eec387f-e43b-450c-f37e-6d3bd60c1ca3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch - 0 starting.....\n",
            "Predicted Output from the Adaline Model in the 0 th step is as follows: [-0.02235053 -0.02112702 -0.01937533 -0.01981992 -0.02173877 -0.02577031\n",
            " -0.01929175 -0.02226694 -0.01806823 -0.02165519 -0.02471397 -0.0215716\n",
            " -0.02051526 -0.01587196 -0.02557648 -0.02654924 -0.02365763 -0.02235053\n",
            " -0.02760558 -0.0228787  -0.02577031 -0.0228787  -0.01717906 -0.02393504\n",
            " -0.02315612 -0.02279512 -0.02279512 -0.02349046 -0.02296228 -0.02095985\n",
            " -0.0215716  -0.02471397 -0.02349046 -0.02479755 -0.02165519 -0.02068243\n",
            " -0.02426938 -0.02165519 -0.01754006 -0.0228787  -0.0212106  -0.01815182\n",
            " -0.01754006 -0.02279512 -0.02499139 -0.02051526 -0.02340687 -0.01929175\n",
            " -0.02410221 -0.02173877 -0.05398751 -0.04617518 -0.05835339 -0.05187482\n",
            " -0.05415467 -0.06510937 -0.03750034 -0.06168958 -0.05537819 -0.06002149\n",
            " -0.05045747 -0.05090206 -0.05440543 -0.04503525 -0.04617518 -0.05090206\n",
            " -0.05257016 -0.0662493  -0.06730564 -0.04687052 -0.05607353 -0.04389532\n",
            " -0.0662493  -0.04817762 -0.05485002 -0.05949331 -0.04703769 -0.0469541\n",
            " -0.05248657 -0.05843697 -0.061245   -0.0658883  -0.05248657 -0.04923396\n",
            " -0.05065131 -0.06308027 -0.05187482 -0.0519584  -0.04581418 -0.05448901\n",
            " -0.05432184 -0.0529045  -0.04617518 -0.05651812 -0.05485002 -0.05220916\n",
            " -0.04870579 -0.05098564 -0.05020672 -0.04678693]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [0.02235053 0.02112702 0.01937533 0.01981992 0.02173877 0.02577031\n",
            " 0.01929175 0.02226694 0.01806823 0.02165519 0.02471397 0.0215716\n",
            " 0.02051526 0.01587196 0.02557648 0.02654924 0.02365763 0.02235053\n",
            " 0.02760558 0.0228787  0.02577031 0.0228787  0.01717906 0.02393504\n",
            " 0.02315612 0.02279512 0.02279512 0.02349046 0.02296228 0.02095985\n",
            " 0.0215716  0.02471397 0.02349046 0.02479755 0.02165519 0.02068243\n",
            " 0.02426938 0.02165519 0.01754006 0.0228787  0.0212106  0.01815182\n",
            " 0.01754006 0.02279512 0.02499139 0.02051526 0.02340687 0.01929175\n",
            " 0.02410221 0.02173877 1.05398751 1.04617518 1.05835339 1.05187482\n",
            " 1.05415467 1.06510937 1.03750034 1.06168958 1.05537819 1.06002149\n",
            " 1.05045747 1.05090206 1.05440543 1.04503525 1.04617518 1.05090206\n",
            " 1.05257016 1.0662493  1.06730564 1.04687052 1.05607353 1.04389532\n",
            " 1.0662493  1.04817762 1.05485002 1.05949331 1.04703769 1.0469541\n",
            " 1.05248657 1.05843697 1.061245   1.0658883  1.05248657 1.04923396\n",
            " 1.05065131 1.06308027 1.05187482 1.0519584  1.04581418 1.05448901\n",
            " 1.05432184 1.0529045  1.04617518 1.05651812 1.05485002 1.05220916\n",
            " 1.04870579 1.05098564 1.05020672 1.04678693]\n",
            "Current value for the Loss value is :: [27.753846092917033]\n",
            "Epoch - 1 starting.....\n",
            "Predicted Output from the Adaline Model in the 1 th step is as follows: [0.20412567 0.19829397 0.19004824 0.19196045 0.20120982 0.22011531\n",
            " 0.18954642 0.20362385 0.18371472 0.200708   0.21528724 0.20020618\n",
            " 0.19537812 0.17355678 0.21970855 0.22403479 0.21045918 0.20412567\n",
            " 0.22886285 0.2065397  0.22011531 0.2065397  0.1798903  0.21136776\n",
            " 0.20744827 0.20603788 0.20603788 0.20945555 0.20704152 0.19729033\n",
            " 0.20020618 0.21528724 0.20945555 0.21578906 0.200708   0.19638176\n",
            " 0.21337503 0.200708   0.18130069 0.2065397  0.19879579 0.18421654\n",
            " 0.18130069 0.20603788 0.21619582 0.19537812 0.20895373 0.18954642\n",
            " 0.21237139 0.20120982 0.35016127 0.31385574 0.37107403 0.34050514\n",
            " 0.3511649  0.40255149 0.27312892 0.38656185 0.3569966  0.37881794\n",
            " 0.33426669 0.3361789  0.35267036 0.30852587 0.31385574 0.3361789\n",
            " 0.34392281 0.40788137 0.41270943 0.31727341 0.36041427 0.30319599\n",
            " 0.40788137 0.32360693 0.35458257 0.37640391 0.31827705 0.31777523\n",
            " 0.34342099 0.37157585 0.38464964 0.40647097 0.34342099 0.32843499\n",
            " 0.33467345 0.39339718 0.34050514 0.34100696 0.31244535 0.35317218\n",
            " 0.35216854 0.34593008 0.31385574 0.36232648 0.35458257 0.34251242\n",
            " 0.32602096 0.33668072 0.33276123 0.31677159]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.20412567 -0.19829397 -0.19004824 -0.19196045 -0.20120982 -0.22011531\n",
            " -0.18954642 -0.20362385 -0.18371472 -0.200708   -0.21528724 -0.20020618\n",
            " -0.19537812 -0.17355678 -0.21970855 -0.22403479 -0.21045918 -0.20412567\n",
            " -0.22886285 -0.2065397  -0.22011531 -0.2065397  -0.1798903  -0.21136776\n",
            " -0.20744827 -0.20603788 -0.20603788 -0.20945555 -0.20704152 -0.19729033\n",
            " -0.20020618 -0.21528724 -0.20945555 -0.21578906 -0.200708   -0.19638176\n",
            " -0.21337503 -0.200708   -0.18130069 -0.2065397  -0.19879579 -0.18421654\n",
            " -0.18130069 -0.20603788 -0.21619582 -0.19537812 -0.20895373 -0.18954642\n",
            " -0.21237139 -0.20120982  0.64983873  0.68614426  0.62892597  0.65949486\n",
            "  0.6488351   0.59744851  0.72687108  0.61343815  0.6430034   0.62118206\n",
            "  0.66573331  0.6638211   0.64732964  0.69147413  0.68614426  0.6638211\n",
            "  0.65607719  0.59211863  0.58729057  0.68272659  0.63958573  0.69680401\n",
            "  0.59211863  0.67639307  0.64541743  0.62359609  0.68172295  0.68222477\n",
            "  0.65657901  0.62842415  0.61535036  0.59352903  0.65657901  0.67156501\n",
            "  0.66532655  0.60660282  0.65949486  0.65899304  0.68755465  0.64682782\n",
            "  0.64783146  0.65406992  0.68614426  0.63767352  0.64541743  0.65748758\n",
            "  0.67397904  0.66331928  0.66723877  0.68322841]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673]\n",
            "Epoch - 2 starting.....\n",
            "Predicted Output from the Adaline Model in the 2 th step is as follows: [0.31261525 0.30352502 0.29036716 0.2939573  0.30807014 0.33845348\n",
            " 0.28988967 0.31213776 0.28079944 0.30759265 0.33031823 0.30711516\n",
            " 0.2989799  0.26405145 0.33629581 0.34395357 0.32218297 0.31261525\n",
            " 0.35208883 0.31668288 0.33845348 0.31668288 0.27361917 0.32481813\n",
            " 0.31931803 0.31620539 0.31620539 0.32122799 0.31716037 0.30257004\n",
            " 0.30711516 0.33031823 0.32122799 0.33079572 0.30759265 0.29993488\n",
            " 0.32672809 0.30759265 0.27673181 0.31668288 0.30400251 0.28127693\n",
            " 0.27673181 0.31620539 0.33295338 0.2989799  0.3207505  0.28988967\n",
            " 0.32577311 0.30807014 0.55426743 0.49493322 0.58656073 0.53799693\n",
            " 0.55522241 0.63775969 0.42962142 0.61192147 0.56431264 0.5992411\n",
            " 0.52674903 0.53033917 0.55665488 0.48632048 0.49493322 0.53033917\n",
            " 0.54301953 0.64637244 0.65450769 0.49995582 0.56933525 0.47770773\n",
            " 0.64637244 0.50952355 0.56024502 0.59517347 0.5009108  0.50043331\n",
            " 0.54254204 0.58703822 0.60833133 0.64325979 0.54254204 0.5176588\n",
            " 0.52890669 0.62196668 0.53799693 0.53847442 0.49182057 0.55713237\n",
            " 0.55617739 0.54492949 0.49493322 0.57292538 0.56024502 0.53990689\n",
            " 0.51359117 0.53081666 0.52531656 0.49947833]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.31261525 -0.30352502 -0.29036716 -0.2939573  -0.30807014 -0.33845348\n",
            " -0.28988967 -0.31213776 -0.28079944 -0.30759265 -0.33031823 -0.30711516\n",
            " -0.2989799  -0.26405145 -0.33629581 -0.34395357 -0.32218297 -0.31261525\n",
            " -0.35208883 -0.31668288 -0.33845348 -0.31668288 -0.27361917 -0.32481813\n",
            " -0.31931803 -0.31620539 -0.31620539 -0.32122799 -0.31716037 -0.30257004\n",
            " -0.30711516 -0.33031823 -0.32122799 -0.33079572 -0.30759265 -0.29993488\n",
            " -0.32672809 -0.30759265 -0.27673181 -0.31668288 -0.30400251 -0.28127693\n",
            " -0.27673181 -0.31620539 -0.33295338 -0.2989799  -0.3207505  -0.28988967\n",
            " -0.32577311 -0.30807014  0.44573257  0.50506678  0.41343927  0.46200307\n",
            "  0.44477759  0.36224031  0.57037858  0.38807853  0.43568736  0.4007589\n",
            "  0.47325097  0.46966083  0.44334512  0.51367952  0.50506678  0.46966083\n",
            "  0.45698047  0.35362756  0.34549231  0.50004418  0.43066475  0.52229227\n",
            "  0.35362756  0.49047645  0.43975498  0.40482653  0.4990892   0.49956669\n",
            "  0.45745796  0.41296178  0.39166867  0.35674021  0.45745796  0.4823412\n",
            "  0.47109331  0.37803332  0.46200307  0.46152558  0.50817943  0.44286763\n",
            "  0.44382261  0.45507051  0.50506678  0.42707462  0.43975498  0.46009311\n",
            "  0.48640883  0.46918334  0.47468344  0.50052167]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465]\n",
            "Epoch - 3 starting.....\n",
            "Predicted Output from the Adaline Model in the 3 th step is as follows: [0.36258215 0.35211449 0.336569   0.34149083 0.35734832 0.39351713\n",
            " 0.336413   0.36242615 0.32594534 0.35719232 0.38336147 0.35703632\n",
            " 0.34688066 0.30547801 0.3890633  0.39906296 0.37320581 0.36258215\n",
            " 0.40921862 0.36765998 0.39351713 0.36765998 0.31610167 0.37781564\n",
            " 0.37226981 0.36750398 0.36750398 0.37289381 0.36781598 0.35180249\n",
            " 0.35703632 0.38336147 0.37289381 0.38351747 0.35719232 0.34719266\n",
            " 0.37843964 0.35719232 0.32086751 0.36765998 0.35227049 0.32610134\n",
            " 0.32086751 0.36750398 0.3879713  0.34688066 0.37273781 0.336413\n",
            " 0.37812764 0.35734832 0.65896835 0.58709871 0.69576116 0.63865702\n",
            " 0.65928034 0.75747513 0.50952725 0.72654014 0.669748   0.71115065\n",
            " 0.62373553 0.62865736 0.65974834 0.57678705 0.58709871 0.62865736\n",
            " 0.64404685 0.76778679 0.77794245 0.59248854 0.67513783 0.56647539\n",
            " 0.76778679 0.6031122  0.66467017 0.70607282 0.59280054 0.59264454\n",
            " 0.64389085 0.69591716 0.72161831 0.76302096 0.64389085 0.61326787\n",
            " 0.62818936 0.7373198  0.63865702 0.63881302 0.58233288 0.65990434\n",
            " 0.65959234 0.64467085 0.58709871 0.68005967 0.66467017 0.63928102\n",
            " 0.60819003 0.62881336 0.62326753 0.59233254]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.36258215 -0.35211449 -0.336569   -0.34149083 -0.35734832 -0.39351713\n",
            " -0.336413   -0.36242615 -0.32594534 -0.35719232 -0.38336147 -0.35703632\n",
            " -0.34688066 -0.30547801 -0.3890633  -0.39906296 -0.37320581 -0.36258215\n",
            " -0.40921862 -0.36765998 -0.39351713 -0.36765998 -0.31610167 -0.37781564\n",
            " -0.37226981 -0.36750398 -0.36750398 -0.37289381 -0.36781598 -0.35180249\n",
            " -0.35703632 -0.38336147 -0.37289381 -0.38351747 -0.35719232 -0.34719266\n",
            " -0.37843964 -0.35719232 -0.32086751 -0.36765998 -0.35227049 -0.32610134\n",
            " -0.32086751 -0.36750398 -0.3879713  -0.34688066 -0.37273781 -0.336413\n",
            " -0.37812764 -0.35734832  0.34103165  0.41290129  0.30423884  0.36134298\n",
            "  0.34071966  0.24252487  0.49047275  0.27345986  0.330252    0.28884935\n",
            "  0.37626447  0.37134264  0.34025166  0.42321295  0.41290129  0.37134264\n",
            "  0.35595315  0.23221321  0.22205755  0.40751146  0.32486217  0.43352461\n",
            "  0.23221321  0.3968878   0.33532983  0.29392718  0.40719946  0.40735546\n",
            "  0.35610915  0.30408284  0.27838169  0.23697904  0.35610915  0.38673213\n",
            "  0.37181064  0.2626802   0.36134298  0.36118698  0.41766712  0.34009566\n",
            "  0.34040766  0.35532915  0.41290129  0.31994033  0.33532983  0.36071898\n",
            "  0.39180997  0.37118664  0.37673247  0.40766746]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542]\n",
            "Epoch - 4 starting.....\n",
            "Predicted Output from the Adaline Model in the 4 th step is as follows: [0.38355581 0.3726406  0.35596026 0.36203293 0.37809821 0.41722402\n",
            " 0.35626779 0.38386334 0.34535258 0.37840574 0.40569376 0.37871327\n",
            " 0.367183   0.32259958 0.41022877 0.42206657 0.39416349 0.38355581\n",
            " 0.43359684 0.38932095 0.41722402 0.38932095 0.33320726 0.40085121\n",
            " 0.39600867 0.38962848 0.38962848 0.39477855 0.38901341 0.37325566\n",
            " 0.37871327 0.40569376 0.39477855 0.40538623 0.37840574 0.36656794\n",
            " 0.39962109 0.37840574 0.33958745 0.38932095 0.37233307 0.34504505\n",
            " 0.33958745 0.38962848 0.41238148 0.367183   0.39508608 0.35626779\n",
            " 0.40023615 0.37809821 0.71424323 0.635069   0.75213892 0.69118269\n",
            " 0.71362817 0.81978288 0.55135976 0.78611467 0.72454338 0.7691268\n",
            " 0.67327223 0.67934489 0.71270558 0.62384626 0.635069   0.67934489\n",
            " 0.69633277 0.83100562 0.84253589 0.64021908 0.72969345 0.61262353\n",
            " 0.83100562 0.65082675 0.71877824 0.76336166 0.63960401 0.63991155\n",
            " 0.6966403  0.75183139 0.780042   0.82462543 0.6966403  0.66235702\n",
            " 0.68026748 0.79641482 0.69118269 0.69087516 0.62868881 0.71239805\n",
            " 0.71301311 0.69510264 0.635069   0.73576611 0.71877824 0.68995257\n",
            " 0.65659189 0.67903736 0.67419482 0.64052661]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38355581 -0.3726406  -0.35596026 -0.36203293 -0.37809821 -0.41722402\n",
            " -0.35626779 -0.38386334 -0.34535258 -0.37840574 -0.40569376 -0.37871327\n",
            " -0.367183   -0.32259958 -0.41022877 -0.42206657 -0.39416349 -0.38355581\n",
            " -0.43359684 -0.38932095 -0.41722402 -0.38932095 -0.33320726 -0.40085121\n",
            " -0.39600867 -0.38962848 -0.38962848 -0.39477855 -0.38901341 -0.37325566\n",
            " -0.37871327 -0.40569376 -0.39477855 -0.40538623 -0.37840574 -0.36656794\n",
            " -0.39962109 -0.37840574 -0.33958745 -0.38932095 -0.37233307 -0.34504505\n",
            " -0.33958745 -0.38962848 -0.41238148 -0.367183   -0.39508608 -0.35626779\n",
            " -0.40023615 -0.37809821  0.28575677  0.364931    0.24786108  0.30881731\n",
            "  0.28637183  0.18021712  0.44864024  0.21388533  0.27545662  0.2308732\n",
            "  0.32672777  0.32065511  0.28729442  0.37615374  0.364931    0.32065511\n",
            "  0.30366723  0.16899438  0.15746411  0.35978092  0.27030655  0.38737647\n",
            "  0.16899438  0.34917325  0.28122176  0.23663834  0.36039599  0.36008845\n",
            "  0.3033597   0.24816861  0.219958    0.17537457  0.3033597   0.33764298\n",
            "  0.31973252  0.20358518  0.30881731  0.30912484  0.37131119  0.28760195\n",
            "  0.28698689  0.30489736  0.364931    0.26423389  0.28122176  0.31004743\n",
            "  0.34340811  0.32096264  0.32580518  0.35947339]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766]\n",
            "Epoch - 5 starting.....\n",
            "Predicted Output from the Adaline Model in the 5 th step is as follows: [0.39019978 0.37929459 0.36210065 0.36922556 0.38474719 0.42542383\n",
            " 0.36293681 0.39103594 0.35203162 0.38558335 0.41284632 0.38641951\n",
            " 0.373842   0.32771276 0.41579044 0.4292041  0.40026881 0.39019978\n",
            " 0.44178161 0.39648854 0.42542383 0.39648854 0.33778179 0.40906605\n",
            " 0.40528577 0.3973247  0.3973247  0.40194113 0.39565238 0.38096691\n",
            " 0.38641951 0.41284632 0.40194113 0.41201016 0.38558335 0.37216968\n",
            " 0.40572141 0.38558335 0.34574287 0.39648854 0.37845843 0.35119546\n",
            " 0.34574287 0.3973247  0.42164356 0.373842   0.40277729 0.36293681\n",
            " 0.40739373 0.38474719 0.74491363 0.66105186 0.78224563 0.71975861\n",
            " 0.74324131 0.85352988 0.57424599 0.81830584 0.7541465  0.80027573\n",
            " 0.69922003 0.70634494 0.74073283 0.64931051 0.66105186 0.70634494\n",
            " 0.72437504 0.86527123 0.87784874 0.6656683  0.75876293 0.63756917\n",
            " 0.86527123 0.67573733 0.74785774 0.79398698 0.66399598 0.66483214\n",
            " 0.7252112  0.78140947 0.81118092 0.85731016 0.7252112  0.68831484\n",
            " 0.70885342 0.82753871 0.71975861 0.71892245 0.65309079 0.73989667\n",
            " 0.74156899 0.7210304  0.66105186 0.76588785 0.74785774 0.71641397\n",
            " 0.68202608 0.70550878 0.70172851 0.66650446]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.39019978 -0.37929459 -0.36210065 -0.36922556 -0.38474719 -0.42542383\n",
            " -0.36293681 -0.39103594 -0.35203162 -0.38558335 -0.41284632 -0.38641951\n",
            " -0.373842   -0.32771276 -0.41579044 -0.4292041  -0.40026881 -0.39019978\n",
            " -0.44178161 -0.39648854 -0.42542383 -0.39648854 -0.33778179 -0.40906605\n",
            " -0.40528577 -0.3973247  -0.3973247  -0.40194113 -0.39565238 -0.38096691\n",
            " -0.38641951 -0.41284632 -0.40194113 -0.41201016 -0.38558335 -0.37216968\n",
            " -0.40572141 -0.38558335 -0.34574287 -0.39648854 -0.37845843 -0.35119546\n",
            " -0.34574287 -0.3973247  -0.42164356 -0.373842   -0.40277729 -0.36293681\n",
            " -0.40739373 -0.38474719  0.25508637  0.33894814  0.21775437  0.28024139\n",
            "  0.25675869  0.14647012  0.42575401  0.18169416  0.2458535   0.19972427\n",
            "  0.30077997  0.29365506  0.25926717  0.35068949  0.33894814  0.29365506\n",
            "  0.27562496  0.13472877  0.12215126  0.3343317   0.24123707  0.36243083\n",
            "  0.13472877  0.32426267  0.25214226  0.20601302  0.33600402  0.33516786\n",
            "  0.2747888   0.21859053  0.18881908  0.14268984  0.2747888   0.31168516\n",
            "  0.29114658  0.17246129  0.28024139  0.28107755  0.34690921  0.26010333\n",
            "  0.25843101  0.2789696   0.33894814  0.23411215  0.25214226  0.28358603\n",
            "  0.31797392  0.29449122  0.29827149  0.33349554]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365]\n",
            "Epoch - 6 starting.....\n",
            "Predicted Output from the Adaline Model in the 6 th step is as follows: [0.38979498 0.37912289 0.36172298 0.36984258 0.38445894 0.42598658\n",
            " 0.36311476 0.39118676 0.35244267 0.38585071 0.41253094 0.38724249\n",
            " 0.37378685 0.32692316 0.41369165 0.42853907 0.39907529 0.38979498\n",
            " 0.44199472 0.3965228  0.42598658 0.3965228  0.33620347 0.40997845\n",
            " 0.40742596 0.39791458 0.39791458 0.40185885 0.39513103 0.38190645\n",
            " 0.38724249 0.41253094 0.40185885 0.41113916 0.38585071 0.37100329\n",
            " 0.40441134 0.38585071 0.34571485 0.3965228  0.37773111 0.35105089\n",
            " 0.34571485 0.39791458 0.4234341  0.37378685 0.40325063 0.36311476\n",
            " 0.40719489 0.38445894 0.76330737 0.67607674 0.79926791 0.73639608\n",
            " 0.76052382 0.87304289 0.5876854  0.83685129 0.7711959  0.8180596\n",
            " 0.71342906 0.72154866 0.75634848 0.66401287 0.67607674 0.72154866\n",
            " 0.74034035 0.88510676 0.8985624  0.68002101 0.77514017 0.65194901\n",
            " 0.88510676 0.68930132 0.76446808 0.81133177 0.67723745 0.67862923\n",
            " 0.74173213 0.79787613 0.82873169 0.87559538 0.74173213 0.70275697\n",
            " 0.72572399 0.84473982 0.73639608 0.7350043  0.66656536 0.7549567\n",
            " 0.75774026 0.73477323 0.67607674 0.78325977 0.76446808 0.73082897\n",
            " 0.69602914 0.72015688 0.71760439 0.68141279]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38979498 -0.37912289 -0.36172298 -0.36984258 -0.38445894 -0.42598658\n",
            " -0.36311476 -0.39118676 -0.35244267 -0.38585071 -0.41253094 -0.38724249\n",
            " -0.37378685 -0.32692316 -0.41369165 -0.42853907 -0.39907529 -0.38979498\n",
            " -0.44199472 -0.3965228  -0.42598658 -0.3965228  -0.33620347 -0.40997845\n",
            " -0.40742596 -0.39791458 -0.39791458 -0.40185885 -0.39513103 -0.38190645\n",
            " -0.38724249 -0.41253094 -0.40185885 -0.41113916 -0.38585071 -0.37100329\n",
            " -0.40441134 -0.38585071 -0.34571485 -0.3965228  -0.37773111 -0.35105089\n",
            " -0.34571485 -0.39791458 -0.4234341  -0.37378685 -0.40325063 -0.36311476\n",
            " -0.40719489 -0.38445894  0.23669263  0.32392326  0.20073209  0.26360392\n",
            "  0.23947618  0.12695711  0.4123146   0.16314871  0.2288041   0.1819404\n",
            "  0.28657094  0.27845134  0.24365152  0.33598713  0.32392326  0.27845134\n",
            "  0.25965965  0.11489324  0.1014376   0.31997899  0.22485983  0.34805099\n",
            "  0.11489324  0.31069868  0.23553192  0.18866823  0.32276255  0.32137077\n",
            "  0.25826787  0.20212387  0.17126831  0.12440462  0.25826787  0.29724303\n",
            "  0.27427601  0.15526018  0.26360392  0.2649957   0.33343464  0.2450433\n",
            "  0.24225974  0.26522677  0.32392326  0.21674023  0.23553192  0.26917103\n",
            "  0.30397086  0.27984312  0.28239561  0.31858721]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798]\n",
            "Epoch - 7 starting.....\n",
            "Predicted Output from the Adaline Model in the 7 th step is as follows: [0.38595602 0.37562373 0.35816976 0.36724701 0.38078987 0.42281953\n",
            " 0.36012531 0.38791157 0.34979303 0.38274543 0.40857613 0.38470098\n",
            " 0.37045759 0.3232618  0.40787561 0.42407456 0.39433274 0.38595602\n",
            " 0.43831795 0.39307771 0.42281953 0.39307771 0.33163853 0.4073211\n",
            " 0.40606607 0.39503327 0.39503327 0.39824385 0.39112216 0.37953484\n",
            " 0.38470098 0.40857613 0.39824385 0.40662058 0.38274543 0.36654648\n",
            " 0.39949889 0.38274543 0.34267133 0.39307771 0.37366818 0.34783747\n",
            " 0.34267133 0.39503327 0.42156449 0.37045759 0.40019941 0.36012531\n",
            " 0.40340999 0.38078987 0.77554769 0.68562173 0.80975513 0.74706091\n",
            " 0.77163659 0.8854377  0.59639629 0.84857419 0.78196887 0.82916466\n",
            " 0.72178472 0.73086197 0.76576992 0.67333389 0.68562173 0.73086197\n",
            " 0.7502715  0.89772554 0.91196893 0.68883232 0.78517945 0.66104606\n",
            " 0.89772554 0.69720905 0.77484717 0.82204296 0.68492121 0.68687676\n",
            " 0.75222705 0.80779957 0.83949694 0.88669273 0.75222705 0.71145244\n",
            " 0.73672863 0.85499536 0.74706091 0.74510536 0.67458893 0.76381437\n",
            " 0.76772548 0.74244928 0.68562173 0.7942567  0.77484717 0.7392387\n",
            " 0.70433074 0.72890641 0.72765138 0.69078787]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38595602 -0.37562373 -0.35816976 -0.36724701 -0.38078987 -0.42281953\n",
            " -0.36012531 -0.38791157 -0.34979303 -0.38274543 -0.40857613 -0.38470098\n",
            " -0.37045759 -0.3232618  -0.40787561 -0.42407456 -0.39433274 -0.38595602\n",
            " -0.43831795 -0.39307771 -0.42281953 -0.39307771 -0.33163853 -0.4073211\n",
            " -0.40606607 -0.39503327 -0.39503327 -0.39824385 -0.39112216 -0.37953484\n",
            " -0.38470098 -0.40857613 -0.39824385 -0.40662058 -0.38274543 -0.36654648\n",
            " -0.39949889 -0.38274543 -0.34267133 -0.39307771 -0.37366818 -0.34783747\n",
            " -0.34267133 -0.39503327 -0.42156449 -0.37045759 -0.40019941 -0.36012531\n",
            " -0.40340999 -0.38078987  0.22445231  0.31437827  0.19024487  0.25293909\n",
            "  0.22836341  0.1145623   0.40360371  0.15142581  0.21803113  0.17083534\n",
            "  0.27821528  0.26913803  0.23423008  0.32666611  0.31437827  0.26913803\n",
            "  0.2497285   0.10227446  0.08803107  0.31116768  0.21482055  0.33895394\n",
            "  0.10227446  0.30279095  0.22515283  0.17795704  0.31507879  0.31312324\n",
            "  0.24777295  0.19220043  0.16050306  0.11330727  0.24777295  0.28854756\n",
            "  0.26327137  0.14500464  0.25293909  0.25489464  0.32541107  0.23618563\n",
            "  0.23227452  0.25755072  0.31437827  0.2057433   0.22515283  0.2607613\n",
            "  0.29566926  0.27109359  0.27234862  0.30921213]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333]\n",
            "Epoch - 8 starting.....\n",
            "Predicted Output from the Adaline Model in the 8 th step is as follows: [0.38047677 0.37053328 0.35309982 0.36310802 0.37550503 0.41786192\n",
            " 0.35561805 0.382995   0.34567456 0.37802326 0.40288198 0.38054149\n",
            " 0.36556154 0.3182329  0.40029903 0.41779721 0.38790203 0.38047677\n",
            " 0.43277716 0.38796674 0.41786192 0.38796674 0.32565815 0.40294669\n",
            " 0.40301141 0.39048497 0.39048497 0.39293849 0.38544851 0.37556974\n",
            " 0.38054149 0.40288198 0.39293849 0.40036375 0.37802326 0.36052508\n",
            " 0.39287377 0.37802326 0.33818459 0.38796674 0.36801505 0.34315633\n",
            " 0.33818459 0.39048497 0.41792664 0.36556154 0.39545672 0.35561805\n",
            " 0.39791023 0.37550503 0.7846765  0.69240802 0.81696048 0.75471661\n",
            " 0.77964004 0.89424902 0.60272248 0.85686386 0.78958353 0.83691217\n",
            " 0.72721022 0.73721843 0.77208535 0.6799463  0.69240802 0.73721843\n",
            " 0.75717012 0.90671074 0.92169068 0.69486153 0.79203704 0.66748458\n",
            " 0.90671074 0.70228679 0.78209356 0.8294222  0.68982507 0.6923433\n",
            " 0.75968835 0.81444225 0.84685566 0.8941843  0.75968835 0.71726674\n",
            " 0.74477312 0.86177089 0.75471661 0.75219838 0.67988158 0.76956712\n",
            " 0.77460358 0.7470972  0.69240802 0.80204525 0.78209356 0.74464369\n",
            " 0.70977676 0.7347002  0.73476491 0.69737976]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.38047677 -0.37053328 -0.35309982 -0.36310802 -0.37550503 -0.41786192\n",
            " -0.35561805 -0.382995   -0.34567456 -0.37802326 -0.40288198 -0.38054149\n",
            " -0.36556154 -0.3182329  -0.40029903 -0.41779721 -0.38790203 -0.38047677\n",
            " -0.43277716 -0.38796674 -0.41786192 -0.38796674 -0.32565815 -0.40294669\n",
            " -0.40301141 -0.39048497 -0.39048497 -0.39293849 -0.38544851 -0.37556974\n",
            " -0.38054149 -0.40288198 -0.39293849 -0.40036375 -0.37802326 -0.36052508\n",
            " -0.39287377 -0.37802326 -0.33818459 -0.38796674 -0.36801505 -0.34315633\n",
            " -0.33818459 -0.39048497 -0.41792664 -0.36556154 -0.39545672 -0.35561805\n",
            " -0.39791023 -0.37550503  0.2153235   0.30759198  0.18303952  0.24528339\n",
            "  0.22035996  0.10575098  0.39727752  0.14313614  0.21041647  0.16308783\n",
            "  0.27278978  0.26278157  0.22791465  0.3200537   0.30759198  0.26278157\n",
            "  0.24282988  0.09328926  0.07830932  0.30513847  0.20796296  0.33251542\n",
            "  0.09328926  0.29771321  0.21790644  0.1705778   0.31017493  0.3076567\n",
            "  0.24031165  0.18555775  0.15314434  0.1058157   0.24031165  0.28273326\n",
            "  0.25522688  0.13822911  0.24528339  0.24780162  0.32011842  0.23043288\n",
            "  0.22539642  0.2529028   0.30759198  0.19795475  0.21790644  0.25535631\n",
            "  0.29022324  0.2652998   0.26523509  0.30262024]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961]\n",
            "Epoch - 9 starting.....\n",
            "Predicted Output from the Adaline Model in the 9 th step is as follows: [0.37424695 0.36471265 0.3473359  0.35825365 0.3694798  0.41207575\n",
            " 0.3504112  0.37732225 0.3408769  0.3725551  0.39639085 0.3756304\n",
            " 0.3599455  0.3125824  0.3919321  0.4106923  0.38070595 0.37424695\n",
            " 0.4263772  0.3820894  0.41207575 0.3820894  0.3190414  0.3977743\n",
            " 0.39915775 0.3851647  0.3851647  0.38685655 0.3790141  0.37086325\n",
            " 0.3756304  0.39639085 0.38685655 0.39331555 0.3725551  0.3537949\n",
            " 0.3854731  0.3725551  0.33303445 0.3820894  0.36163735 0.3378016\n",
            " 0.33303445 0.3851647  0.4134592  0.3599455  0.38993185 0.3504112\n",
            " 0.3916237  0.3694798  0.79220545 0.69778765 0.8225002  0.76083565\n",
            " 0.78605485 0.9012331  0.6078286  0.8634043  0.79558915 0.84295225\n",
            " 0.7311577  0.74207545 0.77682895 0.68517805 0.69778765 0.74207545\n",
            " 0.7625275  0.9138427  0.9295276  0.6994795  0.797281   0.67256845\n",
            " 0.9138427  0.7059385  0.7877467  0.8351098  0.6933289  0.6964042\n",
            " 0.7656028  0.8194249  0.85248655 0.89984965 0.7656028  0.7216234\n",
            " 0.75130135 0.866788   0.76083565 0.75776035 0.6837946  0.77375365\n",
            " 0.77990425 0.7502263  0.69778765 0.80819875 0.7877467  0.74853445\n",
            " 0.71378095 0.73900015 0.7403836  0.7025548 ]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.37424695 -0.36471265 -0.3473359  -0.35825365 -0.3694798  -0.41207575\n",
            " -0.3504112  -0.37732225 -0.3408769  -0.3725551  -0.39639085 -0.3756304\n",
            " -0.3599455  -0.3125824  -0.3919321  -0.4106923  -0.38070595 -0.37424695\n",
            " -0.4263772  -0.3820894  -0.41207575 -0.3820894  -0.3190414  -0.3977743\n",
            " -0.39915775 -0.3851647  -0.3851647  -0.38685655 -0.3790141  -0.37086325\n",
            " -0.3756304  -0.39639085 -0.38685655 -0.39331555 -0.3725551  -0.3537949\n",
            " -0.3854731  -0.3725551  -0.33303445 -0.3820894  -0.36163735 -0.3378016\n",
            " -0.33303445 -0.3851647  -0.4134592  -0.3599455  -0.38993185 -0.3504112\n",
            " -0.3916237  -0.3694798   0.20779455  0.30221235  0.1774998   0.23916435\n",
            "  0.21394515  0.0987669   0.3921714   0.1365957   0.20441085  0.15704775\n",
            "  0.2688423   0.25792455  0.22317105  0.31482195  0.30221235  0.25792455\n",
            "  0.2374725   0.0861573   0.0704724   0.3005205   0.202719    0.32743155\n",
            "  0.0861573   0.2940615   0.2122533   0.1648902   0.3066711   0.3035958\n",
            "  0.2343972   0.1805751   0.14751345  0.10015035  0.2343972   0.2783766\n",
            "  0.24869865  0.133212    0.23916435  0.24223965  0.3162054   0.22624635\n",
            "  0.22009575  0.2497737   0.30221235  0.19180125  0.2122533   0.25146555\n",
            "  0.28621905  0.26099985  0.2596164   0.2974452 ]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658]\n",
            "Epoch - 10 starting.....\n",
            "Predicted Output from the Adaline Model in the 10 th step is as follows: [0.36770724 0.3585884  0.34128551 0.35309417 0.36314782 0.40593764\n",
            " 0.34491013 0.37133186 0.33579128 0.36677244 0.38956955 0.37039706\n",
            " 0.35402897 0.30667973 0.38325512 0.40324782 0.37320147 0.36770724\n",
            " 0.41961591 0.37589129 0.40593764 0.37589129 0.31217396 0.39225937\n",
            " 0.39494918 0.3795159  0.3795159  0.38045071 0.37226667 0.36583763\n",
            " 0.37039706 0.38956955 0.38045071 0.38594494 0.36677244 0.34677974\n",
            " 0.37776089 0.36677244 0.32760724 0.37589129 0.35496378 0.33216666\n",
            " 0.32760724 0.3795159  0.40862745 0.35402897 0.38407533 0.34491013\n",
            " 0.38501013 0.36314782 0.79888624 0.70243275 0.82717758 0.76615007\n",
            " 0.791637   0.90726299 0.61229369 0.8690326  0.80075585 0.84810509\n",
            " 0.73434871 0.74615737 0.78076315 0.68968928 0.70243275 0.74615737\n",
            " 0.76708488 0.92000646 0.93637454 0.70336755 0.80169065 0.67694582\n",
            " 0.92000646 0.70886178 0.79257181 0.83992105 0.69611832 0.69974294\n",
            " 0.7707095  0.82355297 0.85722394 0.90457318 0.7707095  0.72522986\n",
            " 0.75703123 0.87090221 0.76615007 0.76252545 0.68699947 0.77713853\n",
            " 0.78438777 0.7525864  0.70243275 0.81349931 0.79257181 0.7516516\n",
            " 0.71704582 0.74253275 0.74522257 0.70699217]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.36770724 -0.3585884  -0.34128551 -0.35309417 -0.36314782 -0.40593764\n",
            " -0.34491013 -0.37133186 -0.33579128 -0.36677244 -0.38956955 -0.37039706\n",
            " -0.35402897 -0.30667973 -0.38325512 -0.40324782 -0.37320147 -0.36770724\n",
            " -0.41961591 -0.37589129 -0.40593764 -0.37589129 -0.31217396 -0.39225937\n",
            " -0.39494918 -0.3795159  -0.3795159  -0.38045071 -0.37226667 -0.36583763\n",
            " -0.37039706 -0.38956955 -0.38045071 -0.38594494 -0.36677244 -0.34677974\n",
            " -0.37776089 -0.36677244 -0.32760724 -0.37589129 -0.35496378 -0.33216666\n",
            " -0.32760724 -0.3795159  -0.40862745 -0.35402897 -0.38407533 -0.34491013\n",
            " -0.38501013 -0.36314782  0.20111376  0.29756725  0.17282242  0.23384993\n",
            "  0.208363    0.09273701  0.38770631  0.1309674   0.19924415  0.15189491\n",
            "  0.26565129  0.25384263  0.21923685  0.31031072  0.29756725  0.25384263\n",
            "  0.23291512  0.07999354  0.06362546  0.29663245  0.19830935  0.32305418\n",
            "  0.07999354  0.29113822  0.20742819  0.16007895  0.30388168  0.30025706\n",
            "  0.2292905   0.17644703  0.14277606  0.09542682  0.2292905   0.27477014\n",
            "  0.24296877  0.12909779  0.23384993  0.23747455  0.31300053  0.22286147\n",
            "  0.21561223  0.2474136   0.29756725  0.18650069  0.20742819  0.2483484\n",
            "  0.28295418  0.25746725  0.25477743  0.29300783]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431]\n",
            "Epoch - 11 starting.....\n",
            "Predicted Output from the Adaline Model in the 11 th step is as follows: [0.36107538 0.35237131 0.33514999 0.34783244 0.35672335 0.39968323\n",
            " 0.3393152  0.36524059 0.33061112 0.36088855 0.38264874 0.36505376\n",
            " 0.34801927 0.30070735 0.37450516 0.39570486 0.36561425 0.36107538\n",
            " 0.41273935 0.36959263 0.39968323 0.36959263 0.30524621 0.38662712\n",
            " 0.3906055  0.37375784 0.37375784 0.37394467 0.36542742 0.36070172\n",
            " 0.36505376 0.38264874 0.37394467 0.37848354 0.36088855 0.33968886\n",
            " 0.36996629 0.36088855 0.32209387 0.36959263 0.3482061  0.32644591\n",
            " 0.32209387 0.37375784 0.40366161 0.34801927 0.37810988 0.3393152\n",
            " 0.37829671 0.35672335 0.80509313 0.70667773 0.83139218 0.77102415\n",
            " 0.79676271 0.91277309 0.61640592 0.87416524 0.80546679 0.85277871\n",
            " 0.73714199 0.74982445 0.78426709 0.69380845 0.70667773 0.74982445\n",
            " 0.77121098 0.92564237 0.94267687 0.70686456 0.80565362 0.68093916\n",
            " 0.92564237 0.71140343 0.79694954 0.84426147 0.69853414 0.70269935\n",
            " 0.77537618 0.82722698 0.86148279 0.90879471 0.77537618 0.72843792\n",
            " 0.76232007 0.8745389  0.77102415 0.76685894 0.68983007 0.78010188\n",
            " 0.7884323  0.75455015 0.70667773 0.81833607 0.79694954 0.75436332\n",
            " 0.71992067 0.74565924 0.74963762 0.71102977]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.36107538 -0.35237131 -0.33514999 -0.34783244 -0.35672335 -0.39968323\n",
            " -0.3393152  -0.36524059 -0.33061112 -0.36088855 -0.38264874 -0.36505376\n",
            " -0.34801927 -0.30070735 -0.37450516 -0.39570486 -0.36561425 -0.36107538\n",
            " -0.41273935 -0.36959263 -0.39968323 -0.36959263 -0.30524621 -0.38662712\n",
            " -0.3906055  -0.37375784 -0.37375784 -0.37394467 -0.36542742 -0.36070172\n",
            " -0.36505376 -0.38264874 -0.37394467 -0.37848354 -0.36088855 -0.33968886\n",
            " -0.36996629 -0.36088855 -0.32209387 -0.36959263 -0.3482061  -0.32644591\n",
            " -0.32209387 -0.37375784 -0.40366161 -0.34801927 -0.37810988 -0.3393152\n",
            " -0.37829671 -0.35672335  0.19490687  0.29332227  0.16860782  0.22897585\n",
            "  0.20323729  0.08722691  0.38359408  0.12583476  0.19453321  0.14722129\n",
            "  0.26285801  0.25017555  0.21573291  0.30619155  0.29332227  0.25017555\n",
            "  0.22878902  0.07435763  0.05732313  0.29313544  0.19434638  0.31906084\n",
            "  0.07435763  0.28859657  0.20305046  0.15573853  0.30146586  0.29730065\n",
            "  0.22462382  0.17277302  0.13851721  0.09120529  0.22462382  0.27156208\n",
            "  0.23767993  0.1254611   0.22897585  0.23314106  0.31016993  0.21989812\n",
            "  0.2115677   0.24544985  0.29332227  0.18166393  0.20305046  0.24563668\n",
            "  0.28007933  0.25434076  0.25036238  0.28897023]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631]\n",
            "Epoch - 12 starting.....\n",
            "Predicted Output from the Adaline Model in the 12 th step is as follows: [0.35445839 0.34616502 0.3290283  0.34256832 0.35031171 0.39342851\n",
            " 0.33372497 0.35915506 0.3254316  0.35500838 0.3757418  0.35970505\n",
            " 0.34201834 0.29475485 0.36579848 0.38818186 0.35805509 0.35445839\n",
            " 0.40586857 0.36330175 0.39342851 0.36330175 0.29835155 0.38098846\n",
            " 0.38623511 0.36799842 0.36799842 0.36744843 0.35860508 0.35555836\n",
            " 0.35970505 0.3757418  0.36744843 0.37104513 0.35500838 0.332625\n",
            " 0.36220178 0.35500838 0.31658824 0.36330175 0.34146835 0.32073493\n",
            " 0.31658824 0.36799842 0.39867517 0.34201834 0.3721451  0.33372497\n",
            " 0.37159512 0.35031171 0.81101292 0.71068931 0.83534305 0.7756395\n",
            " 0.80161958 0.91797996 0.62030901 0.87900984 0.80991295 0.85717644\n",
            " 0.7397161  0.75325613 0.78752958 0.69769927 0.71068931 0.75325613\n",
            " 0.77508952 0.93097    0.9486567  0.71013932 0.80936297 0.68470923\n",
            " 0.93097    0.71373602 0.8010696  0.84833309 0.70074598 0.70544265\n",
            " 0.77978619 0.83064638 0.86546981 0.9127333  0.77978619 0.73142273\n",
            " 0.76734613 0.87790987 0.7756395  0.77094284 0.69245261 0.78283291\n",
            " 0.79222625 0.75630284 0.71068931 0.82290299 0.8010696  0.75685283\n",
            " 0.72257938 0.74855946 0.75380611 0.71483599]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.35445839 -0.34616502 -0.3290283  -0.34256832 -0.35031171 -0.39342851\n",
            " -0.33372497 -0.35915506 -0.3254316  -0.35500838 -0.3757418  -0.35970505\n",
            " -0.34201834 -0.29475485 -0.36579848 -0.38818186 -0.35805509 -0.35445839\n",
            " -0.40586857 -0.36330175 -0.39342851 -0.36330175 -0.29835155 -0.38098846\n",
            " -0.38623511 -0.36799842 -0.36799842 -0.36744843 -0.35860508 -0.35555836\n",
            " -0.35970505 -0.3757418  -0.36744843 -0.37104513 -0.35500838 -0.332625\n",
            " -0.36220178 -0.35500838 -0.31658824 -0.36330175 -0.34146835 -0.32073493\n",
            " -0.31658824 -0.36799842 -0.39867517 -0.34201834 -0.3721451  -0.33372497\n",
            " -0.37159512 -0.35031171  0.18898708  0.28931069  0.16465695  0.2243605\n",
            "  0.19838042  0.08202004  0.37969099  0.12099016  0.19008705  0.14282356\n",
            "  0.2602839   0.24674387  0.21247042  0.30230073  0.28931069  0.24674387\n",
            "  0.22491048  0.06903     0.0513433   0.28986068  0.19063703  0.31529077\n",
            "  0.06903     0.28626398  0.1989304   0.15166691  0.29925402  0.29455735\n",
            "  0.22021381  0.16935362  0.13453019  0.0872667   0.22021381  0.26857727\n",
            "  0.23265387  0.12209013  0.2243605   0.22905716  0.30754739  0.21716709\n",
            "  0.20777375  0.24369716  0.28931069  0.17709701  0.1989304   0.24314717\n",
            "  0.27742062  0.25144054  0.24619389  0.28516401]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253]\n",
            "Epoch - 13 starting.....\n",
            "Predicted Output from the Adaline Model in the 13 th step is as follows: [0.34790833 0.34001999 0.32296858 0.33735054 0.34396416 0.38723004\n",
            " 0.32818748 0.35312723 0.32029913 0.34918305 0.36890391 0.35440195\n",
            " 0.33607582 0.28886577 0.3571914  0.38073642 0.35057778 0.34790833\n",
            " 0.39906255 0.3570714  0.38723004 0.3570714  0.29153522 0.37539753\n",
            " 0.38189114 0.36229029 0.36229029 0.36101557 0.3518525  0.35045778\n",
            " 0.35440195 0.36890391 0.36101557 0.36368502 0.34918305 0.32563803\n",
            " 0.35452195 0.34918305 0.31113607 0.3570714  0.3348011  0.31508024\n",
            " 0.31113607 0.36229029 0.39372365 0.33607582 0.36623446 0.32818748\n",
            " 0.36495974 0.34396416 0.81673933 0.7145509  0.83912963 0.78008707\n",
            " 0.80630154 0.92299194 0.62407497 0.88367023 0.81418988 0.86139993\n",
            " 0.74216009 0.75654205 0.79064486 0.70144366 0.7145509  0.75654205\n",
            " 0.77881235 0.93609917 0.9544253  0.71327617 0.81291516 0.68833643\n",
            " 0.93609917 0.71594562 0.80502682 0.85223687 0.70283839 0.70805728\n",
            " 0.78403124 0.83391074 0.86928827 0.91649832 0.78403124 0.73427175\n",
            " 0.77219873 0.88112079 0.78008707 0.77486818 0.69495005 0.78542597\n",
            " 0.79586376 0.75793678 0.7145509  0.82729712 0.80502682 0.7592115\n",
            " 0.72510869 0.75132316 0.75781677 0.71849507]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.34790833 -0.34001999 -0.32296858 -0.33735054 -0.34396416 -0.38723004\n",
            " -0.32818748 -0.35312723 -0.32029913 -0.34918305 -0.36890391 -0.35440195\n",
            " -0.33607582 -0.28886577 -0.3571914  -0.38073642 -0.35057778 -0.34790833\n",
            " -0.39906255 -0.3570714  -0.38723004 -0.3570714  -0.29153522 -0.37539753\n",
            " -0.38189114 -0.36229029 -0.36229029 -0.36101557 -0.3518525  -0.35045778\n",
            " -0.35440195 -0.36890391 -0.36101557 -0.36368502 -0.34918305 -0.32563803\n",
            " -0.35452195 -0.34918305 -0.31113607 -0.3570714  -0.3348011  -0.31508024\n",
            " -0.31113607 -0.36229029 -0.39372365 -0.33607582 -0.36623446 -0.32818748\n",
            " -0.36495974 -0.34396416  0.18326067  0.2854491   0.16087037  0.21991293\n",
            "  0.19369846  0.07700806  0.37592503  0.11632977  0.18581012  0.13860007\n",
            "  0.25783991  0.24345795  0.20935514  0.29855634  0.2854491   0.24345795\n",
            "  0.22118765  0.06390083  0.0455747   0.28672383  0.18708484  0.31166357\n",
            "  0.06390083  0.28405438  0.19497318  0.14776313  0.29716161  0.29194272\n",
            "  0.21596876  0.16608926  0.13071173  0.08350168  0.21596876  0.26572825\n",
            "  0.22780127  0.11887921  0.21991293  0.22513182  0.30504995  0.21457403\n",
            "  0.20413624  0.24206322  0.2854491   0.17270288  0.19497318  0.2407885\n",
            "  0.27489131  0.24867684  0.24218323  0.28150493]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154]\n",
            "Epoch - 14 starting.....\n",
            "Predicted Output from the Adaline Model in the 14 th step is as follows: [0.34144999 0.33396026 0.31699376 0.33220244 0.33770513 0.38111489\n",
            " 0.32272567 0.3471819  0.31523594 0.34343703 0.36216135 0.34916894\n",
            " 0.3302154  0.28306077 0.3487105  0.37339595 0.34320781 0.34144999\n",
            " 0.39234949 0.35092676 0.38111489 0.35092676 0.28481859 0.3698803\n",
            " 0.37759925 0.35665867 0.35665867 0.35467163 0.34519486 0.34542407\n",
            " 0.34916894 0.36216135 0.35467163 0.35642945 0.34343703 0.31875159\n",
            " 0.34695268 0.34343703 0.30575917 0.35092676 0.32822836 0.30950404\n",
            " 0.30575917 0.35665867 0.38883384 0.3302154  0.36040353 0.32272567\n",
            " 0.35841649 0.33770513 0.82231978 0.71830453 0.84280193 0.7844127\n",
            " 0.81085597 0.92786364 0.62774013 0.88819873 0.8183457  0.86550033\n",
            " 0.74451858 0.75972726 0.79366025 0.7050829  0.71830453 0.75972726\n",
            " 0.78242566 0.94108527 0.96003881 0.71631749 0.81635866 0.69186126\n",
            " 0.94108527 0.71807531 0.80886893 0.85602356 0.70485368 0.71058558\n",
            " 0.78815757 0.83707002 0.87299006 0.92014469 0.78815757 0.73702885\n",
            " 0.77692297 0.88422465 0.7844127  0.7786808  0.69736395 0.78792835\n",
            " 0.79939216 0.75949804 0.71830453 0.83156733 0.80886893 0.76148508\n",
            " 0.72755208 0.75399535 0.7617143  0.7220494 ]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.34144999 -0.33396026 -0.31699376 -0.33220244 -0.33770513 -0.38111489\n",
            " -0.32272567 -0.3471819  -0.31523594 -0.34343703 -0.36216135 -0.34916894\n",
            " -0.3302154  -0.28306077 -0.3487105  -0.37339595 -0.34320781 -0.34144999\n",
            " -0.39234949 -0.35092676 -0.38111489 -0.35092676 -0.28481859 -0.3698803\n",
            " -0.37759925 -0.35665867 -0.35665867 -0.35467163 -0.34519486 -0.34542407\n",
            " -0.34916894 -0.36216135 -0.35467163 -0.35642945 -0.34343703 -0.31875159\n",
            " -0.34695268 -0.34343703 -0.30575917 -0.35092676 -0.32822836 -0.30950404\n",
            " -0.30575917 -0.35665867 -0.38883384 -0.3302154  -0.36040353 -0.32272567\n",
            " -0.35841649 -0.33770513  0.17768022  0.28169547  0.15719807  0.2155873\n",
            "  0.18914403  0.07213636  0.37225987  0.11180127  0.1816543   0.13449967\n",
            "  0.25548142  0.24027274  0.20633975  0.2949171   0.28169547  0.24027274\n",
            "  0.21757434  0.05891473  0.03996119  0.28368251  0.18364134  0.30813874\n",
            "  0.05891473  0.28192469  0.19113107  0.14397644  0.29514632  0.28941442\n",
            "  0.21184243  0.16292998  0.12700994  0.07985531  0.21184243  0.26297115\n",
            "  0.22307703  0.11577535  0.2155873   0.2213192   0.30263605  0.21207165\n",
            "  0.20060784  0.24050196  0.28169547  0.16843267  0.19113107  0.23851492\n",
            "  0.27244792  0.24600465  0.2382857   0.2779506 ]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035]\n",
            "Epoch - 15 starting.....\n",
            "Predicted Output from the Adaline Model in the 15 th step is as follows: [0.33509463 0.3279968  0.31111425 0.32713478 0.33154571 0.37509553\n",
            " 0.31735006 0.34133044 0.31025223 0.33778152 0.35552609 0.34401733\n",
            " 0.32444789 0.27734915 0.34036759 0.36617283 0.33595665 0.33509463\n",
            " 0.38574228 0.34487935 0.37509553 0.34487935 0.27821118 0.36444879\n",
            " 0.37337149 0.35111516 0.35111516 0.34842826 0.33864354 0.34046841\n",
            " 0.34401733 0.35552609 0.34842826 0.34929029 0.33778152 0.31197627\n",
            " 0.33950557 0.33778152 0.30046751 0.34487935 0.32176099 0.30401642\n",
            " 0.30046751 0.35111516 0.38401823 0.32444789 0.35466407 0.31735006\n",
            " 0.35197718 0.33154571 0.82777875 0.72197169 0.84638534 0.78863986\n",
            " 0.81530713 0.93262295 0.63132314 0.89262205 0.82240496 0.86950369\n",
            " 0.74681409 0.76283462 0.79659971 0.70863806 0.72197169 0.76283462\n",
            " 0.78595297 0.94595659 0.96552603 0.7192848  0.81971807 0.69530442\n",
            " 0.94595659 0.72014682 0.81262024 0.85971897 0.70681318 0.71304899\n",
            " 0.79218878 0.84014953 0.87660152 0.92370025 0.79218878 0.73971626\n",
            " 0.78154204 0.88724826 0.78863986 0.78240406 0.69971536 0.79036391\n",
            " 0.80283552 0.76100975 0.72197169 0.8357386  0.81262024 0.76369664\n",
            " 0.72993154 0.75659881 0.76552151 0.7255206 ]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.33509463 -0.3279968  -0.31111425 -0.32713478 -0.33154571 -0.37509553\n",
            " -0.31735006 -0.34133044 -0.31025223 -0.33778152 -0.35552609 -0.34401733\n",
            " -0.32444789 -0.27734915 -0.34036759 -0.36617283 -0.33595665 -0.33509463\n",
            " -0.38574228 -0.34487935 -0.37509553 -0.34487935 -0.27821118 -0.36444879\n",
            " -0.37337149 -0.35111516 -0.35111516 -0.34842826 -0.33864354 -0.34046841\n",
            " -0.34401733 -0.35552609 -0.34842826 -0.34929029 -0.33778152 -0.31197627\n",
            " -0.33950557 -0.33778152 -0.30046751 -0.34487935 -0.32176099 -0.30401642\n",
            " -0.30046751 -0.35111516 -0.38401823 -0.32444789 -0.35466407 -0.31735006\n",
            " -0.35197718 -0.33154571  0.17222125  0.27802831  0.15361466  0.21136014\n",
            "  0.18469287  0.06737705  0.36867686  0.10737795  0.17759504  0.13049631\n",
            "  0.25318591  0.23716538  0.20340029  0.29136194  0.27802831  0.23716538\n",
            "  0.21404703  0.05404341  0.03447397  0.2807152   0.18028193  0.30469558\n",
            "  0.05404341  0.27985318  0.18737976  0.14028103  0.29318682  0.28695101\n",
            "  0.20781122  0.15985047  0.12339848  0.07629975  0.20781122  0.26028374\n",
            "  0.21845796  0.11275174  0.21136014  0.21759594  0.30028464  0.20963609\n",
            "  0.19716448  0.23899025  0.27802831  0.1642614   0.18737976  0.23630336\n",
            "  0.27006846  0.24340119  0.23447849  0.2744794 ]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253]\n",
            "Epoch - 16 starting.....\n",
            "Predicted Output from the Adaline Model in the 16 th step is as follows: [0.32884681 0.32213408 0.30533427 0.32215208 0.32549045 0.36917717\n",
            " 0.31206499 0.33557754 0.30535226 0.33222117 0.34900299 0.33895189\n",
            " 0.31877772 0.27173463 0.33216719 0.35907209 0.32882882 0.32884681\n",
            " 0.37924626 0.3389339  0.36917717 0.3389339  0.27171664 0.35910808\n",
            " 0.36921316 0.34566462 0.34566462 0.34229026 0.33220318 0.33559553\n",
            " 0.33895189 0.34900299 0.34229026 0.34227227 0.33222117 0.30531627\n",
            " 0.33218518 0.33222117 0.29526517 0.3389339  0.31540336 0.29862154\n",
            " 0.29526517 0.34566462 0.37928225 0.31877772 0.34902099 0.31206499\n",
            " 0.34564663 0.32549045 0.83312924 0.72556362 0.84989307 0.79278089\n",
            " 0.81966779 0.9372845  0.63483382 0.89695415 0.82638052 0.87342361\n",
            " 0.74905817 0.76587599 0.79947562 0.71212017 0.72556362 0.76587599\n",
            " 0.78940653 0.95072796 0.97090213 0.72218926 0.82300616 0.69867672\n",
            " 0.95072796 0.72217127 0.81629343 0.86333652 0.70872782 0.71545854\n",
            " 0.79613725 0.84316234 0.88013634 0.92717942 0.79613725 0.74234545\n",
            " 0.78606816 0.89020543 0.79278089 0.78605016 0.70201509 0.7927449\n",
            " 0.80620634 0.76248363 0.72556362 0.83982397 0.81629343 0.76585799\n",
            " 0.73225836 0.75914526 0.76925035 0.72891999]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.32884681 -0.32213408 -0.30533427 -0.32215208 -0.32549045 -0.36917717\n",
            " -0.31206499 -0.33557754 -0.30535226 -0.33222117 -0.34900299 -0.33895189\n",
            " -0.31877772 -0.27173463 -0.33216719 -0.35907209 -0.32882882 -0.32884681\n",
            " -0.37924626 -0.3389339  -0.36917717 -0.3389339  -0.27171664 -0.35910808\n",
            " -0.36921316 -0.34566462 -0.34566462 -0.34229026 -0.33220318 -0.33559553\n",
            " -0.33895189 -0.34900299 -0.34229026 -0.34227227 -0.33222117 -0.30531627\n",
            " -0.33218518 -0.33222117 -0.29526517 -0.3389339  -0.31540336 -0.29862154\n",
            " -0.29526517 -0.34566462 -0.37928225 -0.31877772 -0.34902099 -0.31206499\n",
            " -0.34564663 -0.32549045  0.16687076  0.27443638  0.15010693  0.20721911\n",
            "  0.18033221  0.0627155   0.36516618  0.10304585  0.17361948  0.12657639\n",
            "  0.25094183  0.23412401  0.20052438  0.28787983  0.27443638  0.23412401\n",
            "  0.21059347  0.04927204  0.02909787  0.27781074  0.17699384  0.30132328\n",
            "  0.04927204  0.27782873  0.18370657  0.13666348  0.29127218  0.28454146\n",
            "  0.20386275  0.15683766  0.11986366  0.07282058  0.20386275  0.25765455\n",
            "  0.21393184  0.10979457  0.20721911  0.21394984  0.29798491  0.2072551\n",
            "  0.19379366  0.23751637  0.27443638  0.16017603  0.18370657  0.23414201\n",
            "  0.26774164  0.24085474  0.23074965  0.27108001]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196]\n",
            "Epoch - 17 starting.....\n",
            "Predicted Output from the Adaline Model in the 17 th step is as follows: [0.32270779 0.31637338 0.29965497 0.31725578 0.31954059 0.36336143\n",
            " 0.30687177 0.3299246  0.30053736 0.32675739 0.34259342 0.33397419\n",
            " 0.31320618 0.26621813 0.32411022 0.35209503 0.3218254  0.32270779\n",
            " 0.37286305 0.3330918  0.36336143 0.3330918  0.26533574 0.35385982\n",
            " 0.36512622 0.3403086  0.3403086  0.33625901 0.325875   0.33080699\n",
            " 0.33397419 0.34259342 0.33625901 0.33537662 0.32675739 0.29877258\n",
            " 0.32499261 0.32675739 0.29015335 0.3330918  0.30915658 0.29332056\n",
            " 0.29015335 0.3403086  0.37462783 0.31320618 0.34347581 0.30687177\n",
            " 0.33942621 0.31954059 0.83837859 0.7290865  0.85333223 0.79684256\n",
            " 0.82394499 0.9418563  0.63827761 0.90120267 0.8302794  0.87726745\n",
            " 0.75125694 0.76885775 0.80229458 0.71553529 0.7290865  0.76885775\n",
            " 0.79279297 0.95540752 0.97617553 0.7250369  0.8262298  0.70198408\n",
            " 0.95540752 0.72415451 0.81989539 0.86688344 0.7106033  0.7178201\n",
            " 0.80000977 0.84611542 0.88360186 0.9305899  0.80000977 0.74492253\n",
            " 0.79050815 0.89310347 0.79684256 0.78962576 0.70426889 0.79507778\n",
            " 0.80951138 0.76392576 0.7290865  0.84383061 0.81989539 0.76797535\n",
            " 0.73453852 0.76164094 0.77290734 0.73225371]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.32270779 -0.31637338 -0.29965497 -0.31725578 -0.31954059 -0.36336143\n",
            " -0.30687177 -0.3299246  -0.30053736 -0.32675739 -0.34259342 -0.33397419\n",
            " -0.31320618 -0.26621813 -0.32411022 -0.35209503 -0.3218254  -0.32270779\n",
            " -0.37286305 -0.3330918  -0.36336143 -0.3330918  -0.26533574 -0.35385982\n",
            " -0.36512622 -0.3403086  -0.3403086  -0.33625901 -0.325875   -0.33080699\n",
            " -0.33397419 -0.34259342 -0.33625901 -0.33537662 -0.32675739 -0.29877258\n",
            " -0.32499261 -0.32675739 -0.29015335 -0.3330918  -0.30915658 -0.29332056\n",
            " -0.29015335 -0.3403086  -0.37462783 -0.31320618 -0.34347581 -0.30687177\n",
            " -0.33942621 -0.31954059  0.16162141  0.2709135   0.14666777  0.20315744\n",
            "  0.17605501  0.0581437   0.36172239  0.09879733  0.1697206   0.12273255\n",
            "  0.24874306  0.23114225  0.19770542  0.28446471  0.2709135   0.23114225\n",
            "  0.20720703  0.04459248  0.02382447  0.2749631   0.1737702   0.29801592\n",
            "  0.04459248  0.27584549  0.18010461  0.13311656  0.2893967   0.2821799\n",
            "  0.19999023  0.15388458  0.11639814  0.0694101   0.19999023  0.25507747\n",
            "  0.20949185  0.10689653  0.20315744  0.21037424  0.29573111  0.20492222\n",
            "  0.19048862  0.23607424  0.2709135   0.15616939  0.18010461  0.23202465\n",
            "  0.26546148  0.23835906  0.22709266  0.26774629]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112]\n",
            "Epoch - 18 starting.....\n",
            "Predicted Output from the Adaline Model in the 18 th step is as follows: [0.31667721 0.31071441 0.29407601 0.3124458  0.31369581 0.35764819\n",
            " 0.3017702  0.3243714  0.2958074  0.32139    0.33629701 0.32908419\n",
            " 0.30773301 0.26079922 0.31619583 0.34524121 0.31494582 0.31667721\n",
            " 0.3665924  0.3273528  0.35764819 0.3273528  0.25906783 0.34870399\n",
            " 0.36111097 0.33504699 0.33504699 0.3303342  0.31965861 0.32610279\n",
            " 0.32908419 0.33629701 0.3303342  0.32860281 0.32139    0.29234462\n",
            " 0.31792722 0.32139    0.28513181 0.3273528  0.30302022 0.28811321\n",
            " 0.28513181 0.33504699 0.37005517 0.30773301 0.3380284  0.3017702\n",
            " 0.3333156  0.31369581 0.84353129 0.73254395 0.85670691 0.80082892\n",
            " 0.82814291 0.94634307 0.64165778 0.90537208 0.83410571 0.8810395\n",
            " 0.75341376 0.77178354 0.80506033 0.71888696 0.73254395 0.77178354\n",
            " 0.79611613 0.96000006 0.98135124 0.72783116 0.82939292 0.70522996\n",
            " 0.96000006 0.72609977 0.82343012 0.8703639  0.71244278 0.72013697\n",
            " 0.80381032 0.84901272 0.8870023  0.93393608 0.80381032 0.74745096\n",
            " 0.79486612 0.8959465  0.80082892 0.79313473 0.70647998 0.79736614\n",
            " 0.81275453 0.76533936 0.73254395 0.84776271 0.82343012 0.77005216\n",
            " 0.73677536 0.76408935 0.77649633 0.73552535]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.31667721 -0.31071441 -0.29407601 -0.3124458  -0.31369581 -0.35764819\n",
            " -0.3017702  -0.3243714  -0.2958074  -0.32139    -0.33629701 -0.32908419\n",
            " -0.30773301 -0.26079922 -0.31619583 -0.34524121 -0.31494582 -0.31667721\n",
            " -0.3665924  -0.3273528  -0.35764819 -0.3273528  -0.25906783 -0.34870399\n",
            " -0.36111097 -0.33504699 -0.33504699 -0.3303342  -0.31965861 -0.32610279\n",
            " -0.32908419 -0.33629701 -0.3303342  -0.32860281 -0.32139    -0.29234462\n",
            " -0.31792722 -0.32139    -0.28513181 -0.3273528  -0.30302022 -0.28811321\n",
            " -0.28513181 -0.33504699 -0.37005517 -0.30773301 -0.3380284  -0.3017702\n",
            " -0.3333156  -0.31369581  0.15646871  0.26745605  0.14329309  0.19917108\n",
            "  0.17185709  0.05365693  0.35834222  0.09462792  0.16589429  0.1189605\n",
            "  0.24658624  0.22821646  0.19493967  0.28111304  0.26745605  0.22821646\n",
            "  0.20388387  0.03999994  0.01864876  0.27216884  0.17060708  0.29477004\n",
            "  0.03999994  0.27390023  0.17656988  0.1296361   0.28755722  0.27986303\n",
            "  0.19618968  0.15098728  0.1129977   0.06606392  0.19618968  0.25254904\n",
            "  0.20513388  0.1040535   0.19917108  0.20686527  0.29352002  0.20263386\n",
            "  0.18724547  0.23466064  0.26745605  0.15223729  0.17656988  0.22994784\n",
            "  0.26322464  0.23591065  0.22350367  0.26447465]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909]\n",
            "Epoch - 19 starting.....\n",
            "Predicted Output from the Adaline Model in the 19 th step is as follows: [0.3107539  0.30515609 0.28859633 0.30772132 0.30795499 0.35203646\n",
            " 0.29675937 0.31891694 0.29116156 0.31611804 0.33011256 0.32428108\n",
            " 0.30235718 0.25547681 0.30842234 0.33850928 0.30818866 0.3107539\n",
            " 0.36043317 0.32171585 0.35203646 0.32171585 0.25291158 0.34363974\n",
            " 0.35716693 0.32987889 0.32987889 0.32451475 0.3135528  0.32148218\n",
            " 0.32428108 0.33011256 0.32451475 0.32194952 0.31611804 0.2860311\n",
            " 0.31098757 0.31611804 0.28019961 0.32171585 0.29699304 0.28299852\n",
            " 0.28019961 0.32987889 0.36556364 0.30235718 0.3326778  0.29675937\n",
            " 0.32731366 0.30795499 0.8485904  0.73593834 0.86001969 0.80474261\n",
            " 0.83226431 0.95074786 0.6449765  0.9094653  0.83786212 0.88474249\n",
            " 0.75553067 0.77465566 0.80777518 0.72217748 0.73593834 0.77465566\n",
            " 0.79937847 0.96450871 0.98643261 0.7305742  0.83249798 0.70841663\n",
            " 0.96450871 0.72800896 0.82690017 0.87378055 0.71424811 0.72241115\n",
            " 0.80754151 0.85185665 0.8903403  0.93722068 0.80754151 0.74993286\n",
            " 0.7991448  0.89873702 0.80474261 0.79657956 0.7086503  0.79961214\n",
            " 0.81593823 0.76672629 0.73593834 0.85162298 0.82690017 0.77209043\n",
            " 0.73897091 0.76649262 0.7800198  0.73873724]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.3107539  -0.30515609 -0.28859633 -0.30772132 -0.30795499 -0.35203646\n",
            " -0.29675937 -0.31891694 -0.29116156 -0.31611804 -0.33011256 -0.32428108\n",
            " -0.30235718 -0.25547681 -0.30842234 -0.33850928 -0.30818866 -0.3107539\n",
            " -0.36043317 -0.32171585 -0.35203646 -0.32171585 -0.25291158 -0.34363974\n",
            " -0.35716693 -0.32987889 -0.32987889 -0.32451475 -0.3135528  -0.32148218\n",
            " -0.32428108 -0.33011256 -0.32451475 -0.32194952 -0.31611804 -0.2860311\n",
            " -0.31098757 -0.31611804 -0.28019961 -0.32171585 -0.29699304 -0.28299852\n",
            " -0.28019961 -0.32987889 -0.36556364 -0.30235718 -0.3326778  -0.29675937\n",
            " -0.32731366 -0.30795499  0.1514096   0.26406166  0.13998031  0.19525739\n",
            "  0.16773569  0.04925214  0.3550235   0.0905347   0.16213788  0.11525751\n",
            "  0.24446933  0.22534434  0.19222482  0.27782252  0.26406166  0.22534434\n",
            "  0.20062153  0.03549129  0.01356739  0.2694258   0.16750202  0.29158337\n",
            "  0.03549129  0.27199104  0.17309983  0.12621945  0.28575189  0.27758885\n",
            "  0.19245849  0.14814335  0.1096597   0.06277932  0.19245849  0.25006714\n",
            "  0.2008552   0.10126298  0.19525739  0.20342044  0.2913497   0.20038786\n",
            "  0.18406177  0.23327371  0.26406166  0.14837702  0.17309983  0.22790957\n",
            "  0.26102909  0.23350738  0.2199802   0.26126276]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737]\n",
            "Epoch - 20 starting.....\n",
            "Predicted Output from the Adaline Model in the 20 th step is as follows: [0.30493633 0.299697   0.2832145  0.30308118 0.30231666 0.34652484\n",
            " 0.29183801 0.31355984 0.28659868 0.31094017 0.32403849 0.31956368\n",
            " 0.29707734 0.2502495  0.30078763 0.33189748 0.30155215 0.30493633\n",
            " 0.35438383 0.3161795  0.34652484 0.3161795  0.24686532 0.33866585\n",
            " 0.3532932  0.32480301 0.32480301 0.31879916 0.30755599 0.31694402\n",
            " 0.31956368 0.32403849 0.31879916 0.31541498 0.31094017 0.27983032\n",
            " 0.30417181 0.31094017 0.27535551 0.3161795  0.29107349 0.27797517\n",
            " 0.27535551 0.32480301 0.36115219 0.29707734 0.32742267 0.29183801\n",
            " 0.32141883 0.30231666 0.85355825 0.73927138 0.86327239 0.80858556\n",
            " 0.83631123 0.95507292 0.64823537 0.91348441 0.84155056 0.8883784\n",
            " 0.75760902 0.77747571 0.81044071 0.72540854 0.73927138 0.77747571\n",
            " 0.80258172 0.96893576 0.9914221  0.73326753 0.83554672 0.7115457\n",
            " 0.96893576 0.72988335 0.83030739 0.87713523 0.71602051 0.72464402\n",
            " 0.81120522 0.85464888 0.89361773 0.94044556 0.81120522 0.7523697\n",
            " 0.80334623 0.90147672 0.80858556 0.79996205 0.71078119 0.8018172\n",
            " 0.81906422 0.76808768 0.73927138 0.8554134  0.83030739 0.77409152\n",
            " 0.74112652 0.7688522  0.78347955 0.74189104]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.30493633 -0.299697   -0.2832145  -0.30308118 -0.30231666 -0.34652484\n",
            " -0.29183801 -0.31355984 -0.28659868 -0.31094017 -0.32403849 -0.31956368\n",
            " -0.29707734 -0.2502495  -0.30078763 -0.33189748 -0.30155215 -0.30493633\n",
            " -0.35438383 -0.3161795  -0.34652484 -0.3161795  -0.24686532 -0.33866585\n",
            " -0.3532932  -0.32480301 -0.32480301 -0.31879916 -0.30755599 -0.31694402\n",
            " -0.31956368 -0.32403849 -0.31879916 -0.31541498 -0.31094017 -0.27983032\n",
            " -0.30417181 -0.31094017 -0.27535551 -0.3161795  -0.29107349 -0.27797517\n",
            " -0.27535551 -0.32480301 -0.36115219 -0.29707734 -0.32742267 -0.29183801\n",
            " -0.32141883 -0.30231666  0.14644175  0.26072862  0.13672761  0.19141444\n",
            "  0.16368877  0.04492708  0.35176463  0.08651559  0.15844944  0.1116216\n",
            "  0.24239098  0.22252429  0.18955929  0.27459146  0.26072862  0.22252429\n",
            "  0.19741828  0.03106424  0.0085779   0.26673247  0.16445328  0.2884543\n",
            "  0.03106424  0.27011665  0.16969261  0.12286477  0.28397949  0.27535598\n",
            "  0.18879478  0.14535112  0.10638227  0.05955444  0.18879478  0.2476303\n",
            "  0.19665377  0.09852328  0.19141444  0.20003795  0.28921881  0.1981828\n",
            "  0.18093578  0.23191232  0.26072862  0.1445866   0.16969261  0.22590848\n",
            "  0.25887348  0.2311478   0.21652045  0.25810896]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854]\n",
            "Epoch - 21 starting.....\n",
            "Predicted Output from the Adaline Model in the 21 th step is as follows: [0.2992228  0.29433555 0.27792895 0.29852405 0.29677918 0.34111174\n",
            " 0.28700469 0.30829854 0.28211744 0.30585491 0.31807302 0.31493065\n",
            " 0.29189193 0.24511574 0.29328943 0.32540389 0.2950343  0.2992228\n",
            " 0.34844261 0.31074216 0.34111174 0.31074216 0.24092725 0.33378088\n",
            " 0.34948873 0.3198179  0.3198179  0.31318578 0.30166642 0.31248703\n",
            " 0.31493065 0.31807302 0.31318578 0.30899729 0.30585491 0.27374046\n",
            " 0.29747793 0.30585491 0.27059808 0.31074216 0.28525982 0.27304171\n",
            " 0.27059808 0.3198179  0.3568196  0.29189193 0.32226152 0.28700469\n",
            " 0.3156294  0.29677918 0.85843681 0.74254446 0.86646643 0.81235937\n",
            " 0.84028534 0.95932006 0.65143571 0.91743111 0.84517258 0.89194877\n",
            " 0.75964982 0.78024492 0.81305812 0.72858148 0.74254446 0.78024492\n",
            " 0.80572726 0.97328304 0.99632176 0.73591235 0.83854046 0.7146185\n",
            " 0.97328304 0.73172385 0.83365322 0.88042941 0.71776087 0.72683661\n",
            " 0.81480299 0.85739069 0.89683601 0.9436122  0.81480299 0.75476257\n",
            " 0.80747213 0.90416688 0.81235937 0.80328364 0.71287363 0.80398239\n",
            " 0.82213386 0.76942431 0.74254446 0.85913556 0.83365322 0.77605642\n",
            " 0.74324321 0.77116918 0.78687703 0.74498809]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.2992228  -0.29433555 -0.27792895 -0.29852405 -0.29677918 -0.34111174\n",
            " -0.28700469 -0.30829854 -0.28211744 -0.30585491 -0.31807302 -0.31493065\n",
            " -0.29189193 -0.24511574 -0.29328943 -0.32540389 -0.2950343  -0.2992228\n",
            " -0.34844261 -0.31074216 -0.34111174 -0.31074216 -0.24092725 -0.33378088\n",
            " -0.34948873 -0.3198179  -0.3198179  -0.31318578 -0.30166642 -0.31248703\n",
            " -0.31493065 -0.31807302 -0.31318578 -0.30899729 -0.30585491 -0.27374046\n",
            " -0.29747793 -0.30585491 -0.27059808 -0.31074216 -0.28525982 -0.27304171\n",
            " -0.27059808 -0.3198179  -0.3568196  -0.29189193 -0.32226152 -0.28700469\n",
            " -0.3156294  -0.29677918  0.14156319  0.25745554  0.13353357  0.18764063\n",
            "  0.15971466  0.04067994  0.34856429  0.08256889  0.15482742  0.10805123\n",
            "  0.24035018  0.21975508  0.18694188  0.27141852  0.25745554  0.21975508\n",
            "  0.19427274  0.02671696  0.00367824  0.26408765  0.16145954  0.2853815\n",
            "  0.02671696  0.26827615  0.16634678  0.11957059  0.28223913  0.27316339\n",
            "  0.18519701  0.14260931  0.10316399  0.0563878   0.18519701  0.24523743\n",
            "  0.19252787  0.09583312  0.18764063  0.19671636  0.28712637  0.19601761\n",
            "  0.17786614  0.23057569  0.25745554  0.14086444  0.16634678  0.22394358\n",
            "  0.25675679  0.22883082  0.21312297  0.25501191]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811]\n",
            "Epoch - 22 starting.....\n",
            "Predicted Output from the Adaline Model in the 22 th step is as follows: [0.29361154 0.28907009 0.27273804 0.29404852 0.29134082 0.33579551\n",
            " 0.28225792 0.30313142 0.27771647 0.30086069 0.31221431 0.31038057\n",
            " 0.28679937 0.24007395 0.28592541 0.31902649 0.28863311 0.29361154\n",
            " 0.34260769 0.30540214 0.33579551 0.30540214 0.23509552 0.32898334\n",
            " 0.34575237 0.31492202 0.31492202 0.30767287 0.29588227 0.30810985\n",
            " 0.31038057 0.31221431 0.30767287 0.30269444 0.30086069 0.26775962\n",
            " 0.29090384 0.30086069 0.26592587 0.30540214 0.27955022 0.2681966\n",
            " 0.26592587 0.31492202 0.35256454 0.28679937 0.31719274 0.28225792\n",
            " 0.30994359 0.29134082 0.86322784 0.74575882 0.86960303 0.81606544\n",
            " 0.84418809 0.96349085 0.6545787  0.92130688 0.84872954 0.89545496\n",
            " 0.76165389 0.78296436 0.81562846 0.73169749 0.74575882 0.78296436\n",
            " 0.80881629 0.97755218 1.00113338 0.73850967 0.84148038 0.71763617\n",
            " 0.97755218 0.73353124 0.83693894 0.88366436 0.71946991 0.72898979\n",
            " 0.81833616 0.86008316 0.89999641 0.94672183 0.81833616 0.75711244\n",
            " 0.81152399 0.90680858 0.81606544 0.80654556 0.71492847 0.80610858\n",
            " 0.82514834 0.77073678 0.74575882 0.86279086 0.83693894 0.77798593\n",
            " 0.74532184 0.77344449 0.79021352 0.74802954]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.29361154 -0.28907009 -0.27273804 -0.29404852 -0.29134082 -0.33579551\n",
            " -0.28225792 -0.30313142 -0.27771647 -0.30086069 -0.31221431 -0.31038057\n",
            " -0.28679937 -0.24007395 -0.28592541 -0.31902649 -0.28863311 -0.29361154\n",
            " -0.34260769 -0.30540214 -0.33579551 -0.30540214 -0.23509552 -0.32898334\n",
            " -0.34575237 -0.31492202 -0.31492202 -0.30767287 -0.29588227 -0.30810985\n",
            " -0.31038057 -0.31221431 -0.30767287 -0.30269444 -0.30086069 -0.26775962\n",
            " -0.29090384 -0.30086069 -0.26592587 -0.30540214 -0.27955022 -0.2681966\n",
            " -0.26592587 -0.31492202 -0.35256454 -0.28679937 -0.31719274 -0.28225792\n",
            " -0.30994359 -0.29134082  0.13677216  0.25424118  0.13039697  0.18393456\n",
            "  0.15581191  0.03650915  0.3454213   0.07869312  0.15127046  0.10454504\n",
            "  0.23834611  0.21703564  0.18437154  0.26830251  0.25424118  0.21703564\n",
            "  0.19118371  0.02244782 -0.00113338  0.26149033  0.15851962  0.28236383\n",
            "  0.02244782  0.26646876  0.16306106  0.11633564  0.28053009  0.27101021\n",
            "  0.18166384  0.13991684  0.10000359  0.05327817  0.18166384  0.24288756\n",
            "  0.18847601  0.09319142  0.18393456  0.19345444  0.28507153  0.19389142\n",
            "  0.17485166  0.22926322  0.25424118  0.13720914  0.16306106  0.22201407\n",
            "  0.25467816  0.22655551  0.20978648  0.25197046]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502]\n",
            "Epoch - 23 starting.....\n",
            "Predicted Output from the Adaline Model in the 23 th step is as follows: [0.28810077 0.28389894 0.26764013 0.28965318 0.28599986 0.33057447\n",
            " 0.2775962  0.29805684 0.27339437 0.29595593 0.3064605  0.305912\n",
            " 0.28179803 0.23512251 0.27869321 0.31276324 0.28234653 0.28810077\n",
            " 0.33687721 0.30015776 0.33057447 0.30015776 0.22936827 0.32427172\n",
            " 0.34208295 0.31011382 0.31011382 0.30225867 0.29020169 0.30381108\n",
            " 0.305912   0.3064605  0.30225867 0.29650443 0.29595593 0.26188589\n",
            " 0.28444745 0.29595593 0.26133739 0.30015776 0.27394287 0.2634383\n",
            " 0.26133739 0.31011382 0.34838569 0.28179803 0.31221474 0.2775962\n",
            " 0.30435958 0.28599986 0.86793299 0.74891556 0.87268332 0.81970505\n",
            " 0.84802085 0.96758678 0.65766543 0.92511308 0.85222268 0.8988982\n",
            " 0.76362196 0.78563502 0.81815264 0.73475767 0.74891556 0.78563502\n",
            " 0.8118499  0.98174467 1.00585864 0.74106041 0.84436752 0.72059977\n",
            " 0.98174467 0.73530617 0.84016569 0.88684122 0.72114827 0.73110434\n",
            " 0.82180597 0.86272725 0.90310003 0.94977555 0.82180597 0.75942014\n",
            " 0.81550323 0.90940277 0.81970505 0.80974898 0.71694644 0.80819657\n",
            " 0.82810871 0.77202562 0.74891556 0.86638058 0.84016569 0.77988078\n",
            " 0.74736315 0.77567895 0.79349017 0.75101648]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.28810077 -0.28389894 -0.26764013 -0.28965318 -0.28599986 -0.33057447\n",
            " -0.2775962  -0.29805684 -0.27339437 -0.29595593 -0.3064605  -0.305912\n",
            " -0.28179803 -0.23512251 -0.27869321 -0.31276324 -0.28234653 -0.28810077\n",
            " -0.33687721 -0.30015776 -0.33057447 -0.30015776 -0.22936827 -0.32427172\n",
            " -0.34208295 -0.31011382 -0.31011382 -0.30225867 -0.29020169 -0.30381108\n",
            " -0.305912   -0.3064605  -0.30225867 -0.29650443 -0.29595593 -0.26188589\n",
            " -0.28444745 -0.29595593 -0.26133739 -0.30015776 -0.27394287 -0.2634383\n",
            " -0.26133739 -0.31011382 -0.34838569 -0.28179803 -0.31221474 -0.2775962\n",
            " -0.30435958 -0.28599986  0.13206701  0.25108444  0.12731668  0.18029495\n",
            "  0.15197915  0.03241322  0.34233457  0.07488692  0.14777732  0.1011018\n",
            "  0.23637804  0.21436498  0.18184736  0.26524233  0.25108444  0.21436498\n",
            "  0.1881501   0.01825533 -0.00585864  0.25893959  0.15563248  0.27940023\n",
            "  0.01825533  0.26469383  0.15983431  0.11315878  0.27885173  0.26889566\n",
            "  0.17819403  0.13727275  0.09689997  0.05022445  0.17819403  0.24057986\n",
            "  0.18449677  0.09059723  0.18029495  0.19025102  0.28305356  0.19180343\n",
            "  0.17189129  0.22797438  0.25108444  0.13361942  0.15983431  0.22011922\n",
            "  0.25263685  0.22432105  0.20650983  0.24898352]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426]\n",
            "Epoch - 24 starting.....\n",
            "Predicted Output from the Adaline Model in the 24 th step is as follows: [0.28268871 0.27882044 0.26263356 0.28533662 0.28075458 0.32544692\n",
            " 0.27301802 0.29307317 0.26914975 0.29113903 0.30080972 0.30152349\n",
            " 0.2768863  0.23025982 0.27159049 0.30661214 0.27617253 0.28268871\n",
            " 0.33124933 0.29500731 0.32544692 0.29500731 0.22374363 0.3196445\n",
            " 0.33847928 0.30539177 0.30539177 0.29694145 0.28462285 0.29958936\n",
            " 0.30152349 0.30080972 0.29694145 0.29042527 0.29113903 0.25611738\n",
            " 0.27810667 0.29113903 0.25683115 0.29500731 0.26843598 0.25876529\n",
            " 0.25683115 0.30539177 0.3442817  0.2768863  0.30732591 0.27301802\n",
            " 0.29887559 0.28075458 0.87255383 0.75201577 0.87570834 0.82327945\n",
            " 0.85178492 0.97160921 0.66069695 0.928851   0.85565319 0.90227967\n",
            " 0.76555474 0.78825779 0.82063154 0.73776303 0.75201577 0.78825779\n",
            " 0.81482912 0.98586194 1.01049914 0.74356545 0.84720287 0.7235103\n",
            " 0.98586194 0.73704927 0.84333459 0.88996108 0.72279653 0.73318099\n",
            " 0.82521358 0.86532388 0.90614795 0.95277443 0.82521358 0.76168646\n",
            " 0.81941117 0.91195036 0.82327945 0.81289499 0.71892825 0.81024708\n",
            " 0.831016   0.77329129 0.75201577 0.86990593 0.84333459 0.78174161\n",
            " 0.74936786 0.77787333 0.79670811 0.75394991]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.28268871 -0.27882044 -0.26263356 -0.28533662 -0.28075458 -0.32544692\n",
            " -0.27301802 -0.29307317 -0.26914975 -0.29113903 -0.30080972 -0.30152349\n",
            " -0.2768863  -0.23025982 -0.27159049 -0.30661214 -0.27617253 -0.28268871\n",
            " -0.33124933 -0.29500731 -0.32544692 -0.29500731 -0.22374363 -0.3196445\n",
            " -0.33847928 -0.30539177 -0.30539177 -0.29694145 -0.28462285 -0.29958936\n",
            " -0.30152349 -0.30080972 -0.29694145 -0.29042527 -0.29113903 -0.25611738\n",
            " -0.27810667 -0.29113903 -0.25683115 -0.29500731 -0.26843598 -0.25876529\n",
            " -0.25683115 -0.30539177 -0.3442817  -0.2768863  -0.30732591 -0.27301802\n",
            " -0.29887559 -0.28075458  0.12744617  0.24798423  0.12429166  0.17672055\n",
            "  0.14821508  0.02839079  0.33930305  0.071149    0.14434681  0.09772033\n",
            "  0.23444526  0.21174221  0.17936846  0.26223697  0.24798423  0.21174221\n",
            "  0.18517088  0.01413806 -0.01049914  0.25643455  0.15279713  0.2764897\n",
            "  0.01413806  0.26295073  0.15666541  0.11003892  0.27720347  0.26681901\n",
            "  0.17478642  0.13467612  0.09385205  0.04722557  0.17478642  0.23831354\n",
            "  0.18058883  0.08804964  0.17672055  0.18710501  0.28107175  0.18975292\n",
            "  0.168984    0.22670871  0.24798423  0.13009407  0.15666541  0.21825839\n",
            "  0.25063214  0.22212667  0.20329189  0.24605009]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913]\n",
            "Epoch - 25 starting.....\n",
            "Predicted Output from the Adaline Model in the 25 th step is as follows: [0.27737361 0.27383293 0.25771672 0.28109743 0.27560327 0.32041121\n",
            " 0.2685219  0.28817879 0.26498122 0.28640845 0.29526016 0.29721364\n",
            " 0.27206259 0.2254843  0.26461494 0.30057118 0.2701091  0.27737361\n",
            " 0.32572223 0.28994913 0.32041121 0.28994913 0.2182198  0.31510019\n",
            " 0.33494022 0.30075432 0.30075432 0.29171948 0.27914395 0.2954433\n",
            " 0.29721364 0.29526016 0.29171948 0.28445497 0.28640845 0.25045222\n",
            " 0.27187945 0.28640845 0.2524057  0.28994913 0.26302774 0.25417604\n",
            " 0.2524057  0.30075432 0.34025124 0.27206259 0.30252466 0.2685219\n",
            " 0.29348982 0.27560327 0.87709191 0.75506047 0.87867911 0.8267898\n",
            " 0.85548154 0.97555949 0.66367424 0.93252189 0.85902222 0.9056005\n",
            " 0.76745285 0.79083356 0.82306598 0.7407146  0.75506047 0.79083356\n",
            " 0.81775496 0.98990536 1.01505641 0.74602562 0.84998737 0.72636873\n",
            " 0.98990536 0.73876112 0.84644669 0.89302497 0.72441525 0.73522044\n",
            " 0.82856014 0.86787392 0.90914118 0.95571946 0.82856014 0.76391217\n",
            " 0.82324912 0.9144522  0.8267898  0.81598462 0.72087457 0.81226079\n",
            " 0.83387116 0.77453421 0.75506047 0.87336808 0.84644669 0.78356906\n",
            " 0.75133664 0.78002838 0.79986841 0.75683081]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.27737361 -0.27383293 -0.25771672 -0.28109743 -0.27560327 -0.32041121\n",
            " -0.2685219  -0.28817879 -0.26498122 -0.28640845 -0.29526016 -0.29721364\n",
            " -0.27206259 -0.2254843  -0.26461494 -0.30057118 -0.2701091  -0.27737361\n",
            " -0.32572223 -0.28994913 -0.32041121 -0.28994913 -0.2182198  -0.31510019\n",
            " -0.33494022 -0.30075432 -0.30075432 -0.29171948 -0.27914395 -0.2954433\n",
            " -0.29721364 -0.29526016 -0.29171948 -0.28445497 -0.28640845 -0.25045222\n",
            " -0.27187945 -0.28640845 -0.2524057  -0.28994913 -0.26302774 -0.25417604\n",
            " -0.2524057  -0.30075432 -0.34025124 -0.27206259 -0.30252466 -0.2685219\n",
            " -0.29348982 -0.27560327  0.12290809  0.24493953  0.12132089  0.1732102\n",
            "  0.14451846  0.02444051  0.33632576  0.06747811  0.14097778  0.0943995\n",
            "  0.23254715  0.20916644  0.17693402  0.2592854   0.24493953  0.20916644\n",
            "  0.18224504  0.01009464 -0.01505641  0.25397438  0.15001263  0.27363127\n",
            "  0.01009464  0.26123888  0.15355331  0.10697503  0.27558475  0.26477956\n",
            "  0.17143986  0.13212608  0.09085882  0.04428054  0.17143986  0.23608783\n",
            "  0.17675088  0.0855478   0.1732102   0.18401538  0.27912543  0.18773921\n",
            "  0.16612884  0.22546579  0.24493953  0.12663192  0.15355331  0.21643094\n",
            "  0.24866336  0.21997162  0.20013159  0.24316919]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634]\n",
            "Epoch - 26 starting.....\n",
            "Predicted Output from the Adaline Model in the 26 th step is as follows: [0.27215373 0.26893479 0.25288799 0.27693423 0.27054426 0.3154657\n",
            " 0.26410638 0.28337211 0.26088744 0.28176264 0.28980999 0.29298103\n",
            " 0.26732532 0.2207944  0.2577643  0.2946384  0.26415428 0.27215373\n",
            " 0.32029411 0.28498158 0.3154657  0.28498158 0.21279496 0.31063729\n",
            " 0.33146459 0.29619997 0.29619997 0.28659105 0.2737632  0.29137156\n",
            " 0.29298103 0.28980999 0.28659105 0.2785916  0.28176264 0.24488855\n",
            " 0.26576375 0.28176264 0.24805958 0.28498158 0.2577164  0.24966905\n",
            " 0.24805958 0.29619997 0.336293   0.26732532 0.29780944 0.26410638\n",
            " 0.28820052 0.27054426 0.8815487  0.75805066 0.8815966  0.83023728\n",
            " 0.85911193 0.97943894 0.6665983  0.93612696 0.86233087 0.90886178\n",
            " 0.76931694 0.79336318 0.82545677 0.74361333 0.75805066 0.79336318\n",
            " 0.82062836 0.99387626 1.01953197 0.74844174 0.85272195 0.72917601\n",
            " 0.99387626 0.74044229 0.84950301 0.89603393 0.72600497 0.73722335\n",
            " 0.83184675 0.87037822 0.91208072 0.95861163 0.83184675 0.766098\n",
            " 0.82701834 0.91690913 0.83023728 0.81901889 0.72278603 0.81423839\n",
            " 0.83667516 0.77575482 0.75805066 0.87676819 0.84950301 0.78536374\n",
            " 0.75327015 0.7821448  0.8029721  0.75966013]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.27215373 -0.26893479 -0.25288799 -0.27693423 -0.27054426 -0.3154657\n",
            " -0.26410638 -0.28337211 -0.26088744 -0.28176264 -0.28980999 -0.29298103\n",
            " -0.26732532 -0.2207944  -0.2577643  -0.2946384  -0.26415428 -0.27215373\n",
            " -0.32029411 -0.28498158 -0.3154657  -0.28498158 -0.21279496 -0.31063729\n",
            " -0.33146459 -0.29619997 -0.29619997 -0.28659105 -0.2737632  -0.29137156\n",
            " -0.29298103 -0.28980999 -0.28659105 -0.2785916  -0.28176264 -0.24488855\n",
            " -0.26576375 -0.28176264 -0.24805958 -0.28498158 -0.2577164  -0.24966905\n",
            " -0.24805958 -0.29619997 -0.336293   -0.26732532 -0.29780944 -0.26410638\n",
            " -0.28820052 -0.27054426  0.1184513   0.24194934  0.1184034   0.16976272\n",
            "  0.14088807  0.02056106  0.3334017   0.06387304  0.13766913  0.09113822\n",
            "  0.23068306  0.20663682  0.17454323  0.25638667  0.24194934  0.20663682\n",
            "  0.17937164  0.00612374 -0.01953197  0.25155826  0.14727805  0.27082399\n",
            "  0.00612374  0.25955771  0.15049699  0.10396607  0.27399503  0.26277665\n",
            "  0.16815325  0.12962178  0.08791928  0.04138837  0.16815325  0.233902\n",
            "  0.17298166  0.08309087  0.16976272  0.18098111  0.27721397  0.18576161\n",
            "  0.16332484  0.22424518  0.24194934  0.12323181  0.15049699  0.21463626\n",
            "  0.24672985  0.2178552   0.1970279   0.24033987]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496]\n",
            "Epoch - 27 starting.....\n",
            "Predicted Output from the Adaline Model in the 27 th step is as follows: [0.26702736 0.26412442 0.24814581 0.27284567 0.26557589 0.31060878\n",
            " 0.25977001 0.27865156 0.25686706 0.27720009 0.28445745 0.28882428\n",
            " 0.26267295 0.21618859 0.25103633 0.28881186 0.25830611 0.26702736\n",
            " 0.31496319 0.28010303 0.31060878 0.28010303 0.20746734 0.30625436\n",
            " 0.32805128 0.29172722 0.29172722 0.2815545  0.26847884 0.28737281\n",
            " 0.28882428 0.28445745 0.2815545  0.27283325 0.27720009 0.23942456\n",
            " 0.25975758 0.27720009 0.2437914  0.28010303 0.25250023 0.24524287\n",
            " 0.2437914  0.29172722 0.3324057  0.26267295 0.2931787  0.25977001\n",
            " 0.28300597 0.26557589 0.88592568 0.76098732 0.88446178 0.83362301\n",
            " 0.86267729 0.98324881 0.66947008 0.93966739 0.86558023 0.91206459\n",
            " 0.77114762 0.79584748 0.8278047  0.74646018 0.76098732 0.79584748\n",
            " 0.82345029 0.99777594 1.02392728 0.7508146  0.85540751 0.73193305\n",
            " 0.99777594 0.74209335 0.85250456 0.89898892 0.72756621 0.7391904\n",
            " 0.83507448 0.87283759 0.91496753 0.96145189 0.83507448 0.76824468\n",
            " 0.83072007 0.91932195 0.83362301 0.82199882 0.72466327 0.81618051\n",
            " 0.8394289  0.77695351 0.76098732 0.88010737 0.85250456 0.78712623\n",
            " 0.75516901 0.78422329 0.80602021 0.76243879]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.26702736 -0.26412442 -0.24814581 -0.27284567 -0.26557589 -0.31060878\n",
            " -0.25977001 -0.27865156 -0.25686706 -0.27720009 -0.28445745 -0.28882428\n",
            " -0.26267295 -0.21618859 -0.25103633 -0.28881186 -0.25830611 -0.26702736\n",
            " -0.31496319 -0.28010303 -0.31060878 -0.28010303 -0.20746734 -0.30625436\n",
            " -0.32805128 -0.29172722 -0.29172722 -0.2815545  -0.26847884 -0.28737281\n",
            " -0.28882428 -0.28445745 -0.2815545  -0.27283325 -0.27720009 -0.23942456\n",
            " -0.25975758 -0.27720009 -0.2437914  -0.28010303 -0.25250023 -0.24524287\n",
            " -0.2437914  -0.29172722 -0.3324057  -0.26267295 -0.2931787  -0.25977001\n",
            " -0.28300597 -0.26557589  0.11407432  0.23901268  0.11553822  0.16637699\n",
            "  0.13732271  0.01675119  0.33052992  0.06033261  0.13441977  0.08793541\n",
            "  0.22885238  0.20415252  0.1721953   0.25353982  0.23901268  0.20415252\n",
            "  0.17654971  0.00222406 -0.02392728  0.2491854   0.14459249  0.26806695\n",
            "  0.00222406  0.25790665  0.14749544  0.10101108  0.27243379  0.2608096\n",
            "  0.16492552  0.12716241  0.08503247  0.03854811  0.16492552  0.23175532\n",
            "  0.16927993  0.08067805  0.16637699  0.17800118  0.27533673  0.18381949\n",
            "  0.1605711   0.22304649  0.23901268  0.11989263  0.14749544  0.21287377\n",
            "  0.24483099  0.21577671  0.19397979  0.23756121]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271]\n",
            "Epoch - 28 starting.....\n",
            "Predicted Output from the Adaline Model in the 28 th step is as follows: [0.26199285 0.25940025 0.24348862 0.26883041 0.26069655 0.30583886\n",
            " 0.25551137 0.27401559 0.25291878 0.2727193  0.27920077 0.28474204\n",
            " 0.25810396 0.21166536 0.24442884 0.28308966 0.25256269 0.26199285\n",
            " 0.30972774 0.27531189 0.30583886 0.27531189 0.2022352  0.30194997\n",
            " 0.32469916 0.28733463 0.28733463 0.27660818 0.26328914 0.28344574\n",
            " 0.28474204 0.27920077 0.27660818 0.26717803 0.2727193  0.23405847\n",
            " 0.25385899 0.2727193  0.23959973 0.27531189 0.24737751 0.24089603\n",
            " 0.23959973 0.28733463 0.32858805 0.25810396 0.28863093 0.25551137\n",
            " 0.27790448 0.26069655 0.89022427 0.76387142 0.88727559 0.83694811\n",
            " 0.86617878 0.98699036 0.67229052 0.94314435 0.86877137 0.91520997\n",
            " 0.77294549 0.79828728 0.83011054 0.74925609 0.76387142 0.79828728\n",
            " 0.82622166 1.0016057  1.02824378 0.75314497 0.85804492 0.73464075\n",
            " 1.0016057  0.74371482 0.85545233 0.90189093 0.72909948 0.74112223\n",
            " 0.8382444  0.87525285 0.91780256 0.96424116 0.8382444  0.7703529\n",
            " 0.83435551 0.92169145 0.83694811 0.82492536 0.72650689 0.8180878\n",
            " 0.84213329 0.77813068 0.76387142 0.88338671 0.85545233 0.78885713\n",
            " 0.75703386 0.78626453 0.80901373 0.76516772]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.26199285 -0.25940025 -0.24348862 -0.26883041 -0.26069655 -0.30583886\n",
            " -0.25551137 -0.27401559 -0.25291878 -0.2727193  -0.27920077 -0.28474204\n",
            " -0.25810396 -0.21166536 -0.24442884 -0.28308966 -0.25256269 -0.26199285\n",
            " -0.30972774 -0.27531189 -0.30583886 -0.27531189 -0.2022352  -0.30194997\n",
            " -0.32469916 -0.28733463 -0.28733463 -0.27660818 -0.26328914 -0.28344574\n",
            " -0.28474204 -0.27920077 -0.27660818 -0.26717803 -0.2727193  -0.23405847\n",
            " -0.25385899 -0.2727193  -0.23959973 -0.27531189 -0.24737751 -0.24089603\n",
            " -0.23959973 -0.28733463 -0.32858805 -0.25810396 -0.28863093 -0.25551137\n",
            " -0.27790448 -0.26069655  0.10977573  0.23612858  0.11272441  0.16305189\n",
            "  0.13382122  0.01300964  0.32770948  0.05685565  0.13122863  0.08479003\n",
            "  0.22705451  0.20171272  0.16988946  0.25074391  0.23612858  0.20171272\n",
            "  0.17377834 -0.0016057  -0.02824378  0.24685503  0.14195508  0.26535925\n",
            " -0.0016057   0.25628518  0.14454767  0.09810907  0.27090052  0.25887777\n",
            "  0.1617556   0.12474715  0.08219744  0.03575884  0.1617556   0.2296471\n",
            "  0.16564449  0.07830855  0.16305189  0.17507464  0.27349311  0.1819122\n",
            "  0.15786671  0.22186932  0.23612858  0.11661329  0.14454767  0.21114287\n",
            "  0.24296614  0.21373547  0.19098627  0.23483228]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283]\n",
            "Epoch - 29 starting.....\n",
            "Predicted Output from the Adaline Model in the 29 th step is as follows: [0.25704853 0.25476075 0.23891491 0.26488713 0.25590464 0.30115438\n",
            " 0.25132907 0.2694627  0.24904129 0.2683188  0.27403826 0.28073297\n",
            " 0.25361685 0.20722322 0.23793965 0.27746994 0.24692215 0.25704853\n",
            " 0.30458605 0.27060659 0.30115438 0.27060659 0.19709684 0.2977227\n",
            " 0.32140714 0.28302075 0.28302075 0.27175048 0.25819242 0.27958908\n",
            " 0.28073297 0.27403826 0.27175048 0.2616241  0.2683188  0.22878852\n",
            " 0.24806604 0.2683188  0.23548323 0.27060659 0.24234658 0.23662712\n",
            " 0.23548323 0.28302075 0.32483882 0.25361685 0.28416464 0.25132907\n",
            " 0.27289437 0.25590464 0.89444588 0.7667039  0.89003895 0.84021365\n",
            " 0.86961755 0.99066482 0.67506053 0.94655897 0.87190533 0.91829896\n",
            " 0.77471114 0.80068337 0.83237505 0.75200195 0.7667039  0.80068337\n",
            " 0.82894337 1.00536677 1.03248288 0.75543363 0.86063506 0.73730001\n",
            " 1.00536677 0.74530725 0.85834727 0.9047409  0.7306053  0.74301946\n",
            " 0.84135754 0.87762479 0.92058674 0.96698038 0.84135754 0.77242336\n",
            " 0.83792587 0.92401842 0.84021365 0.82779948 0.72831751 0.81996088\n",
            " 0.84478922 0.77928671 0.7667039  0.88660728 0.85834727 0.79055698\n",
            " 0.7588653  0.7882692  0.81195364 0.7678478 ]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.25704853 -0.25476075 -0.23891491 -0.26488713 -0.25590464 -0.30115438\n",
            " -0.25132907 -0.2694627  -0.24904129 -0.2683188  -0.27403826 -0.28073297\n",
            " -0.25361685 -0.20722322 -0.23793965 -0.27746994 -0.24692215 -0.25704853\n",
            " -0.30458605 -0.27060659 -0.30115438 -0.27060659 -0.19709684 -0.2977227\n",
            " -0.32140714 -0.28302075 -0.28302075 -0.27175048 -0.25819242 -0.27958908\n",
            " -0.28073297 -0.27403826 -0.27175048 -0.2616241  -0.2683188  -0.22878852\n",
            " -0.24806604 -0.2683188  -0.23548323 -0.27060659 -0.24234658 -0.23662712\n",
            " -0.23548323 -0.28302075 -0.32483882 -0.25361685 -0.28416464 -0.25132907\n",
            " -0.27289437 -0.25590464  0.10555412  0.2332961   0.10996105  0.15978635\n",
            "  0.13038245  0.00933518  0.32493947  0.05344103  0.12809467  0.08170104\n",
            "  0.22528886  0.19931663  0.16762495  0.24799805  0.2332961   0.19931663\n",
            "  0.17105663 -0.00536677 -0.03248288  0.24456637  0.13936494  0.26269999\n",
            " -0.00536677  0.25469275  0.14165273  0.0952591   0.2693947   0.25698054\n",
            "  0.15864246  0.12237521  0.07941326  0.03301962  0.15864246  0.22757664\n",
            "  0.16207413  0.07598158  0.15978635  0.17220052  0.27168249  0.18003912\n",
            "  0.15521078  0.22071329  0.2332961   0.11339272  0.14165273  0.20944302\n",
            "  0.2411347   0.2117308   0.18804636  0.2321522 ]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687]\n",
            "Epoch - 30 starting.....\n",
            "Predicted Output from the Adaline Model in the 30 th step is as follows: [0.2521928  0.25020438 0.23442316 0.26101455 0.25119859 0.29655381\n",
            " 0.24722175 0.26499138 0.24523333 0.26399717 0.26896822 0.27679576\n",
            " 0.24921017 0.20286074 0.23156667 0.27195085 0.24138263 0.2521928\n",
            " 0.29953644 0.26598559 0.29655381 0.26598559 0.19205057 0.29357118\n",
            " 0.31817415 0.27878418 0.27878418 0.2669798  0.25318701 0.27580155\n",
            " 0.27679576 0.26896822 0.2669798  0.25616963 0.26399717 0.223613\n",
            " 0.24237684 0.26399717 0.23144054 0.26598559 0.23740579 0.23243475\n",
            " 0.23144054 0.27878418 0.32115677 0.24921017 0.27977839 0.24722175\n",
            " 0.26797401 0.25119859 0.89859189 0.76948569 0.89275277 0.84342071\n",
            " 0.87299472 0.99427338 0.67778104 0.94991237 0.87498314 0.92133257\n",
            " 0.77644515 0.80303653 0.83459896 0.75469868 0.76948569 0.80303653\n",
            " 0.83161633 1.00906039 1.03664598 0.75768131 0.86317876 0.73991168\n",
            " 1.00906039 0.74687114 0.86119034 0.90753977 0.73208414 0.74488273\n",
            " 0.84441492 0.87995418 0.92332099 0.96967042 0.84441492 0.77445673\n",
            " 0.84143229 0.92630361 0.84342071 0.83062212 0.73009572 0.82180037\n",
            " 0.84739755 0.78042199 0.76948569 0.88977014 0.86119034 0.79222637\n",
            " 0.76066394 0.79023795 0.81484091 0.7704799 ]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.2521928  -0.25020438 -0.23442316 -0.26101455 -0.25119859 -0.29655381\n",
            " -0.24722175 -0.26499138 -0.24523333 -0.26399717 -0.26896822 -0.27679576\n",
            " -0.24921017 -0.20286074 -0.23156667 -0.27195085 -0.24138263 -0.2521928\n",
            " -0.29953644 -0.26598559 -0.29655381 -0.26598559 -0.19205057 -0.29357118\n",
            " -0.31817415 -0.27878418 -0.27878418 -0.2669798  -0.25318701 -0.27580155\n",
            " -0.27679576 -0.26896822 -0.2669798  -0.25616963 -0.26399717 -0.223613\n",
            " -0.24237684 -0.26399717 -0.23144054 -0.26598559 -0.23740579 -0.23243475\n",
            " -0.23144054 -0.27878418 -0.32115677 -0.24921017 -0.27977839 -0.24722175\n",
            " -0.26797401 -0.25119859  0.10140811  0.23051431  0.10724723  0.15657929\n",
            "  0.12700528  0.00572662  0.32221896  0.05008763  0.12501686  0.07866743\n",
            "  0.22355485  0.19696347  0.16540104  0.24530132  0.23051431  0.19696347\n",
            "  0.16838367 -0.00906039 -0.03664598  0.24231869  0.13682124  0.26008832\n",
            " -0.00906039  0.25312886  0.13880966  0.09246023  0.26791586  0.25511727\n",
            "  0.15558508  0.12004582  0.07667901  0.03032958  0.15558508  0.22554327\n",
            "  0.15856771  0.07369639  0.15657929  0.16937788  0.26990428  0.17819963\n",
            "  0.15260245  0.21957801  0.23051431  0.11022986  0.13880966  0.20777363\n",
            "  0.23933606  0.20976205  0.18515909  0.2295201 ]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618]\n",
            "Epoch - 31 starting.....\n",
            "Predicted Output from the Adaline Model in the 31 th step is as follows: [0.24742406 0.24572966 0.23001193 0.25721139 0.24657686 0.29203565\n",
            " 0.24318806 0.26060019 0.24149366 0.25975299 0.26398899 0.27292912\n",
            " 0.24488246 0.19857647 0.2253078  0.26653059 0.23594233 0.24742406\n",
            " 0.29457725 0.26144739 0.29203565 0.26144739 0.18709474 0.28949405\n",
            " 0.31499911 0.27462352 0.27462352 0.26229459 0.24827126 0.27208192\n",
            " 0.27292912 0.26398899 0.26229459 0.25081286 0.25975299 0.2185302\n",
            " 0.23678953 0.25975299 0.22747033 0.26144739 0.23255353 0.22831753\n",
            " 0.22747033 0.27462352 0.31754071 0.24488246 0.27547072 0.24318806\n",
            " 0.26314179 0.24657686 0.90266366 0.77221769 0.89541793 0.84657034\n",
            " 0.8763114  0.99781724 0.68045291 0.95320565 0.8780058  0.92431179\n",
            " 0.77814808 0.80534755 0.83678301 0.75734716 0.77221769 0.80534755\n",
            " 0.83424141 1.01268777 1.04073443 0.75988876 0.86567687 0.74247663\n",
            " 1.01268777 0.74840702 0.86398247 0.91028846 0.73353649 0.74671263\n",
            " 0.84741754 0.8822418  0.92600619 0.97231218 0.84741754 0.77645369\n",
            " 0.84487594 0.92854778 0.84657034 0.83339421 0.7318421  0.82360687\n",
            " 0.84995914 0.78153688 0.77221769 0.89287633 0.86398247 0.79386581\n",
            " 0.76243035 0.79217142 0.81767648 0.77306489]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.24742406 -0.24572966 -0.23001193 -0.25721139 -0.24657686 -0.29203565\n",
            " -0.24318806 -0.26060019 -0.24149366 -0.25975299 -0.26398899 -0.27292912\n",
            " -0.24488246 -0.19857647 -0.2253078  -0.26653059 -0.23594233 -0.24742406\n",
            " -0.29457725 -0.26144739 -0.29203565 -0.26144739 -0.18709474 -0.28949405\n",
            " -0.31499911 -0.27462352 -0.27462352 -0.26229459 -0.24827126 -0.27208192\n",
            " -0.27292912 -0.26398899 -0.26229459 -0.25081286 -0.25975299 -0.2185302\n",
            " -0.23678953 -0.25975299 -0.22747033 -0.26144739 -0.23255353 -0.22831753\n",
            " -0.22747033 -0.27462352 -0.31754071 -0.24488246 -0.27547072 -0.24318806\n",
            " -0.26314179 -0.24657686  0.09733634  0.22778231  0.10458207  0.15342966\n",
            "  0.1236886   0.00218276  0.31954709  0.04679435  0.1219942   0.07568821\n",
            "  0.22185192  0.19465245  0.16321699  0.24265284  0.22778231  0.19465245\n",
            "  0.16575859 -0.01268777 -0.04073443  0.24011124  0.13432313  0.25752337\n",
            " -0.01268777  0.25159298  0.13601753  0.08971154  0.26646351  0.25328737\n",
            "  0.15258246  0.1177582   0.07399381  0.02768782  0.15258246  0.22354631\n",
            "  0.15512406  0.07145222  0.15342966  0.16660579  0.2681579   0.17639313\n",
            "  0.15004086  0.21846312  0.22778231  0.10712367  0.13601753  0.20613419\n",
            "  0.23756965  0.20782858  0.18232352  0.22693511]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054]\n",
            "Epoch - 32 starting.....\n",
            "Predicted Output from the Adaline Model in the 32 th step is as follows: [0.24274076 0.24133513 0.22567976 0.25347643 0.24203795 0.28759842\n",
            " 0.23922669 0.25628769 0.23782106 0.25558487 0.25909895 0.26913179\n",
            " 0.24063232 0.19436903 0.21916099 0.26120739 0.23059947 0.24274076\n",
            " 0.28970687 0.2569905  0.28759842 0.2569905  0.18222773 0.28548998\n",
            " 0.31188101 0.27053742 0.27053742 0.25769332 0.24344358 0.26842898\n",
            " 0.26913179 0.25909895 0.25769332 0.24555202 0.25558487 0.21353847\n",
            " 0.23130229 0.25558487 0.22357132 0.2569905  0.22778821 0.22427413\n",
            " 0.22357132 0.27053742 0.31398946 0.24063232 0.27124024 0.23922669\n",
            " 0.25839613 0.24203795 0.90666251 0.77490079 0.8980353  0.84966356\n",
            " 0.87956867 1.00129754 0.68307702 0.95643988 0.8809743  0.92723759\n",
            " 0.7798205  0.80761716 0.8389279  0.75994824 0.77490079 0.80761716\n",
            " 0.83681945 1.0162501  1.04474957 0.76205668 0.86813019 0.74499568\n",
            " 1.0162501  0.74991539 0.86672456 0.91298785 0.73496284 0.74850976\n",
            " 0.85036638 0.88448837 0.92864322 0.97490651 0.85036638 0.77841487\n",
            " 0.84825793 0.93075167 0.84966356 0.83611664 0.73355721 0.82538098\n",
            " 0.85247482 0.78263176 0.77490079 0.89592685 0.86672456 0.79547587\n",
            " 0.76416513 0.79407024 0.82046127 0.77560361]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.24274076 -0.24133513 -0.22567976 -0.25347643 -0.24203795 -0.28759842\n",
            " -0.23922669 -0.25628769 -0.23782106 -0.25558487 -0.25909895 -0.26913179\n",
            " -0.24063232 -0.19436903 -0.21916099 -0.26120739 -0.23059947 -0.24274076\n",
            " -0.28970687 -0.2569905  -0.28759842 -0.2569905  -0.18222773 -0.28548998\n",
            " -0.31188101 -0.27053742 -0.27053742 -0.25769332 -0.24344358 -0.26842898\n",
            " -0.26913179 -0.25909895 -0.25769332 -0.24555202 -0.25558487 -0.21353847\n",
            " -0.23130229 -0.25558487 -0.22357132 -0.2569905  -0.22778821 -0.22427413\n",
            " -0.22357132 -0.27053742 -0.31398946 -0.24063232 -0.27124024 -0.23922669\n",
            " -0.25839613 -0.24203795  0.09333749  0.22509921  0.1019647   0.15033644\n",
            "  0.12043133 -0.00129754  0.31692298  0.04356012  0.1190257   0.07276241\n",
            "  0.2201795   0.19238284  0.1610721   0.24005176  0.22509921  0.19238284\n",
            "  0.16318055 -0.0162501  -0.04474957  0.23794332  0.13186981  0.25500432\n",
            " -0.0162501   0.25008461  0.13327544  0.08701215  0.26503716  0.25149024\n",
            "  0.14963362  0.11551163  0.07135678  0.02509349  0.14963362  0.22158513\n",
            "  0.15174207  0.06924833  0.15033644  0.16388336  0.26644279  0.17461902\n",
            "  0.14752518  0.21736824  0.22509921  0.10407315  0.13327544  0.20452413\n",
            "  0.23583487  0.20592976  0.17953873  0.22439639]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053]\n",
            "Epoch - 33 starting.....\n",
            "Predicted Output from the Adaline Model in the 33 th step is as follows: [0.23814137 0.23701936 0.22142524 0.24980842 0.23758037 0.28324068\n",
            " 0.23533633 0.25205246 0.23421431 0.25149145 0.25429649 0.26540253\n",
            " 0.23645835 0.19023702 0.21312425 0.25597952 0.22535231 0.23814137\n",
            " 0.28492371 0.25261347 0.28324068 0.25261347 0.17744796 0.28155765\n",
            " 0.30881881 0.26652455 0.26652455 0.25317448 0.23870238 0.26484152\n",
            " 0.26540253 0.25429649 0.25317448 0.24038541 0.25149145 0.20863618\n",
            " 0.22591332 0.25149145 0.21974222 0.25261347 0.22310827 0.22030323\n",
            " 0.21974222 0.26652455 0.31050184 0.23645835 0.26708556 0.23533633\n",
            " 0.25373549 0.23758037 0.91058976 0.77753588 0.90060574 0.85270139\n",
            " 0.88276759 1.00471544 0.68565424 0.95961613 0.88388961 0.93011093\n",
            " 0.78146294 0.80984612 0.84103434 0.76250278 0.77753588 0.80984612\n",
            " 0.83935131 1.01974854 1.04869272 0.7641858  0.87053954 0.74746967\n",
            " 1.01974854 0.75139674 0.86941752 0.91563884 0.73636364 0.75027472\n",
            " 0.8532624  0.88669466 0.93123295 0.97745428 0.8532624  0.78034092\n",
            " 0.85157937 0.93291598 0.85270139 0.8387903  0.73524162 0.82712326\n",
            " 0.85494542 0.78370698 0.77753588 0.89892271 0.86941752 0.79705705\n",
            " 0.76586883 0.79593503 0.82319619 0.77809689]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.23814137 -0.23701936 -0.22142524 -0.24980842 -0.23758037 -0.28324068\n",
            " -0.23533633 -0.25205246 -0.23421431 -0.25149145 -0.25429649 -0.26540253\n",
            " -0.23645835 -0.19023702 -0.21312425 -0.25597952 -0.22535231 -0.23814137\n",
            " -0.28492371 -0.25261347 -0.28324068 -0.25261347 -0.17744796 -0.28155765\n",
            " -0.30881881 -0.26652455 -0.26652455 -0.25317448 -0.23870238 -0.26484152\n",
            " -0.26540253 -0.25429649 -0.25317448 -0.24038541 -0.25149145 -0.20863618\n",
            " -0.22591332 -0.25149145 -0.21974222 -0.25261347 -0.22310827 -0.22030323\n",
            " -0.21974222 -0.26652455 -0.31050184 -0.23645835 -0.26708556 -0.23533633\n",
            " -0.25373549 -0.23758037  0.08941024  0.22246412  0.09939426  0.14729861\n",
            "  0.11723241 -0.00471544  0.31434576  0.04038387  0.11611039  0.06988907\n",
            "  0.21853706  0.19015388  0.15896566  0.23749722  0.22246412  0.19015388\n",
            "  0.16064869 -0.01974854 -0.04869272  0.2358142   0.12946046  0.25253033\n",
            " -0.01974854  0.24860326  0.13058248  0.08436116  0.26363636  0.24972528\n",
            "  0.1467376   0.11330534  0.06876705  0.02254572  0.1467376   0.21965908\n",
            "  0.14842063  0.06708402  0.14729861  0.1612097   0.26475838  0.17287674\n",
            "  0.14505458  0.21629302  0.22246412  0.10107729  0.13058248  0.20294295\n",
            "  0.23413117  0.20406497  0.17680381  0.22190311]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053, 2.290947632071186]\n",
            "Epoch - 34 starting.....\n",
            "Predicted Output from the Adaline Model in the 34 th step is as follows: [0.23362439 0.23278092 0.21724698 0.24620618 0.23320265 0.27896099\n",
            " 0.23151571 0.24789312 0.23067225 0.24747139 0.24958006 0.26174012\n",
            " 0.23235918 0.18617911 0.2071956  0.25084527 0.22019913 0.23362439\n",
            " 0.2802262  0.24831486 0.27896099 0.24831486 0.17275385 0.27769579\n",
            " 0.30581152 0.26258359 0.26258359 0.24873659 0.23404612 0.26131838\n",
            " 0.26174012 0.24958006 0.24873659 0.23531133 0.24747139 0.20382172\n",
            " 0.22062086 0.24747139 0.21598178 0.24831486 0.21851219 0.21640351\n",
            " 0.21598178 0.26258359 0.30707672 0.23235918 0.26300532 0.23151571\n",
            " 0.24915833 0.23320265 0.91444668 0.78012381 0.90313009 0.85568481\n",
            " 0.88590922 1.00807204 0.68818539 0.96273543 0.88675269 0.93293276\n",
            " 0.78307595 0.81203515 0.84310302 0.7650116  0.78012381 0.81203515\n",
            " 0.84183782 1.02318424 1.05256517 0.76627681 0.87290569 0.7498994\n",
            " 1.02318424 0.75285155 0.87206222 0.9182423  0.73773934 0.75200808\n",
            " 0.85610655 0.88886136 0.93377623 0.97995631 0.85610655 0.78223248\n",
            " 0.85484134 0.93504144 0.85568481 0.84141608 0.73689587 0.82883429\n",
            " 0.85737175 0.78476289 0.78012381 0.90186489 0.87206222 0.79860989\n",
            " 0.76754201 0.79776642 0.82588215 0.78054554]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.23362439 -0.23278092 -0.21724698 -0.24620618 -0.23320265 -0.27896099\n",
            " -0.23151571 -0.24789312 -0.23067225 -0.24747139 -0.24958006 -0.26174012\n",
            " -0.23235918 -0.18617911 -0.2071956  -0.25084527 -0.22019913 -0.23362439\n",
            " -0.2802262  -0.24831486 -0.27896099 -0.24831486 -0.17275385 -0.27769579\n",
            " -0.30581152 -0.26258359 -0.26258359 -0.24873659 -0.23404612 -0.26131838\n",
            " -0.26174012 -0.24958006 -0.24873659 -0.23531133 -0.24747139 -0.20382172\n",
            " -0.22062086 -0.24747139 -0.21598178 -0.24831486 -0.21851219 -0.21640351\n",
            " -0.21598178 -0.26258359 -0.30707672 -0.23235918 -0.26300532 -0.23151571\n",
            " -0.24915833 -0.23320265  0.08555332  0.21987619  0.09686991  0.14431519\n",
            "  0.11409078 -0.00807204  0.31181461  0.03726457  0.11324731  0.06706724\n",
            "  0.21692405  0.18796485  0.15689698  0.2349884   0.21987619  0.18796485\n",
            "  0.15816218 -0.02318424 -0.05256517  0.23372319  0.12709431  0.2501006\n",
            " -0.02318424  0.24714845  0.12793778  0.0817577   0.26226066  0.24799192\n",
            "  0.14389345  0.11113864  0.06622377  0.02004369  0.14389345  0.21776752\n",
            "  0.14515866  0.06495856  0.14431519  0.15858392  0.26310413  0.17116571\n",
            "  0.14262825  0.21523711  0.21987619  0.09813511  0.12793778  0.20139011\n",
            "  0.23245799  0.20223358  0.17411785  0.21945446]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053, 2.290947632071186, 2.222263427119805]\n",
            "Epoch - 35 starting.....\n",
            "Predicted Output from the Adaline Model in the 35 th step is as follows: [0.22918833 0.22861844 0.21314361 0.24266853 0.22890339 0.27475797\n",
            " 0.2277636  0.24380832 0.2271937  0.24352337 0.24494811 0.25814335\n",
            " 0.22833349 0.18219396 0.2013731  0.24580295 0.21513824 0.22918833\n",
            " 0.27561281 0.24409326 0.27475797 0.24409326 0.16814387 0.27390313\n",
            " 0.30285815 0.25871325 0.25871325 0.24437821 0.22947328 0.25785841\n",
            " 0.25814335 0.24494811 0.24437821 0.23032812 0.24352337 0.19909352\n",
            " 0.21542319 0.24352337 0.21228877 0.24409326 0.21399845 0.21257372\n",
            " 0.21228877 0.25871325 0.30371299 0.22833349 0.25899819 0.2277636\n",
            " 0.24466316 0.22890339 0.91823454 0.78266542 0.90560918 0.85861481\n",
            " 0.88899457 1.01136844 0.69067131 0.9657988  0.88956446 0.93570399\n",
            " 0.78466005 0.81418497 0.84513462 0.76747554 0.78266542 0.81418497\n",
            " 0.84427978 1.02655832 1.05636818 0.76833038 0.87522943 0.75228566\n",
            " 1.02655832 0.75428029 0.87465953 0.92079906 0.73909042 0.7537104\n",
            " 0.85889976 0.8909892  0.93627389 0.98241342 0.85889976 0.78409016\n",
            " 0.85804492 0.93712873 0.85861481 0.84399483 0.73852052 0.83051463\n",
            " 0.8597546  0.78579984 0.78266542 0.90475434 0.87465953 0.80013488\n",
            " 0.76918523 0.79956498 0.82852    0.78295037]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.22918833 -0.22861844 -0.21314361 -0.24266853 -0.22890339 -0.27475797\n",
            " -0.2277636  -0.24380832 -0.2271937  -0.24352337 -0.24494811 -0.25814335\n",
            " -0.22833349 -0.18219396 -0.2013731  -0.24580295 -0.21513824 -0.22918833\n",
            " -0.27561281 -0.24409326 -0.27475797 -0.24409326 -0.16814387 -0.27390313\n",
            " -0.30285815 -0.25871325 -0.25871325 -0.24437821 -0.22947328 -0.25785841\n",
            " -0.25814335 -0.24494811 -0.24437821 -0.23032812 -0.24352337 -0.19909352\n",
            " -0.21542319 -0.24352337 -0.21228877 -0.24409326 -0.21399845 -0.21257372\n",
            " -0.21228877 -0.25871325 -0.30371299 -0.22833349 -0.25899819 -0.2277636\n",
            " -0.24466316 -0.22890339  0.08176546  0.21733458  0.09439082  0.14138519\n",
            "  0.11100543 -0.01136844  0.30932869  0.0342012   0.11043554  0.06429601\n",
            "  0.21533995  0.18581503  0.15486538  0.23252446  0.21733458  0.18581503\n",
            "  0.15572022 -0.02655832 -0.05636818  0.23166962  0.12477057  0.24771434\n",
            " -0.02655832  0.24571971  0.12534047  0.07920094  0.26090958  0.2462896\n",
            "  0.14110024  0.1090108   0.06372611  0.01758658  0.14110024  0.21590984\n",
            "  0.14195508  0.06287127  0.14138519  0.15600517  0.26147948  0.16948537\n",
            "  0.1402454   0.21420016  0.21733458  0.09524566  0.12534047  0.19986512\n",
            "  0.23081477  0.20043502  0.17148     0.21704963]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053, 2.290947632071186, 2.222263427119805, 2.1560183174034226]\n",
            "Epoch - 36 starting.....\n",
            "Predicted Output from the Adaline Model in the 36 th step is as follows: [0.22483175 0.22453055 0.20911379 0.2391943  0.22468115 0.27063023\n",
            " 0.22407875 0.23979671 0.22377754 0.23964611 0.24039911 0.25461106\n",
            " 0.22437995 0.17828027 0.19565485 0.24085092 0.210168   0.22483175\n",
            " 0.27108203 0.23994731 0.27063023 0.23994731 0.16361652 0.27017842\n",
            " 0.29995773 0.25491226 0.25491226 0.24009791 0.22498235 0.25446046\n",
            " 0.25461106 0.24039911 0.24009791 0.22543416 0.23964611 0.19445004\n",
            " 0.2103186  0.23964611 0.20866199 0.23994731 0.2095656  0.20881259\n",
            " 0.20866199 0.25491226 0.30040954 0.22437995 0.25506287 0.22407875\n",
            " 0.24024851 0.22468115 0.92195457 0.78516155 0.90804382 0.86149234\n",
            " 0.89202466 1.01460573 0.6931128  0.96880725 0.89232586 0.93842554\n",
            " 0.78621576 0.81629627 0.84712979 0.76989539 0.78516155 0.81629627\n",
            " 0.84667799 1.02987188 1.060103   0.7703472  0.87751151 0.75462924\n",
            " 1.02987188 0.75568345 0.8772103  0.92330998 0.74041729 0.75538224\n",
            " 0.86164294 0.89307887 0.93872674 0.98482642 0.86164294 0.78591456\n",
            " 0.86119114 0.93917855 0.86149234 0.84652739 0.74011609 0.83216484\n",
            " 0.86209475 0.78681817 0.78516155 0.90759202 0.8772103  0.80163252\n",
            " 0.770799   0.80133132 0.83111063 0.78531215]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.22483175 -0.22453055 -0.20911379 -0.2391943  -0.22468115 -0.27063023\n",
            " -0.22407875 -0.23979671 -0.22377754 -0.23964611 -0.24039911 -0.25461106\n",
            " -0.22437995 -0.17828027 -0.19565485 -0.24085092 -0.210168   -0.22483175\n",
            " -0.27108203 -0.23994731 -0.27063023 -0.23994731 -0.16361652 -0.27017842\n",
            " -0.29995773 -0.25491226 -0.25491226 -0.24009791 -0.22498235 -0.25446046\n",
            " -0.25461106 -0.24039911 -0.24009791 -0.22543416 -0.23964611 -0.19445004\n",
            " -0.2103186  -0.23964611 -0.20866199 -0.23994731 -0.2095656  -0.20881259\n",
            " -0.20866199 -0.25491226 -0.30040954 -0.22437995 -0.25506287 -0.22407875\n",
            " -0.24024851 -0.22468115  0.07804543  0.21483845  0.09195618  0.13850766\n",
            "  0.10797534 -0.01460573  0.3068872   0.03119275  0.10767414  0.06157446\n",
            "  0.21378424  0.18370373  0.15287021  0.23010461  0.21483845  0.18370373\n",
            "  0.15332201 -0.02987188 -0.060103    0.2296528   0.12248849  0.24537076\n",
            " -0.02987188  0.24431655  0.1227897   0.07669002  0.25958271  0.24461776\n",
            "  0.13835706  0.10692113  0.06127326  0.01517358  0.13835706  0.21408544\n",
            "  0.13880886  0.06082145  0.13850766  0.15347261  0.25988391  0.16783516\n",
            "  0.13790525  0.21318183  0.21483845  0.09240798  0.1227897   0.19836748\n",
            "  0.229201    0.19866868  0.16888937  0.21468785]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053, 2.290947632071186, 2.222263427119805, 2.1560183174034226, 2.0921256797590733]\n",
            "Epoch - 37 starting.....\n",
            "Predicted Output from the Adaline Model in the 37 th step is as follows: [0.22055323 0.22051592 0.2051562  0.23578237 0.22053457 0.26657642\n",
            " 0.22045996 0.23585698 0.22042265 0.23583833 0.2359316  0.25114209\n",
            " 0.22049727 0.17443676 0.19003899 0.23598756 0.20528678 0.22055323\n",
            " 0.26663239 0.23587564 0.26657642 0.23587564 0.15917031 0.26652046\n",
            " 0.29710932 0.2511794  0.2511794  0.23589429 0.22057188 0.25112343\n",
            " 0.25114209 0.2359316  0.23589429 0.22062784 0.23583833 0.18988975\n",
            " 0.20530543 0.23583833 0.20510024 0.23587564 0.20521216 0.20511889\n",
            " 0.20510024 0.2511794  0.29716528 0.22049727 0.25119805 0.22045996\n",
            " 0.23591295 0.22053457 0.92560799 0.78761302 0.91043481 0.86431834\n",
            " 0.89500047 1.01778496 0.69551066 0.97176176 0.89503778 0.94109828\n",
            " 0.78774359 0.81836976 0.8490892  0.77227195 0.78761302 0.81836976\n",
            " 0.84903324 1.03312602 1.06377084 0.77232791 0.87975268 0.75693088\n",
            " 1.03312602 0.75706146 0.87971537 0.92577587 0.7417204  0.75702416\n",
            " 0.864337   0.89513105 0.94113559 0.9871961  0.864337   0.78770629\n",
            " 0.86428103 0.94119156 0.86431834 0.84901458 0.74168309 0.83378544\n",
            " 0.86439296 0.78781821 0.78761302 0.91037885 0.87971537 0.80310331\n",
            " 0.77238388 0.80306601 0.83365487 0.78763167]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.22055323 -0.22051592 -0.2051562  -0.23578237 -0.22053457 -0.26657642\n",
            " -0.22045996 -0.23585698 -0.22042265 -0.23583833 -0.2359316  -0.25114209\n",
            " -0.22049727 -0.17443676 -0.19003899 -0.23598756 -0.20528678 -0.22055323\n",
            " -0.26663239 -0.23587564 -0.26657642 -0.23587564 -0.15917031 -0.26652046\n",
            " -0.29710932 -0.2511794  -0.2511794  -0.23589429 -0.22057188 -0.25112343\n",
            " -0.25114209 -0.2359316  -0.23589429 -0.22062784 -0.23583833 -0.18988975\n",
            " -0.20530543 -0.23583833 -0.20510024 -0.23587564 -0.20521216 -0.20511889\n",
            " -0.20510024 -0.2511794  -0.29716528 -0.22049727 -0.25119805 -0.22045996\n",
            " -0.23591295 -0.22053457  0.07439201  0.21238698  0.08956519  0.13568166\n",
            "  0.10499953 -0.01778496  0.30448934  0.02823824  0.10496222  0.05890172\n",
            "  0.21225641  0.18163024  0.1509108   0.22772805  0.21238698  0.18163024\n",
            "  0.15096676 -0.03312602 -0.06377084  0.22767209  0.12024732  0.24306912\n",
            " -0.03312602  0.24293854  0.12028463  0.07422413  0.2582796   0.24297584\n",
            "  0.135663    0.10486895  0.05886441  0.0128039   0.135663    0.21229371\n",
            "  0.13571897  0.05880844  0.13568166  0.15098542  0.25831691  0.16621456\n",
            "  0.13560704  0.21218179  0.21238698  0.08962115  0.12028463  0.19689669\n",
            "  0.22761612  0.19693399  0.16634513  0.21236833]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053, 2.290947632071186, 2.222263427119805, 2.1560183174034226, 2.0921256797590733, 2.0305019674001348]\n",
            "Epoch - 38 starting.....\n",
            "Predicted Output from the Adaline Model in the 38 th step is as follows: [0.21635136 0.21657323 0.20126955 0.23243161 0.2164623  0.26259523\n",
            " 0.21690605 0.23198786 0.21712792 0.2320988  0.23154411 0.2477353\n",
            " 0.21668417 0.17066217 0.18452367 0.23121129 0.20049298 0.21635136\n",
            " 0.26226242 0.23187692 0.26259523 0.23187692 0.1548038  0.26292805\n",
            " 0.29431198 0.24751342 0.24751342 0.23176598 0.21624042 0.24784623\n",
            " 0.2477353  0.23154411 0.23176598 0.21590761 0.2320988  0.18541117\n",
            " 0.20038204 0.2320988  0.20160236 0.23187692 0.20093673 0.20149142\n",
            " 0.20160236 0.24751342 0.29397917 0.21668417 0.24740248 0.21690605\n",
            " 0.23165504 0.2164623  0.92919599 0.79002061 0.91278292 0.86709373\n",
            " 0.89792298 1.02090717 0.69786568 0.97466329 0.89770111 0.94372311\n",
            " 0.78924405 0.82040611 0.85101348 0.77460599 0.79002061 0.82040611\n",
            " 0.8513463  1.03632179 1.06737292 0.77427317 0.88195367 0.75919136\n",
            " 1.03632179 0.7584148  0.88217555 0.92819754 0.74300017 0.75863667\n",
            " 0.8669828  0.89714642 0.94350123 0.98952323 0.8669828  0.78946592\n",
            " 0.86731561 0.94316842 0.86709373 0.85145723 0.74322205 0.83537698\n",
            " 0.86664998 0.78880029 0.79002061 0.91311573 0.88217555 0.80454773\n",
            " 0.77394036 0.80476961 0.83615355 0.78990967]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.21635136 -0.21657323 -0.20126955 -0.23243161 -0.2164623  -0.26259523\n",
            " -0.21690605 -0.23198786 -0.21712792 -0.2320988  -0.23154411 -0.2477353\n",
            " -0.21668417 -0.17066217 -0.18452367 -0.23121129 -0.20049298 -0.21635136\n",
            " -0.26226242 -0.23187692 -0.26259523 -0.23187692 -0.1548038  -0.26292805\n",
            " -0.29431198 -0.24751342 -0.24751342 -0.23176598 -0.21624042 -0.24784623\n",
            " -0.2477353  -0.23154411 -0.23176598 -0.21590761 -0.2320988  -0.18541117\n",
            " -0.20038204 -0.2320988  -0.20160236 -0.23187692 -0.20093673 -0.20149142\n",
            " -0.20160236 -0.24751342 -0.29397917 -0.21668417 -0.24740248 -0.21690605\n",
            " -0.23165504 -0.2164623   0.07080401  0.20997939  0.08721708  0.13290627\n",
            "  0.10207702 -0.02090717  0.30213432  0.02533671  0.10229889  0.05627689\n",
            "  0.21075595  0.17959389  0.14898652  0.22539401  0.20997939  0.17959389\n",
            "  0.1486537  -0.03632179 -0.06737292  0.22572683  0.11804633  0.24080864\n",
            " -0.03632179  0.2415852   0.11782445  0.07180246  0.25699983  0.24136333\n",
            "  0.1330172   0.10285358  0.05649877  0.01047677  0.1330172   0.21053408\n",
            "  0.13268439  0.05683158  0.13290627  0.14854277  0.25677795  0.16462302\n",
            "  0.13335002  0.21119971  0.20997939  0.08688427  0.11782445  0.19545227\n",
            "  0.22605964  0.19523039  0.16384645  0.21009033]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053, 2.290947632071186, 2.222263427119805, 2.1560183174034226, 2.0921256797590733, 2.0305019674001348, 1.971066600660427]\n",
            "Epoch - 39 starting.....\n",
            "Predicted Output from the Adaline Model in the 39 th step is as follows: [0.21222477 0.2127012  0.19745256 0.22914093 0.21246299 0.25868535\n",
            " 0.21341585 0.22818806 0.21389229 0.22842628 0.2272352  0.24438958\n",
            " 0.21293942 0.16695527 0.1791071  0.22652055 0.19578504 0.21222477\n",
            " 0.2579707  0.22794985 0.25868535 0.22794985 0.15051554 0.2594\n",
            " 0.29156481 0.24391314 0.24391314 0.22771163 0.21198655 0.24462779\n",
            " 0.24438958 0.2272352  0.22771163 0.2112719  0.22842628 0.18101283\n",
            " 0.19554682 0.22842628 0.19816721 0.22794985 0.19673791 0.19792899\n",
            " 0.19816721 0.24391314 0.29085016 0.21293942 0.24367492 0.21341585\n",
            " 0.22747341 0.21246299 0.93271974 0.79238512 0.91508893 0.86981943\n",
            " 0.90079315 1.02397339 0.70017861 0.9775128  0.90031672 0.94630087\n",
            " 0.79071761 0.82240598 0.85290327 0.77689826 0.79238512 0.82240598\n",
            " 0.85361792 1.03946025 1.0709104  0.77618361 0.88411521 0.7614114\n",
            " 1.03946025 0.75974388 0.88459164 0.93057579 0.74425702 0.76022032\n",
            " 0.86958121 0.89912563 0.94582443 0.99180858 0.86958121 0.79119404\n",
            " 0.87029586 0.94510978 0.86981943 0.85385613 0.74473346 0.83693997\n",
            " 0.86886656 0.78976474 0.79238512 0.91580358 0.88459164 0.80596625\n",
            " 0.77546896 0.80644268 0.83860749 0.79214691]\n",
            "\n",
            "\n",
            "Here are the continuous Errors in this Epoch, This will be used to make update in the weigths for the model:::\n",
            " [-0.21222477 -0.2127012  -0.19745256 -0.22914093 -0.21246299 -0.25868535\n",
            " -0.21341585 -0.22818806 -0.21389229 -0.22842628 -0.2272352  -0.24438958\n",
            " -0.21293942 -0.16695527 -0.1791071  -0.22652055 -0.19578504 -0.21222477\n",
            " -0.2579707  -0.22794985 -0.25868535 -0.22794985 -0.15051554 -0.2594\n",
            " -0.29156481 -0.24391314 -0.24391314 -0.22771163 -0.21198655 -0.24462779\n",
            " -0.24438958 -0.2272352  -0.22771163 -0.2112719  -0.22842628 -0.18101283\n",
            " -0.19554682 -0.22842628 -0.19816721 -0.22794985 -0.19673791 -0.19792899\n",
            " -0.19816721 -0.24391314 -0.29085016 -0.21293942 -0.24367492 -0.21341585\n",
            " -0.22747341 -0.21246299  0.06728026  0.20761488  0.08491107  0.13018057\n",
            "  0.09920685 -0.02397339  0.29982139  0.0224872   0.09968328  0.05369913\n",
            "  0.20928239  0.17759402  0.14709673  0.22310174  0.20761488  0.17759402\n",
            "  0.14638208 -0.03946025 -0.0709104   0.22381639  0.11588479  0.2385886\n",
            " -0.03946025  0.24025612  0.11540836  0.06942421  0.25574298  0.23977968\n",
            "  0.13041879  0.10087437  0.05417557  0.00819142  0.13041879  0.20880596\n",
            "  0.12970414  0.05489022  0.13018057  0.14614387  0.25526654  0.16306003\n",
            "  0.13113344  0.21023526  0.20761488  0.08419642  0.11540836  0.19403375\n",
            "  0.22453104  0.19355732  0.16139251  0.20785309]\n",
            "Current value for the Loss value is :: [27.753846092917033, 11.692264235485673, 7.5684397817329465, 6.394568360318542, 5.953805667157766, 5.699219263034365, 5.495729829868798, 5.309839107596333, 5.133108047366961, 4.963284191914658, 4.799646945772431, 4.641859375282631, 4.489684822758253, 4.342916814943154, 4.201361582832035, 4.064833563774253, 3.9331541119993196, 3.8061510068259112, 3.683658163772909, 3.5655154016638737, 3.451568229281854, 3.341667642382811, 3.2356699286040502, 3.133436479470426, 3.0348336091187913, 2.939732379470634, 2.8480084316161496, 2.759541823187271, 2.6742168715064283, 2.5919220023058687, 2.512549603819618, 2.4359958860573054, 2.3621607450758053, 2.290947632071186, 2.222263427119805, 2.1560183174034226, 2.0921256797590733, 2.0305019674001348, 1.971066600660427, 1.9137418616184807]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ru-P06zfTm77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}